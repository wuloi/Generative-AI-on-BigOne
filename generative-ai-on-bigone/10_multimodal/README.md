# Chapter 10:  Multimodal Foundation Models
[![](../img/gaia_book_cover_sm.png)](https://www.amazon.com/Generative-AI-AWS-Multimodal-Applications/dp/1098159225/)

# Questions and Answers
_Q: What are the typical use cases for multimodal foundation models?_

A: Text summarization, rewriting, information extraction, question answering (QA) and visual question answering (VQA), detecting toxic or harmful content, classification and content moderation, conversational interface, translation, source code generation, reasoning, mask personally identifiable information (PII), personalized marketing and ads.

_Q: How does image generation differ from image editing and enhancement?_

A: Image generation involves creating images from text prompts, while image editing and enhancement modify existing images based on instructions and prompts, supporting use cases like artistic style transfer, domain adaptation, and upscaling.

_Q: What are best practices for multimodal prompt engineering for image-based generative AI?_

A: Understand the nuances of the foundation model, define the type of image, describe the subject, specify style and artists, be specific about quality, and be expressive in prompt writing.

_Q: Can you explain inpainting, outpainting, and depth-to-image techniques?_

A: Inpainting, Outpainting, and Depth-to-Image are specific tasks within generative AI but the document does not provide detailed explanations of these techniques."

_Q: How does image captioning contribute to visual question answering?_

A: Image captioning, by combining computer vision and natural language processing, enhances tasks like VQA by understanding both visual information in images and textual content of questions to provide accurate and relevant answers.

# Chapters
* [Chapter 1](/01_intro) - Generative AI Use Cases, Fundamentals, Project Lifecycle
* [Chapter 2](/02_prompt) - Prompt Engineering and In-Context Learning
* [Chapter 3](/03_foundation) - Large-Language Foundation Models
* [Chapter 4](/04_optimize) - Quantization and Distributed Computing
* [Chapter 5](/05_finetune) - Fine-Tuning and Evaluation
* [Chapter 6](/06_peft) - Parameter-efficient Fine Tuning (PEFT)
* [Chapter 7](/07_rlhf) - Fine-tuning using Reinforcement Learning with RLHF
* [Chapter 8](/08_deploy) - Optimize and Deploy Generative AI Applications
* [Chapter 9](/09_rag) - Retrieval Augmented Generation (RAG) and Agents
* [Chapter 10](/10_multimodal) - Multimodal Foundation Models
* [Chapter 11](/11_diffusers) - Controlled Generation and Fine-Tuning with Stable Diffusion
* [Chapter 12](/12_bedrock) - Amazon Bedrock Managed Service for Generative AI

# Related Resources
* YouTube Channel: https://youtube.generativeaionaws.com
* Generative AI on AWS Meetup (Global, Virtual): https://meetup.generativeaionaws.com
* Generative AI on AWS O'Reilly Book: https://www.amazon.com/Generative-AI-AWS-Multimodal-Applications/dp/1098159225/
* Data Science on AWS O'Reilly Book: https://www.amazon.com/Data-Science-AWS-End-End/dp/1492079391/
