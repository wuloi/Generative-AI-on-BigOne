{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7770f11b-b09e-4e02-a24d-a79ee0cc1653",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explore the reward dataset used to improve the model's helpfulness\n",
    "\n",
    "Dataset is from this repo: https://huggingface.co/datasets/lvwerra/stack-exchange-paired/viewer/lvwerra--stack-exchange-paired/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2cdeb5-ae1e-43df-b5ff-356ed6c7b779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch==2.0.1 in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchdata in /opt/conda/lib/python3.10/site-packages (0.6.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (4.3.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (68.2.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.41.2)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1) (3.27.7)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1) (17.0.3)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata) (2.0.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchdata) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.0.1 torchdata\n",
    "#%pip install torch==1.13.1 torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9e2b97-4359-462c-96ab-c61d7a252360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --disable-pip-version-check -q \\\n",
    "    transformers==4.34.1 \\\n",
    "    datasets==2.12.0 \\\n",
    "    accelerate==0.23.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    trl==0.7.2 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    loralib==0.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5fc934-26c5-4bce-a647-60e3b16ff7e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScriptArguments(local_rank=-1, resume_from_checkpoint=False, deepspeed=None, per_device_train_batch_size=4, per_device_eval_batch_size=1, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.001, model_name='roberta-base', bf16=True, num_train_epochs=1, train_subset=100000, eval_subset=50000, gradient_checkpointing=False, optim='adamw_hf', lr_scheduler_type='linear', max_length=512)\n"
     ]
    }
   ],
   "source": [
    "# reward_modeling.py\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    PreTrainedTokenizerBase,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.utils import PaddingStrategy\n",
    "\n",
    "# Define and parse arguments.\n",
    "@dataclass\n",
    "class ScriptArguments:\n",
    "    \"\"\"\n",
    "    These arguments vary depending on how many GPUs you have, what their capacity and features are, and what size model you want to train.\n",
    "    \"\"\"\n",
    "\n",
    "    local_rank: Optional[int] = field(default=-1, metadata={\"help\": \"Used for multi-gpu\"})\n",
    "    resume_from_checkpoint: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"If you want to resume training where it left off.\"},\n",
    "    )\n",
    "    deepspeed: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Path to deepspeed config if using deepspeed. You may need this if the model that you want to train doesn't fit on a single GPU.\"\n",
    "        },\n",
    "    )\n",
    "    per_device_train_batch_size: Optional[int] = field(default=4)\n",
    "    per_device_eval_batch_size: Optional[int] = field(default=1)\n",
    "    gradient_accumulation_steps: Optional[int] = field(default=1)\n",
    "    learning_rate: Optional[float] = field(default=2e-5)\n",
    "    weight_decay: Optional[int] = field(default=0.001)\n",
    "    model_name: Optional[str] = field(        \n",
    "        #default=\"gpt2\",\n",
    "        #default=\"EleutherAI/gpt-neo-125m\",\n",
    "        default=\"roberta-base\",\n",
    "        metadata={\n",
    "            \"help\": \"The model that you want to train from the Hugging Face hub. E.g. gpt2, gpt2-xl, bert, etc.\"\n",
    "        },\n",
    "    )\n",
    "    bf16: Optional[bool] = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            \"help\": \"This essentially cuts the training time in half if you want to sacrifice a little precision and have a supported GPU.\"\n",
    "        },\n",
    "    )\n",
    "    num_train_epochs: Optional[int] = field(\n",
    "        default=1,\n",
    "        metadata={\"help\": \"The number of training epochs for the reward model.\"},\n",
    "    )\n",
    "    train_subset: Optional[int] = field(\n",
    "        default=100000,\n",
    "        metadata={\"help\": \"The size of the subset of the training data to use\"},\n",
    "    )\n",
    "    eval_subset: Optional[int] = field(\n",
    "        default=50000,\n",
    "        metadata={\"help\": \"The size of the subset of the eval data to use\"},\n",
    "    )\n",
    "    gradient_checkpointing: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Enables gradient checkpointing.\"},\n",
    "    )\n",
    "    optim: Optional[str] = field(\n",
    "        default=\"adamw_hf\",\n",
    "        metadata={\"help\": \"Enables gradient checkpointing.\"},\n",
    "    )\n",
    "    lr_scheduler_type: Optional[str] = field(\n",
    "        default=\"linear\",\n",
    "        metadata={\"help\": \"The lr scheduler\"},\n",
    "    )\n",
    "    max_length: Optional[int] = field(\n",
    "        default=512\n",
    "    )\n",
    "\n",
    "\n",
    "parser = HfArgumentParser(ScriptArguments)\n",
    "script_args = parser.parse_args_into_dataclasses(return_remaining_strings=True)[0]\n",
    "print(script_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b9eb14-ac48-4e00-8eae-9641fdcaf290",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/lvwerra___parquet/lvwerra--stack-exchange-paired-ea956f7e49277b88/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/lvwerra___parquet/lvwerra--stack-exchange-paired-6fbcbcc16115b7c8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "# Load the human stack-exchange-paired dataset for training the reward model.\n",
    "train_dataset = load_dataset(\"lvwerra/stack-exchange-paired\", data_dir=\"data/reward\", split=\"train\")\n",
    "if script_args.train_subset > 0:\n",
    "    train_dataset = train_dataset.select(range(script_args.train_subset))\n",
    "\n",
    "validation_dataset = load_dataset(\"lvwerra/stack-exchange-paired\", data_dir=\"data/evaluation\", split=\"train\")\n",
    "if script_args.eval_subset > 0:\n",
    "    validation_dataset = validation_dataset.select(range(script_args.eval_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c49bbb13-ef9c-447d-8fcc-72e82ee9b349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 886,273 || all params: 125,532,674 || trainable%: 0.706009815420645\n"
     ]
    }
   ],
   "source": [
    "model_name_split = script_args.model_name.split(\"/\")[-1]\n",
    "# output_name = (\n",
    "#     f\"{model_name_split}_peft_stack-exchange-paired_rmts__{script_args.train_subset}_{script_args.learning_rate}\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Load the value-head model and tokenizer.\n",
    "config = AutoConfig.from_pretrained(script_args.model_name)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8, # rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "peft_ranking_reward_public_qanda_model_base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    script_args.model_name, num_labels=1, torch_dtype=torch.bfloat16\n",
    ")\n",
    "peft_ranking_reward_public_qanda_model = get_peft_model(peft_ranking_reward_public_qanda_model_base, peft_config)\n",
    "peft_ranking_reward_public_qanda_model.print_trainable_parameters()\n",
    "#peft_rl_ranking_reward_public_dataset_model.config.pad_token_id = tokenizer.eos_token_id # needed for gpt2, gpt-neo, etc\n",
    "#peft_rl_ranking_reward_public_dataset_model.config.use_cache = not script_args.gradient_checkpointing\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(script_args.model_name)\n",
    "# tokenizer.pad_token = tokenizer.eos_token # needed for gpt2, gpt-neo\n",
    "\n",
    "num_proc = 24  # Can adjust to be higher if you have more processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c2c86af-77ee-4bd6-8353-16bd37534032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn the dataset into pairs of post + summaries, where text_j is the preferred question + answer and text_k is the other.\n",
    "# Then tokenize the dataset.\n",
    "def preprocess_function(examples):\n",
    "    new_examples = {\n",
    "        \"input_ids_j\": [],\n",
    "        \"attention_mask_j\": [],\n",
    "        \"input_ids_k\": [],\n",
    "        \"attention_mask_k\": [],\n",
    "    }\n",
    "    for question, response_j, response_k in zip(examples[\"question\"], examples[\"response_j\"], examples[\"response_k\"]):\n",
    "        tokenized_j = tokenizer(\"Question: \" + question + \"\\n\\nAnswer: \" + response_j, truncation=True)\n",
    "        tokenized_k = tokenizer(\"Question: \" + question + \"\\n\\nAnswer: \" + response_k, truncation=True)\n",
    "\n",
    "        new_examples[\"input_ids_j\"].append(tokenized_j[\"input_ids\"])\n",
    "        new_examples[\"attention_mask_j\"].append(tokenized_j[\"attention_mask\"])\n",
    "        new_examples[\"input_ids_k\"].append(tokenized_k[\"input_ids\"])\n",
    "        new_examples[\"attention_mask_k\"].append(tokenized_k[\"attention_mask\"])\n",
    "\n",
    "    return new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e480f2a3-3c9e-43c2-b1a6-cda1a646508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/lvwerra___parquet/lvwerra--stack-exchange-paired-ea956f7e49277b88/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-08b0763558cb68da_*_of_00024.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/lvwerra___parquet/lvwerra--stack-exchange-paired-ea956f7e49277b88/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-4404778d5774ed60.arrow\n"
     ]
    }
   ],
   "source": [
    "original_columns = train_dataset.column_names\n",
    "\n",
    "# preprocess the dataset and filter out QAs that are longer than script_args.max_length\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, num_proc=num_proc, remove_columns=original_columns)\n",
    "train_dataset = train_dataset.filter(lambda x: len(x[\"input_ids_j\"]) <= script_args.max_length and len(x[\"input_ids_k\"]) <= script_args.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "421434dd-a734-4081-b346-dcc1e8fbbe30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/lvwerra___parquet/lvwerra--stack-exchange-paired-6fbcbcc16115b7c8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-f55953eb9f45777a_*_of_00024.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/lvwerra___parquet/lvwerra--stack-exchange-paired-6fbcbcc16115b7c8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-f41bdb6f88ea1c3c.arrow\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = validation_dataset.map(preprocess_function, batched=True, num_proc=num_proc, remove_columns=original_columns)\n",
    "validation_dataset = validation_dataset.filter(lambda x: len(x[\"input_ids_j\"]) <= script_args.max_length and len(x[\"input_ids_k\"]) <= script_args.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db988cbe-e3d6-46c7-9633-16e023645a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to define a special data collator that batches the data in our j vs k format.\n",
    "@dataclass\n",
    "class RewardDataCollatorWithPadding:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        features_j = []\n",
    "        features_k = []\n",
    "        for feature in features:\n",
    "            features_j.append(\n",
    "                {\n",
    "                    \"input_ids\": feature[\"input_ids_j\"],\n",
    "                    \"attention_mask\": feature[\"attention_mask_j\"],\n",
    "                }\n",
    "            )\n",
    "            features_k.append(\n",
    "                {\n",
    "                    \"input_ids\": feature[\"input_ids_k\"],\n",
    "                    \"attention_mask\": feature[\"attention_mask_k\"],\n",
    "                }\n",
    "            )\n",
    "        batch_j = self.tokenizer.pad(\n",
    "            features_j,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "        batch_k = self.tokenizer.pad(\n",
    "            features_k,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "        batch = {\n",
    "            \"input_ids_j\": batch_j[\"input_ids\"],\n",
    "            \"attention_mask_j\": batch_j[\"attention_mask\"],\n",
    "            \"input_ids_k\": batch_k[\"input_ids\"],\n",
    "            \"attention_mask_k\": batch_k[\"attention_mask\"],\n",
    "            \"return_loss\": True,\n",
    "        }\n",
    "        \n",
    "        # print(batch)\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da928dc-dddf-49e2-a39c-a5d745b24a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the metric that we'll use for validation.\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, _ = eval_pred\n",
    "    # Here, predictions is rewards_j and rewards_k.\n",
    "    # We want to see how much of the time rewards_j > rewards_k.\n",
    "    predictions = np.argmax(predictions, axis=0)\n",
    "    #print('predictions {}'.format(predictions))\n",
    "    labels = np.zeros(predictions.shape)\n",
    "    #print('labels {}'.format(labels))\n",
    "    metrics = accuracy.compute(predictions=predictions, references=labels)\n",
    "    #print('metrics {}'.format(metrics))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "class RewardTrainer(Trainer):\n",
    "    # Define how to compute the reward loss. We use the InstructGPT pairwise logloss: https://arxiv.org/abs/2203.02155\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        predicted_rewards_j = model(input_ids=inputs[\"input_ids_j\"], attention_mask=inputs[\"attention_mask_j\"])[0]\n",
    "        print('shape rewards_j: {}'.format(predicted_rewards_j.shape))        \n",
    "        \n",
    "        predicted_rewards_k = model(input_ids=inputs[\"input_ids_k\"], attention_mask=inputs[\"attention_mask_k\"])[0]\n",
    "        print('shape rewards_k: {}'.format(predicted_rewards_k.shape))\n",
    "        \n",
    "        loss = -nn.functional.logsigmoid(predicted_rewards_j - predicted_rewards_k).mean()\n",
    "        \n",
    "        print('return_outputs {}'.format({\"loss\": loss, \"rewards_j\": predicted_rewards_j, \"rewards_k\": predicted_rewards_k}))\n",
    "        if return_outputs:\n",
    "            return loss, {\"rewards_j\": predicted_rewards_j, \"rewards_k\": predicted_rewards_k}\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e84b9b-707f-4af2-ac7b-8d0e4f9348b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_ranking_reward_public_qanda_checkpoint='./peft_ranking_reward_public_qanda/'\n",
    "    \n",
    "# Define the training args. Needs to be done before the model is loaded if you are using deepspeed.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=peft_ranking_reward_public_qanda_checkpoint,\n",
    "    learning_rate=script_args.learning_rate,\n",
    "    per_device_train_batch_size=script_args.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=script_args.per_device_eval_batch_size,\n",
    "    num_train_epochs=script_args.num_train_epochs,\n",
    "    weight_decay=script_args.weight_decay,\n",
    "\n",
    "#   evaluation_strategy=\"steps\",\n",
    "#   eval_steps=500,\n",
    "#   save_strategy=\"steps\",\n",
    "#   save_steps=500,\n",
    "    \n",
    "#    gradient_accumulation_steps=script_args.gradient_accumulation_steps,\n",
    "#    gradient_checkpointing=script_args.gradient_checkpointing,\n",
    "#    deepspeed=script_args.deepspeed,\n",
    "    local_rank=script_args.local_rank,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[],\n",
    "    bf16=script_args.bf16,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1, # was 1000\n",
    "    max_steps=10, # was 1000\n",
    "    optim=script_args.optim,\n",
    "    lr_scheduler_type=script_args.lr_scheduler_type,\n",
    ")\n",
    "\n",
    "# Train the reward model, finally!\n",
    "reward_trainer = RewardTrainer(\n",
    "    model=peft_ranking_reward_public_qanda_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=RewardDataCollatorWithPadding(tokenizer=tokenizer, max_length=script_args.max_length),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29930aae-afa1-4d68-be93-deeff0fa0556",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2624: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape rewards_j: torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.7305, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[0.2080],\n",
      "        [0.2217],\n",
      "        [0.2676],\n",
      "        [0.3164],\n",
      "        [0.2285],\n",
      "        [0.2188],\n",
      "        [0.2871],\n",
      "        [0.3086],\n",
      "        [0.2207],\n",
      "        [0.2246],\n",
      "        [0.3027],\n",
      "        [0.3086],\n",
      "        [0.2080],\n",
      "        [0.2119],\n",
      "        [0.2988],\n",
      "        [0.2988],\n",
      "        [0.2031],\n",
      "        [0.2324],\n",
      "        [0.2891],\n",
      "        [0.2988],\n",
      "        [0.2188],\n",
      "        [0.2178],\n",
      "        [0.2715],\n",
      "        [0.3242],\n",
      "        [0.2168],\n",
      "        [0.2051],\n",
      "        [0.2930],\n",
      "        [0.2852],\n",
      "        [0.1924],\n",
      "        [0.2012],\n",
      "        [0.2656],\n",
      "        [0.3164]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[ 0.2441],\n",
      "        [-0.0028],\n",
      "        [ 0.7617],\n",
      "        [ 0.2656],\n",
      "        [ 0.2373],\n",
      "        [-0.0087],\n",
      "        [ 0.7266],\n",
      "        [ 0.2617],\n",
      "        [ 0.2432],\n",
      "        [-0.0156],\n",
      "        [ 0.7852],\n",
      "        [ 0.2490],\n",
      "        [ 0.2314],\n",
      "        [-0.0171],\n",
      "        [ 0.8008],\n",
      "        [ 0.2578],\n",
      "        [ 0.2246],\n",
      "        [-0.0159],\n",
      "        [ 0.7891],\n",
      "        [ 0.2490],\n",
      "        [ 0.2412],\n",
      "        [-0.0153],\n",
      "        [ 0.7773],\n",
      "        [ 0.2754],\n",
      "        [ 0.2354],\n",
      "        [-0.0255],\n",
      "        [ 0.7812],\n",
      "        [ 0.2500],\n",
      "        [ 0.2051],\n",
      "        [-0.0315],\n",
      "        [ 0.7734],\n",
      "        [ 0.2676]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.730500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.742200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.675800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.726600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.695300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.679700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.671900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2624: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape rewards_j: torch.Size([32, 1])\n",
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.7422, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[0.3047],\n",
      "        [0.2715],\n",
      "        [0.3574],\n",
      "        [0.2812],\n",
      "        [0.3223],\n",
      "        [0.2793],\n",
      "        [0.2471],\n",
      "        [0.2734],\n",
      "        [0.3047],\n",
      "        [0.2754],\n",
      "        [0.3262],\n",
      "        [0.2773],\n",
      "        [0.3008],\n",
      "        [0.2754],\n",
      "        [0.2256],\n",
      "        [0.2793],\n",
      "        [0.3105],\n",
      "        [0.2891],\n",
      "        [0.3418],\n",
      "        [0.2754],\n",
      "        [0.2891],\n",
      "        [0.2656],\n",
      "        [0.4102],\n",
      "        [0.2832],\n",
      "        [0.3027],\n",
      "        [0.2793],\n",
      "        [0.2656],\n",
      "        [0.2734],\n",
      "        [0.2891],\n",
      "        [0.2637],\n",
      "        [0.2949],\n",
      "        [0.2832]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[0.3320],\n",
      "        [0.3242],\n",
      "        [0.2832],\n",
      "        [0.5977],\n",
      "        [0.3105],\n",
      "        [0.3262],\n",
      "        [0.2773],\n",
      "        [0.6328],\n",
      "        [0.3184],\n",
      "        [0.3242],\n",
      "        [0.2754],\n",
      "        [0.5938],\n",
      "        [0.3105],\n",
      "        [0.3301],\n",
      "        [0.2852],\n",
      "        [0.6445],\n",
      "        [0.3086],\n",
      "        [0.3340],\n",
      "        [0.2891],\n",
      "        [0.6133],\n",
      "        [0.3145],\n",
      "        [0.3281],\n",
      "        [0.2793],\n",
      "        [0.6211],\n",
      "        [0.3223],\n",
      "        [0.3301],\n",
      "        [0.2891],\n",
      "        [0.5859],\n",
      "        [0.3066],\n",
      "        [0.3320],\n",
      "        [0.2891],\n",
      "        [0.5938]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n",
      "shape rewards_j: torch.Size([32, 1])\n",
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.6758, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[0.3145],\n",
      "        [0.2578],\n",
      "        [0.3770],\n",
      "        [0.3145],\n",
      "        [0.3477],\n",
      "        [0.2793],\n",
      "        [0.3633],\n",
      "        [0.2949],\n",
      "        [0.2969],\n",
      "        [0.2617],\n",
      "        [0.2988],\n",
      "        [0.2910],\n",
      "        [0.2793],\n",
      "        [0.2656],\n",
      "        [0.5469],\n",
      "        [0.2832],\n",
      "        [0.3125],\n",
      "        [0.2637],\n",
      "        [0.3477],\n",
      "        [0.2930],\n",
      "        [0.2930],\n",
      "        [0.2471],\n",
      "        [0.3828],\n",
      "        [0.2969],\n",
      "        [0.3027],\n",
      "        [0.2598],\n",
      "        [0.3613],\n",
      "        [0.2930],\n",
      "        [0.3301],\n",
      "        [0.2637],\n",
      "        [0.2969],\n",
      "        [0.2891]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[0.2168],\n",
      "        [0.2852],\n",
      "        [0.3438],\n",
      "        [0.2715],\n",
      "        [0.2285],\n",
      "        [0.3008],\n",
      "        [0.3516],\n",
      "        [0.2539],\n",
      "        [0.2012],\n",
      "        [0.2871],\n",
      "        [0.3516],\n",
      "        [0.2500],\n",
      "        [0.2402],\n",
      "        [0.2832],\n",
      "        [0.3418],\n",
      "        [0.2402],\n",
      "        [0.1992],\n",
      "        [0.2852],\n",
      "        [0.3379],\n",
      "        [0.2578],\n",
      "        [0.2207],\n",
      "        [0.2715],\n",
      "        [0.3027],\n",
      "        [0.2695],\n",
      "        [0.1973],\n",
      "        [0.2832],\n",
      "        [0.3379],\n",
      "        [0.2617],\n",
      "        [0.2139],\n",
      "        [0.2734],\n",
      "        [0.3535],\n",
      "        [0.2617]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n",
      "shape rewards_j: torch.Size([32, 1])\n",
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.5938, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[0.3887],\n",
      "        [0.2432],\n",
      "        [0.4688],\n",
      "        [0.2236],\n",
      "        [0.5234],\n",
      "        [0.2578],\n",
      "        [0.5195],\n",
      "        [0.2178],\n",
      "        [0.5508],\n",
      "        [0.2559],\n",
      "        [0.3008],\n",
      "        [0.2197],\n",
      "        [0.5430],\n",
      "        [0.2520],\n",
      "        [0.3086],\n",
      "        [0.2285],\n",
      "        [0.4023],\n",
      "        [0.2539],\n",
      "        [0.3906],\n",
      "        [0.2256],\n",
      "        [0.4258],\n",
      "        [0.2754],\n",
      "        [0.5234],\n",
      "        [0.2236],\n",
      "        [0.3867],\n",
      "        [0.2422],\n",
      "        [0.3457],\n",
      "        [0.2178],\n",
      "        [0.4941],\n",
      "        [0.2715],\n",
      "        [0.3555],\n",
      "        [0.2295]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[ 0.3379],\n",
      "        [ 0.2031],\n",
      "        [-0.0131],\n",
      "        [-0.0317],\n",
      "        [ 0.3242],\n",
      "        [ 0.2129],\n",
      "        [-0.0109],\n",
      "        [-0.0811],\n",
      "        [ 0.3340],\n",
      "        [ 0.2227],\n",
      "        [-0.0176],\n",
      "        [-0.0103],\n",
      "        [ 0.3516],\n",
      "        [ 0.2158],\n",
      "        [-0.0184],\n",
      "        [-0.0297],\n",
      "        [ 0.3418],\n",
      "        [ 0.2207],\n",
      "        [-0.0128],\n",
      "        [-0.0430],\n",
      "        [ 0.3086],\n",
      "        [ 0.2207],\n",
      "        [-0.0098],\n",
      "        [-0.0289],\n",
      "        [ 0.3203],\n",
      "        [ 0.2080],\n",
      "        [-0.0103],\n",
      "        [-0.0850],\n",
      "        [ 0.3223],\n",
      "        [ 0.2344],\n",
      "        [-0.0019],\n",
      "        [-0.0152]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n",
      "shape rewards_j: torch.Size([32, 1])\n",
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.6328, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[0.2559],\n",
      "        [0.3125],\n",
      "        [0.3594],\n",
      "        [0.3379],\n",
      "        [0.2695],\n",
      "        [0.3125],\n",
      "        [0.3418],\n",
      "        [0.3125],\n",
      "        [0.2832],\n",
      "        [0.3027],\n",
      "        [0.3574],\n",
      "        [0.3418],\n",
      "        [0.2812],\n",
      "        [0.3105],\n",
      "        [0.3535],\n",
      "        [0.3359],\n",
      "        [0.2617],\n",
      "        [0.2988],\n",
      "        [0.3477],\n",
      "        [0.3301],\n",
      "        [0.2383],\n",
      "        [0.3086],\n",
      "        [0.3672],\n",
      "        [0.3184],\n",
      "        [0.2490],\n",
      "        [0.3105],\n",
      "        [0.3438],\n",
      "        [0.3320],\n",
      "        [0.2500],\n",
      "        [0.3027],\n",
      "        [0.3418],\n",
      "        [0.3359]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[ 0.2988],\n",
      "        [ 0.2188],\n",
      "        [-0.0232],\n",
      "        [ 0.2266],\n",
      "        [ 0.3105],\n",
      "        [ 0.2139],\n",
      "        [ 0.0023],\n",
      "        [ 0.2207],\n",
      "        [ 0.3008],\n",
      "        [ 0.2178],\n",
      "        [-0.0102],\n",
      "        [ 0.2402],\n",
      "        [ 0.3281],\n",
      "        [ 0.2051],\n",
      "        [-0.0122],\n",
      "        [ 0.2207],\n",
      "        [ 0.2852],\n",
      "        [ 0.2129],\n",
      "        [-0.0011],\n",
      "        [ 0.2246],\n",
      "        [ 0.2969],\n",
      "        [ 0.1973],\n",
      "        [ 0.0048],\n",
      "        [ 0.2236],\n",
      "        [ 0.2988],\n",
      "        [ 0.2188],\n",
      "        [-0.0233],\n",
      "        [ 0.2314],\n",
      "        [ 0.3066],\n",
      "        [ 0.2217],\n",
      "        [ 0.0043],\n",
      "        [ 0.2246]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n",
      "shape rewards_j: torch.Size([32, 1])\n",
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.7266, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[ 0.3535],\n",
      "        [ 0.2490],\n",
      "        [-0.0012],\n",
      "        [ 0.3125],\n",
      "        [ 0.3613],\n",
      "        [ 0.2480],\n",
      "        [ 0.0041],\n",
      "        [ 0.3125],\n",
      "        [ 0.3574],\n",
      "        [ 0.2471],\n",
      "        [-0.0057],\n",
      "        [ 0.2988],\n",
      "        [ 0.3730],\n",
      "        [ 0.2285],\n",
      "        [-0.0047],\n",
      "        [ 0.3066],\n",
      "        [ 0.3516],\n",
      "        [ 0.2334],\n",
      "        [-0.0028],\n",
      "        [ 0.3398],\n",
      "        [ 0.3633],\n",
      "        [ 0.2451],\n",
      "        [ 0.0110],\n",
      "        [ 0.3086],\n",
      "        [ 0.3457],\n",
      "        [ 0.2441],\n",
      "        [ 0.0052],\n",
      "        [ 0.3359],\n",
      "        [ 0.3457],\n",
      "        [ 0.2432],\n",
      "        [-0.0056],\n",
      "        [ 0.3203]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[0.3105],\n",
      "        [0.2832],\n",
      "        [0.2637],\n",
      "        [0.2910],\n",
      "        [0.3145],\n",
      "        [0.2793],\n",
      "        [0.2539],\n",
      "        [0.2012],\n",
      "        [0.3340],\n",
      "        [0.2910],\n",
      "        [0.2490],\n",
      "        [0.2422],\n",
      "        [0.3105],\n",
      "        [0.2695],\n",
      "        [0.2559],\n",
      "        [0.2871],\n",
      "        [0.3223],\n",
      "        [0.2793],\n",
      "        [0.2471],\n",
      "        [0.3262],\n",
      "        [0.3242],\n",
      "        [0.2812],\n",
      "        [0.2578],\n",
      "        [0.3477],\n",
      "        [0.3242],\n",
      "        [0.2891],\n",
      "        [0.2578],\n",
      "        [0.4062],\n",
      "        [0.3223],\n",
      "        [0.2910],\n",
      "        [0.2539],\n",
      "        [0.3379]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n",
      "shape rewards_j: torch.Size([32, 1])\n",
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.6953, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[0.2100],\n",
      "        [0.1914],\n",
      "        [0.2656],\n",
      "        [0.5078],\n",
      "        [0.2324],\n",
      "        [0.1973],\n",
      "        [0.2598],\n",
      "        [0.5000],\n",
      "        [0.2148],\n",
      "        [0.1904],\n",
      "        [0.2656],\n",
      "        [0.4805],\n",
      "        [0.2285],\n",
      "        [0.1846],\n",
      "        [0.2695],\n",
      "        [0.5039],\n",
      "        [0.2227],\n",
      "        [0.1895],\n",
      "        [0.2715],\n",
      "        [0.5000],\n",
      "        [0.2109],\n",
      "        [0.1807],\n",
      "        [0.2617],\n",
      "        [0.4824],\n",
      "        [0.2197],\n",
      "        [0.1660],\n",
      "        [0.2227],\n",
      "        [0.4805],\n",
      "        [0.2168],\n",
      "        [0.1934],\n",
      "        [0.2578],\n",
      "        [0.5352]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[0.2539],\n",
      "        [0.3516],\n",
      "        [0.2852],\n",
      "        [0.2734],\n",
      "        [0.2617],\n",
      "        [0.3457],\n",
      "        [0.3184],\n",
      "        [0.2930],\n",
      "        [0.2539],\n",
      "        [0.3281],\n",
      "        [0.2988],\n",
      "        [0.2695],\n",
      "        [0.2715],\n",
      "        [0.3418],\n",
      "        [0.2910],\n",
      "        [0.2871],\n",
      "        [0.2559],\n",
      "        [0.3555],\n",
      "        [0.2988],\n",
      "        [0.2871],\n",
      "        [0.2559],\n",
      "        [0.3125],\n",
      "        [0.3008],\n",
      "        [0.2715],\n",
      "        [0.2422],\n",
      "        [0.3008],\n",
      "        [0.2754],\n",
      "        [0.2871],\n",
      "        [0.2617],\n",
      "        [0.3496],\n",
      "        [0.2871],\n",
      "        [0.2852]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n",
      "shape rewards_j: torch.Size([32, 1])\n",
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.6680, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[0.3301],\n",
      "        [0.3184],\n",
      "        [0.3066],\n",
      "        [0.2520],\n",
      "        [0.3613],\n",
      "        [0.3223],\n",
      "        [0.2969],\n",
      "        [0.2539],\n",
      "        [0.3340],\n",
      "        [0.3184],\n",
      "        [0.2988],\n",
      "        [0.2715],\n",
      "        [0.3496],\n",
      "        [0.3223],\n",
      "        [0.3184],\n",
      "        [0.2373],\n",
      "        [0.3438],\n",
      "        [0.3242],\n",
      "        [0.2871],\n",
      "        [0.2500],\n",
      "        [0.3359],\n",
      "        [0.3164],\n",
      "        [0.3047],\n",
      "        [0.2324],\n",
      "        [0.3379],\n",
      "        [0.3477],\n",
      "        [0.2793],\n",
      "        [0.2354],\n",
      "        [0.3262],\n",
      "        [0.3418],\n",
      "        [0.2793],\n",
      "        [0.2500]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[0.2393],\n",
      "        [0.2559],\n",
      "        [0.2793],\n",
      "        [0.2559],\n",
      "        [0.1973],\n",
      "        [0.2949],\n",
      "        [0.2832],\n",
      "        [0.2383],\n",
      "        [0.2354],\n",
      "        [0.2773],\n",
      "        [0.2812],\n",
      "        [0.2578],\n",
      "        [0.2041],\n",
      "        [0.2559],\n",
      "        [0.2891],\n",
      "        [0.2520],\n",
      "        [0.1235],\n",
      "        [0.2715],\n",
      "        [0.2852],\n",
      "        [0.2441],\n",
      "        [0.1211],\n",
      "        [0.3105],\n",
      "        [0.2969],\n",
      "        [0.2266],\n",
      "        [0.2637],\n",
      "        [0.3066],\n",
      "        [0.2754],\n",
      "        [0.2285],\n",
      "        [0.0908],\n",
      "        [0.2969],\n",
      "        [0.2637],\n",
      "        [0.2578]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n",
      "shape rewards_j: torch.Size([32, 1])\n",
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.6797, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[0.2676],\n",
      "        [0.5781],\n",
      "        [0.3125],\n",
      "        [0.2910],\n",
      "        [0.2715],\n",
      "        [0.5312],\n",
      "        [0.3145],\n",
      "        [0.3105],\n",
      "        [0.2637],\n",
      "        [0.5703],\n",
      "        [0.3027],\n",
      "        [0.2969],\n",
      "        [0.2578],\n",
      "        [0.5898],\n",
      "        [0.2969],\n",
      "        [0.2949],\n",
      "        [0.2471],\n",
      "        [0.5664],\n",
      "        [0.3105],\n",
      "        [0.2988],\n",
      "        [0.2393],\n",
      "        [0.5859],\n",
      "        [0.2949],\n",
      "        [0.2930],\n",
      "        [0.2539],\n",
      "        [0.5430],\n",
      "        [0.3086],\n",
      "        [0.3125],\n",
      "        [0.2715],\n",
      "        [0.5859],\n",
      "        [0.2949],\n",
      "        [0.2988]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[0.5312],\n",
      "        [0.2559],\n",
      "        [0.2695],\n",
      "        [0.2393],\n",
      "        [0.5625],\n",
      "        [0.2471],\n",
      "        [0.2793],\n",
      "        [0.2031],\n",
      "        [0.5391],\n",
      "        [0.2637],\n",
      "        [0.2539],\n",
      "        [0.2432],\n",
      "        [0.5195],\n",
      "        [0.2656],\n",
      "        [0.2500],\n",
      "        [0.2266],\n",
      "        [0.4961],\n",
      "        [0.2617],\n",
      "        [0.2637],\n",
      "        [0.2334],\n",
      "        [0.5234],\n",
      "        [0.2637],\n",
      "        [0.2461],\n",
      "        [0.2295],\n",
      "        [0.5273],\n",
      "        [0.2490],\n",
      "        [0.2754],\n",
      "        [0.2471],\n",
      "        [0.5430],\n",
      "        [0.2500],\n",
      "        [0.2715],\n",
      "        [0.2236]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n",
      "shape rewards_j: torch.Size([32, 1])\n",
      "shape rewards_k: torch.Size([32, 1])\n",
      "return_outputs {'loss': tensor(0.6719, device='cuda:0', dtype=torch.bfloat16, grad_fn=<NegBackward0>), 'rewards_j': tensor([[ 0.2812],\n",
      "        [ 0.3281],\n",
      "        [-0.0142],\n",
      "        [ 0.3008],\n",
      "        [ 0.2676],\n",
      "        [ 0.3145],\n",
      "        [-0.0062],\n",
      "        [ 0.2695],\n",
      "        [ 0.2754],\n",
      "        [ 0.3164],\n",
      "        [-0.0069],\n",
      "        [ 0.3379],\n",
      "        [ 0.2754],\n",
      "        [ 0.3145],\n",
      "        [-0.0177],\n",
      "        [ 0.3027],\n",
      "        [ 0.2832],\n",
      "        [ 0.3125],\n",
      "        [ 0.0038],\n",
      "        [ 0.3418],\n",
      "        [ 0.2754],\n",
      "        [ 0.3203],\n",
      "        [-0.0190],\n",
      "        [ 0.2695],\n",
      "        [ 0.2754],\n",
      "        [ 0.3145],\n",
      "        [-0.0122],\n",
      "        [ 0.2285],\n",
      "        [ 0.2754],\n",
      "        [ 0.3262],\n",
      "        [-0.0089],\n",
      "        [ 0.2891]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>), 'rewards_k': tensor([[ 0.1826],\n",
      "        [ 0.2500],\n",
      "        [-0.0060],\n",
      "        [ 0.2500],\n",
      "        [ 0.1367],\n",
      "        [ 0.2461],\n",
      "        [-0.0047],\n",
      "        [ 0.2754],\n",
      "        [ 0.2236],\n",
      "        [ 0.2520],\n",
      "        [-0.0024],\n",
      "        [ 0.2617],\n",
      "        [ 0.1719],\n",
      "        [ 0.2539],\n",
      "        [-0.0109],\n",
      "        [ 0.2793],\n",
      "        [ 0.2793],\n",
      "        [ 0.2432],\n",
      "        [ 0.0081],\n",
      "        [ 0.2383],\n",
      "        [ 0.2275],\n",
      "        [ 0.2422],\n",
      "        [-0.0176],\n",
      "        [ 0.2598],\n",
      "        [ 0.1982],\n",
      "        [ 0.2412],\n",
      "        [-0.0005],\n",
      "        [ 0.2715],\n",
      "        [ 0.2266],\n",
      "        [ 0.2734],\n",
      "        [-0.0087],\n",
      "        [ 0.2598]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<GatherBackward>)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=0.681640625, metrics={'train_runtime': 29.2687, 'train_samples_per_second': 10.933, 'train_steps_per_second': 0.342, 'total_flos': 0.0, 'train_loss': 0.681640625, 'epoch': 0.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_trainer.train(script_args.resume_from_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bedef8f-208c-4193-93ec-35987cfd2b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving last checkpoint of the model to ./peft_ranking_reward_public_qanda/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./peft_ranking_reward_public_qanda/tokenizer_config.json',\n",
       " './peft_ranking_reward_public_qanda/special_tokens_map.json',\n",
       " './peft_ranking_reward_public_qanda/vocab.json',\n",
       " './peft_ranking_reward_public_qanda/merges.txt',\n",
       " './peft_ranking_reward_public_qanda/added_tokens.json',\n",
       " './peft_ranking_reward_public_qanda/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Saving last checkpoint of the model to {}\".format(peft_ranking_reward_public_qanda_checkpoint))\n",
    "#peft_rl_ranking_reward_public_dataset_model.save_pretrained(peft_rl_ranking_reward_public_dataset_model_checkpoint_name)\n",
    "#reward_trainer.tokenizer.save_pretrained(peft_rl_ranking_reward_public_dataset_model)\n",
    "#reward_trainer.unwrap_model(reward_trainer.model).save_pretrained(peft_rl_ranking_reward_public_dataset_model) # merge?\n",
    "#reward_trainer.model.save_pretrained(peft_rl_ranking_reward_public_dataset_model_checkpoint_name)\n",
    "\n",
    "merged_model = peft_ranking_reward_public_qanda_model.merge_and_unload()\n",
    "merged_model.save_pretrained(peft_ranking_reward_public_qanda_checkpoint)\n",
    "tokenizer.save_pretrained(peft_ranking_reward_public_qanda_checkpoint)  #    output_name + \"rl_reward_model\")??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef704c71-b0e2-43c5-96b2-d624036c8ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'peft_ranking_reward_public_qanda_checkpoint' (str)\n"
     ]
    }
   ],
   "source": [
    "%store peft_ranking_reward_public_qanda_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b0a492-89da-485b-ad07-09a446212c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_ranking_reward_public_qanda_model = AutoModelForSequenceClassification.from_pretrained(peft_ranking_reward_public_qanda_checkpoint, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaf3f6df-6ac7-4f4e-b010-ea260701233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_ranking_reward_public_qanda_checkpoint)\n",
    "\n",
    "peft_ranking_reward_public_qanda_pipeline = pipeline(\"text-classification\", tokenizer=tokenizer, model=peft_ranking_reward_public_qanda_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "576964d9-e8ed-4770-bb4d-91bd1659203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5686056017875671}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'Who was not the President of the United States in 2010?'\n",
    "answer = 'Barack Obama'\n",
    "prompt_and_answer = \"Question: \" + question + \"\\n\\nAnswer: \" + answer + \"\\n\"\n",
    "peft_ranking_reward_public_qanda_pipeline.predict(prompt_and_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cf621-045f-45d8-9f5e-ca4013765b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
