{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308a0e04-6066-4405-8a13-8b060e552a8a",
   "metadata": {},
   "source": [
    "# Continued Pre-Training with Amazon Bedrock\n",
    "\n",
    "#### GitHub repo\n",
    "https://github.com/generative-ai-on-aws/generative-ai-on-aws\n",
    "\n",
    "![](images/github.png)\n",
    "\n",
    "_Note: This notebook was tested in Amazon SageMaker Studio with Python 3 (Data Science 3.0) kernel with the ml.t3.medium kernel._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc4ad9-f418-4625-8f31-63893778c790",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4698dba-bed6-4e8a-a3f9-711f5225a704",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "### 2. Test the base model\n",
    "### 3. Prepare the dataset for continued pre-training\n",
    "### 4. Upload the dataset to S3\n",
    "### 5. Customize the model with continued pre-training\n",
    "### 6. Provision the custom model for inference\n",
    "### 7. Test the custom model\n",
    "### 8. Delete the provisioned model to save cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26768f-3775-436d-8b77-dee584420aff",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c5e24-b7c8-4932-b8d1-729ff52c6fb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015ca659-794d-45e4-b028-7b88449e989a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q -U --force-reinstall \\\n",
    "    boto3 \\\n",
    "    pandas==2.1.2 \\\n",
    "    langchain==0.0.324 \\\n",
    "    typing_extensions==4.7.1 \\\n",
    "    pypdf==3.16.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9faad051-1f1a-41e1-885e-27e185b259c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "from pprint import pprint\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 2)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ad566f-2a15-46ac-aeeb-346f9db0a10e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Amazon Bedrock control plane including fine-tuning\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "\n",
    "# Amazon Bedrock data plane including model inference\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e92ad3-5552-4c56-b0b6-c90286831c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_id = \"amazon.titan-text-express-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d7068-0239-4f58-908b-57e3b879a08c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Test the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992211af-b864-4e4c-b5d3-2e3931296c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Describe the book, 'Generative AI on AWS' by O'Reilly Media.\"\n",
    "\n",
    "body = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": [],\n",
    "        \"temperature\": 1,\n",
    "        \"topP\": 0.9\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df72e30-46f7-4edc-a39c-8bbfb403a226",
   "metadata": {},
   "source": [
    "![](images/gaia_cover_sm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d2e28-4ea1-49d5-a44e-dd239a30ed85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Amazon Titan Text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0333ed9a-b633-4b37-942b-0b735979722d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amazon Web Services (AWS) is at the forefront of machine learning (ML) and artificial intelligence (AI), and this book shows you how to leverage the power of AWS to create, train, and deploy generative AI (GAI) models.\n",
      "\n",
      "Written by AI and ML experts from AWS, this comprehensive guide provides a step-by-step roadmap for building, training, and deploying GAI models using AWS services such as Amazon SageMaker, Amazon Transcribe, and Amazon Rekognition.\n",
      "\n",
      "The book begins by introducing the basics of GAI and its applications in fields such as natural language processing, image generation, and speech recognition. It then provides an overview of AWS services that can be used to build, train, and deploy GAI models, including Amazon SageMaker, Amazon Transcribe, Amazon Rekognition, and Amazon Transcribe.\n",
      "\n",
      "Each chapter in the book focuses on a specific aspect of GAI and provides hands-on examples and code snippets that demonstrate how to use AWS services to build, train, and deploy GAI models. The book covers topics such as data preprocessing, model training, hyperparameter tuning, and model deployment, and provides best practices for optimizing the performance of GAI models.\n",
      "\n",
      "In addition to providing technical guidance, the book also includes case studies and real-world examples of GAI models that have been built and deployed using AWS services. These examples showcase the potential of GAI to solve real-world problems and improve business operations.\n",
      "\n",
      "Overall, \"Generative AI on AWS\" is a valuable resource for anyone interested in building, training, and deploying GAI models using AWS services. It provides a comprehensive and up-to-date introduction to GAI, and includes hands-on examples and code snippets that demonstrate how to use AWS services to build, train, and deploy GAI models. Whether you are a data scientist, machine learning engineer, or business professional, this book will help you gain a deeper understanding of GAI and its potential to transform your business.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=\"amazon.titan-text-express-v1\", # Amazon Titan Text model\n",
    "    body=json.dumps(body)\n",
    ")\n",
    "\n",
    "response_body = response[\"body\"].read().decode('utf8')\n",
    "print(json.loads(response_body)[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa6614-7080-4dbb-af08-cd67ce6a8706",
   "metadata": {},
   "source": [
    "# 3. Prepare the dataset for continued pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9, 
   "id": "707406e1-5dff-4791-8f5b-f44fa75fb5af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Generative AI  \\n on AWS\\nBuilding Context-Aware  \\nMultimodal Reasoning  \\nApplications\\nChris Fregly, \\nAntje Barth &  \\nShelbee Eigenbrode', metadata={'source': 'data/Generative_AI_on_AWS_OReilly.pdf', 'page': 0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/Generative_AI_on_AWS_OReilly.pdf\")\n",
    "document = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 20000, # 4096 token context window * 6 chars per token ~= 24,576 \n",
    "    chunk_overlap = 2000, # overlap for continuity across chunks\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(document)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876e79ea-fc92-4b6b-b427-f24de3b42e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = \"\"\n",
    "for doc in docs:\n",
    "    content = {\"input\": doc.page_content}\n",
    "    contents += (json.dumps(content) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e5b67b-b9e1-47a7-a96b-c4c1a292e301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./train-continual-pretraining.jsonl\", \"w\") as file:\n",
    "    file.writelines(contents)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3154fd6-ff69-49fb-9777-55c15015ed1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generative AI  \\n on AWS\\nBuilding Context-Aware  \\nMultimodal Reasoning  \\nApplications\\nChris Fregly, \\nAntje Barth &amp;  \\nShelbee Eigenbrode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA“I am very excited about \\nthis book —it has a great \\nmix of all-important \\nbackground/theoretical \\ninfo and detailed, \\nhands-on code, scripts, \\nand walk-throughs. I \\nenjoyed reading it, and  \\nI know that you will too!” \\n—Jeff Barr\\nVP and Chief Evangelist @ AWSGenerative AI on AWS\\nTwitter: @oreillymedia\\nlinkedin.com/company/oreilly-media\\nyoutube.com/oreillymedia Companies today are moving rapidly to integrate generative  \\nAI into their products and services. But there’s a great deal  \\nof hype (and misunderstanding) about the impact and \\npromise of this technology. With this book, Chris Fregly,  \\nAntje Barth, and Shelbee Eigenbrode from AWS help CTOs,  \\nML practitioners, application developers, business analysts, \\ndata engineers, and data scientists find practical ways to  \\nuse this exciting new technology.\\nYou’ll learn the generative AI project life cycle including  \\nuse case definition, model selection, model fine-tuning, \\nretrieval-augmented generation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Praise for Generative AI on AWS\\nI am very excited about this book—it has a great mix of all-important background/\\ntheoretical info and detailed, hands-on code, scripts, and walk-throughs. I enjoyed\\nreading it, and I know that you will too! Starting from the basics, you will learn about\\ngenerative foundation models, prompt engineering, and much more. From there you will\\nproceed to large language models (LLMs) and will see how to use them from within\\nAmazon SageMaker. After you master the basics, you will have the opportunity to learn\\nabout multiple types of fine-tuning, and then you will get to the heart of the book and\\nlearn to build applications that have the power to perform context-aware reasoning with\\ngenerative models of different modalities including text and images.\\n—Jeff Barr, VP and Chief Evangelist @ AWS\\nThis book is a comprehensive resource for building generative AI–based solutions\\non AWS. Using real-world examples, Chris, Antje, and Shelbee have done a\\nspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It’s very rare to find a book that comprehensively covers the full end-to-end process of\\nmodel development and deployment! If you’re an ML practitioner, this book is a must!\\n—Alejandro Herrera, Data Scientist @ Snowflake\\nThis book goes deep into how GenAI models are actually built and used. And it covers\\nthe whole life cycle, not just prompt engineering or tuning. If you’re thinking about using\\nGenAI for anything nontrivial, you should read this book to understand what skill sets\\nand tools you’ll need to be successful.\\n—Randy DeFauw, Sr. Principal Solution Architect @ AWS\\nThere’s no better book to get started with generative AI. With all the information\\non the internet about the topic, it’s extremely overwhelming for anyone. But this\\nbook is a clear and structured guide: it goes from the basics all the way to\\nadvanced topics like parameter-efficient fine-tuning and LLM deployment. It’s also\\nvery practical and covers deployment on AWS too. This book is an extremely\\nvalu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generative AI on AWS  provides an in-depth look at the innovative techniques for creating\\napplications that comprehend diverse data types and make context-driven decisions.\\nReaders get a comprehensive view, bridging both the theoretical aspects and practical\\ntools needed for generative AI applications. This book is a must-read for those wanting to\\nharness the full potential of AWS in the realm of generative AI.\\n—Kesha Williams, Director @ Slalom Consulting\\nand AWS Machine Learning Hero\\nThe generative AI landscape evolves so fast that it’s incredible to see so much relevant\\nknowledge condensed into a comprehensive book. Well done!\\n—Francesco Mosconi, Head of Data Science @ Catalit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>greedy versus random sampling, 30\\nmax new tokens, 30\\ntemperature, 33\\ntop-p and top-k random sampling, 31-32\\ninput_id as token in model’s vocabulary, 37\\nnumeric representations of each token,\\n37\\nscaling laws, 49-51\\ntokenizers, 37\\nembeddings, 38-40\\ntraining large-language foundation models\\nabout, 35\\ncompute-optimal models, 51\\nembeddings, 38-40\\nend-of-sequence (EOS) token, 45\\npretrained models publicly available, 36\\npretraining datasets, 48\\npretraining datasets optimal size, 51\\npublicly available, pretrained models’\\nvocabulary, 37\\nscaling laws, 49-51\\ntokenizers, 37\\nTransformer architecture, 40-45\\ntypes of Transformer-based foundation\\nmodels, 46-48\\ntoken_ids from tokenizer, 37\\ntop-p and top-k random sampling, 31-32\\ntoxic language detection\\nabout toxic language reduction, 122\\nexample model, 115\\nreward model by Meta, 123\\nreward model by Meta used to fine-tune,\\n123, 126-128\\nfine-tuning with RLHF, 124-131\\ntoxicity baseline compared to fine-tuned\\nmodel, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Transformers-NeuronX library, 145\\n“tricking” a model to learn incorrect answer, 23\\nTRL library, 127\\nPPOTrainer, 127\\nU\\nU-Net models, 223\\nunidirectional causal language modeling\\n(CLM), 47\\nunimodal models defined, 195\\nupdate and deployment strategies, 147\\nA/B testing, 148-149\\nshadow deployment, 149\\nupscaling in image generation, 203\\nuse cases and tasks for generative AI, 1-4\\nV\\nvector stores\\nabout, 168, 254\\nAWS generative AI, 9\\nRAG document search and retrieval, 9, 161,\\n167\\nexample with FAISS and LangChain,\\n168-171\\nvector embedding storage options, 168\\nsupported by LangChain, 169vectors (see embedding vectors or “embed‐\\ndings”)\\nvirtual tokens as soft prompts, 106\\ngenerating virtual tokens, 107\\nvisual language models (VLMs), 209\\n(see also multimodal large language models)\\nvisual question answering (VQA), 211-216\\nevaluating, 219\\nVizWiz-VQA dataset, 219\\nVQAv2 dataset, 219\\nW\\nweights (see parameters)\\nWiki-40B as a pretraining dataset, 49\\nWikipedia as a pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>About the Authors\\nChris Fregly  is a Principal Solutions Architect for generative AI at Amazon Web\\nServices based in San Francisco, California. Chris holds every AWS certification. He\\nis also cofounder of the global Generative AI on AWS Meetup. Chris regularly speaks\\nat AI and machine learning meetups and conferences across the world. Previously,\\nChris was an engineer at Databricks and Netflix, where he worked on scalable big\\ndata and machine learning products and solutions. He is also coauthor of the O’Reilly\\nbook Data Science on AWS .\\nAntje Barth  is a Principal Developer Advocate for generative AI at Amazon Web\\nServices based in San Francisco, California. She is also cofounder of the global Gener‐\\native AI on AWS Meetup and the Düsseldorf chapter of Women in Big Data. Antje\\nfrequently speaks at AI and machine learning conferences and meetups around the\\nworld. Prior to joining AWS, Antje worked in solutions engineering roles at MapR\\nand Cisco, helping developers leve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>with their ability to create novel song patterns—to the great classical composers and\\nmodern artists like Kendrick Lamar.\\nThough its population size has not been precisely quantified, the brown-backed\\nmockingbird has been categorized by the IUCN as a species of least concern. Many\\nof the animals on O’Reilly covers are endangered; all of them are important to the\\nworld.\\nThe cover illustration is by Karen Montgomery, based on an antique line engraving\\nfrom Cassell’s Natural History . The cover fonts are Gilroy Semibold and Guardian\\nSans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad Con‐\\ndensed; and the code font is Dalton Maag’s Ubuntu Mono.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Learn from experts.  \\nBecome one yourself.\\nBooks | Live online courses   \\nInstant answers | Virtual events  \\nVideos | Interactive learning\\nGet started at oreilly.com.  \\n©2023 O’Reilly Media, Inc. O’Reilly is a registered trademark of O’Reilly Media, Inc.  175  7x9.1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       input\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Generative AI  \\n on AWS\\nBuilding Context-Aware  \\nMultimodal Reasoning  \\nApplications\\nChris Fregly, \\nAntje Barth &  \\nShelbee Eigenbrode\n",
       "1    DATA“I am very excited about \\nthis book —it has a great \\nmix of all-important \\nbackground/theoretical \\ninfo and detailed, \\nhands-on code, scripts, \\nand walk-throughs. I \\nenjoyed reading it, and  \\nI know that you will too!” \\n—Jeff Barr\\nVP and Chief Evangelist @ AWSGenerative AI on AWS\\nTwitter: @oreillymedia\\nlinkedin.com/company/oreilly-media\\nyoutube.com/oreillymedia Companies today are moving rapidly to integrate generative  \\nAI into their products and services. But there’s a great deal  \\nof hype (and misunderstanding) about the impact and \\npromise of this technology. With this book, Chris Fregly,  \\nAntje Barth, and Shelbee Eigenbrode from AWS help CTOs,  \\nML practitioners, application developers, business analysts, \\ndata engineers, and data scientists find practical ways to  \\nuse this exciting new technology.\\nYou’ll learn the generative AI project life cycle including  \\nuse case definition, model selection, model fine-tuning, \\nretrieval-augmented generation, ...\n",
       "2    Praise for Generative AI on AWS\\nI am very excited about this book—it has a great mix of all-important background/\\ntheoretical info and detailed, hands-on code, scripts, and walk-throughs. I enjoyed\\nreading it, and I know that you will too! Starting from the basics, you will learn about\\ngenerative foundation models, prompt engineering, and much more. From there you will\\nproceed to large language models (LLMs) and will see how to use them from within\\nAmazon SageMaker. After you master the basics, you will have the opportunity to learn\\nabout multiple types of fine-tuning, and then you will get to the heart of the book and\\nlearn to build applications that have the power to perform context-aware reasoning with\\ngenerative models of different modalities including text and images.\\n—Jeff Barr, VP and Chief Evangelist @ AWS\\nThis book is a comprehensive resource for building generative AI–based solutions\\non AWS. Using real-world examples, Chris, Antje, and Shelbee have done a\\nspe...\n",
       "3    It’s very rare to find a book that comprehensively covers the full end-to-end process of\\nmodel development and deployment! If you’re an ML practitioner, this book is a must!\\n—Alejandro Herrera, Data Scientist @ Snowflake\\nThis book goes deep into how GenAI models are actually built and used. And it covers\\nthe whole life cycle, not just prompt engineering or tuning. If you’re thinking about using\\nGenAI for anything nontrivial, you should read this book to understand what skill sets\\nand tools you’ll need to be successful.\\n—Randy DeFauw, Sr. Principal Solution Architect @ AWS\\nThere’s no better book to get started with generative AI. With all the information\\non the internet about the topic, it’s extremely overwhelming for anyone. But this\\nbook is a clear and structured guide: it goes from the basics all the way to\\nadvanced topics like parameter-efficient fine-tuning and LLM deployment. It’s also\\nvery practical and covers deployment on AWS too. This book is an extremely\\nvalu...\n",
       "4                                                                                                                                                                                                                                                                                                                  Generative AI on AWS  provides an in-depth look at the innovative techniques for creating\\napplications that comprehend diverse data types and make context-driven decisions.\\nReaders get a comprehensive view, bridging both the theoretical aspects and practical\\ntools needed for generative AI applications. This book is a must-read for those wanting to\\nharness the full potential of AWS in the realm of generative AI.\\n—Kesha Williams, Director @ Slalom Consulting\\nand AWS Machine Learning Hero\\nThe generative AI landscape evolves so fast that it’s incredible to see so much relevant\\nknowledge condensed into a comprehensive book. Well done!\\n—Francesco Mosconi, Head of Data Science @ Catalit\n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...\n",
       "300  greedy versus random sampling, 30\\nmax new tokens, 30\\ntemperature, 33\\ntop-p and top-k random sampling, 31-32\\ninput_id as token in model’s vocabulary, 37\\nnumeric representations of each token,\\n37\\nscaling laws, 49-51\\ntokenizers, 37\\nembeddings, 38-40\\ntraining large-language foundation models\\nabout, 35\\ncompute-optimal models, 51\\nembeddings, 38-40\\nend-of-sequence (EOS) token, 45\\npretrained models publicly available, 36\\npretraining datasets, 48\\npretraining datasets optimal size, 51\\npublicly available, pretrained models’\\nvocabulary, 37\\nscaling laws, 49-51\\ntokenizers, 37\\nTransformer architecture, 40-45\\ntypes of Transformer-based foundation\\nmodels, 46-48\\ntoken_ids from tokenizer, 37\\ntop-p and top-k random sampling, 31-32\\ntoxic language detection\\nabout toxic language reduction, 122\\nexample model, 115\\nreward model by Meta, 123\\nreward model by Meta used to fine-tune,\\n123, 126-128\\nfine-tuning with RLHF, 124-131\\ntoxicity baseline compared to fine-tuned\\nmodel, 13...\n",
       "301  Transformers-NeuronX library, 145\\n“tricking” a model to learn incorrect answer, 23\\nTRL library, 127\\nPPOTrainer, 127\\nU\\nU-Net models, 223\\nunidirectional causal language modeling\\n(CLM), 47\\nunimodal models defined, 195\\nupdate and deployment strategies, 147\\nA/B testing, 148-149\\nshadow deployment, 149\\nupscaling in image generation, 203\\nuse cases and tasks for generative AI, 1-4\\nV\\nvector stores\\nabout, 168, 254\\nAWS generative AI, 9\\nRAG document search and retrieval, 9, 161,\\n167\\nexample with FAISS and LangChain,\\n168-171\\nvector embedding storage options, 168\\nsupported by LangChain, 169vectors (see embedding vectors or “embed‐\\ndings”)\\nvirtual tokens as soft prompts, 106\\ngenerating virtual tokens, 107\\nvisual language models (VLMs), 209\\n(see also multimodal large language models)\\nvisual question answering (VQA), 211-216\\nevaluating, 219\\nVizWiz-VQA dataset, 219\\nVQAv2 dataset, 219\\nW\\nweights (see parameters)\\nWiki-40B as a pretraining dataset, 49\\nWikipedia as a pr...\n",
       "302  About the Authors\\nChris Fregly  is a Principal Solutions Architect for generative AI at Amazon Web\\nServices based in San Francisco, California. Chris holds every AWS certification. He\\nis also cofounder of the global Generative AI on AWS Meetup. Chris regularly speaks\\nat AI and machine learning meetups and conferences across the world. Previously,\\nChris was an engineer at Databricks and Netflix, where he worked on scalable big\\ndata and machine learning products and solutions. He is also coauthor of the O’Reilly\\nbook Data Science on AWS .\\nAntje Barth  is a Principal Developer Advocate for generative AI at Amazon Web\\nServices based in San Francisco, California. She is also cofounder of the global Gener‐\\native AI on AWS Meetup and the Düsseldorf chapter of Women in Big Data. Antje\\nfrequently speaks at AI and machine learning conferences and meetups around the\\nworld. Prior to joining AWS, Antje worked in solutions engineering roles at MapR\\nand Cisco, helping developers leve...\n",
       "303                                                                                                                                                                                                                                                                                                                                  with their ability to create novel song patterns—to the great classical composers and\\nmodern artists like Kendrick Lamar.\\nThough its population size has not been precisely quantified, the brown-backed\\nmockingbird has been categorized by the IUCN as a species of least concern. Many\\nof the animals on O’Reilly covers are endangered; all of them are important to the\\nworld.\\nThe cover illustration is by Karen Montgomery, based on an antique line engraving\\nfrom Cassell’s Natural History . The cover fonts are Gilroy Semibold and Guardian\\nSans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad Con‐\\ndensed; and the code font is Dalton Maag’s Ubuntu Mono.\n",
       "304                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Learn from experts.  \\nBecome one yourself.\\nBooks | Live online courses   \\nInstant answers | Virtual events  \\nVideos | Interactive learning\\nGet started at oreilly.com.  \\n©2023 O’Reilly Media, Inc. O’Reilly is a registered trademark of O’Reilly Media, Inc.  175  7x9.1975\n",
       "\n",
       "[305 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"./train-continual-pretraining.jsonl\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "215843b6-9c4e-4c82-b3c1-c8cc99d01488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"./train-continual-pretraining.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546f2e9-000b-4c87-807e-2a63554bcc8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Upload dataset to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91c8bc-cb24-4b04-8de8-25c03c3490df",
   "metadata": {},
   "source": [
    "Next, we need to upload our training dataset to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e9547f-127d-444e-89ed-6403781c83a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "s3_location = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/train-continual-pretraining.jsonl\"\n",
    "s3_output = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb873b6-c50b-46fb-bd1f-a050bf523221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./train-continual-pretraining.jsonl to s3://sagemaker-us-east-1-079002598131/bedrock/finetuning/train-continual-pretraining.jsonl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp train-continual-pretraining.jsonl $s3_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04f82b-a918-4226-bf88-3ce567e50bcc",
   "metadata": {},
   "source": [
    "# 5. Customize the model with continued pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "093e54cf-f0f3-403f-8ef5-84e0cbb40d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom-titan-1701126158'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = int(time.time())\n",
    "\n",
    "job_name = \"titan-{}\".format(timestamp)\n",
    "job_name\n",
    "\n",
    "custom_model_name = \"custom-{}\".format(job_name)\n",
    "custom_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f0ead8-31d2-4146-82c8-2d4d5fa07397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.create_model_customization_job(\n",
    "    customizationType=\"CONTINUED_PRE_TRAINING\",\n",
    "    jobName=job_name,\n",
    "    customModelName=custom_model_name,\n",
    "    roleArn=role,\n",
    "    baseModelIdentifier=base_model_id,\n",
    "    hyperParameters = {\n",
    "        \"epochCount\": \"10\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \"0.000001\"\n",
    "    },\n",
    "    trainingDataConfig={\"s3Uri\": s3_location},\n",
    "    outputDataConfig={\"s3Uri\": s3_output},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f87f790-8ee0-4485-b090-1be7af0f0554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "\n",
    "while status == \"InProgress\":\n",
    "    print(status)\n",
    "    time.sleep(300)\n",
    "    status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "    \n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19c92bc6-e3ed-4afa-a47f-89221b5be6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/bedrock/home?region=us-east-1#/custom-models/item?arn=arn:aws:bedrock:us-east-1:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/4re5mqt0anzp\">Custom Model</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_model_arn = bedrock.get_custom_model(modelIdentifier=custom_model_name)['modelArn']\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/bedrock/home?region={}#/custom-models/item?arn={}\">Custom Model</a></b>'.format(\n",
    "            region, custom_model_arn\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b47ec7-9933-45d1-9ad6-67be8fb318f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6. Provision the custom model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd028a6c-f13b-4d58-9b4f-ce8a18aecd66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provisioned_model_name = \"{}-provisioned\".format(custom_model_name)\n",
    "\n",
    "base_model_arn = bedrock.get_custom_model(modelIdentifier=custom_model_name)['baseModelArn']\n",
    "\n",
    "# Must do this manually through the console.  \n",
    "# Use the value of \"provisioned_model_name\" for continuity.\n",
    "#\n",
    "# bedrock.create_provisioned_model_throughput(\n",
    "#     modelUnits = 1,\n",
    "#     provisionedModelName = provisioned_model_name,\n",
    "#     modelId = base_model_arn\n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b22987e2-82fe-4550-9ecd-d13004f0919f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n"
     ]
    }
   ],
   "source": [
    "deployment_status = bedrock.get_provisioned_model_throughput(\n",
    "    provisionedModelId=provisioned_model_name)[\"status\"]\n",
    "\n",
    "while deployment_status == \"Creating\":    \n",
    "    print(deployment_status)\n",
    "    time.sleep(120)\n",
    "    deployment_status = bedrock.get_provisioned_model_throughput(\n",
    "        provisionedModelId=provisioned_model_name)[\"status\"]  \n",
    "    \n",
    "print(deployment_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a0f3ab7-4b78-4201-b5a5-f635890ee80e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/bedrock/home?region=us-east-1#/provisioned-throughput/details?arn=arn:aws:bedrock:us-east-1:079002598131:provisioned-model/u6pq53vof8jh\">Custom Model Inference</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "provisioned_model_arn = bedrock.get_provisioned_model_throughput(\n",
    "     provisionedModelId=provisioned_model_name)[\"provisionedModelArn\"]\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/bedrock/home?region={}#/provisioned-throughput/details?arn={}\">Custom Model Inference</a></b>'.format(\n",
    "            region, provisioned_model_arn\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364ddd6-8ad2-47c8-90b3-e518be36a329",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. Test the custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b590c35-bd5a-469d-871e-cece7fa812c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Describe the book, 'Generative AI on AWS' by O'Reilly Media.\"\n",
    "\n",
    "body = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": [],\n",
    "        \"temperature\": 1,\n",
    "        \"topP\": 0.9\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8525d6e-3499-4cf8-b165-0f02fa13bfdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Amazon Titan Text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0157c469-4bec-4816-8604-0ff43a459783",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amazon Web Services (AWS) is at the forefront of machine learning (ML) and artificial intelligence (AI), and this book shows you how to leverage the power of AWS to create, train, and deploy generative AI (GAI) models.\n",
      "\n",
      "Written by AI and ML experts from AWS, this comprehensive guide provides a step-by-step roadmap for building, training, and deploying GAI models using AWS services such as Amazon SageMaker, Amazon Transcribe, and Amazon Rekognition.\n",
      "\n",
      "The book begins by introducing the basics of GAI and its applications in fields such as natural language processing, image generation, and speech recognition. It then provides an overview of AWS services that can be used to build, train, and deploy GAI models, including Amazon SageMaker, Amazon Transcribe, Amazon Rekognition, and Amazon Transcribe.\n",
      "\n",
      "Each chapter in the book focuses on a specific aspect of GAI and provides hands-on examples and code snippets that demonstrate how to use AWS services to build, train, and deploy GAI models. The book covers topics such as data preprocessing, model training, hyperparameter tuning, and model deployment, and provides best practices for optimizing the performance of GAI models.\n",
      "\n",
      "In addition to providing technical guidance, the book also includes case studies and real-world examples of GAI models that have been built and deployed using AWS services. These examples showcase the potential of GAI to solve real-world problems and improve business operations.\n",
      "\n",
      "Overall, \"Generative AI on AWS\" is a valuable resource for anyone interested in building, training, and deploying GAI models using AWS services. It provides a comprehensive and up-to-date introduction to GAI, and includes hands-on examples and code snippets that demonstrate how to use AWS services to build, train, and deploy GAI models. Whether you are a data scientist, machine learning engineer, or business professional, this book will help you gain a deeper understanding of GAI and its potential to transform your business.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=\"amazon.titan-text-express-v1\", # Amazon Titan Text model\n",
    "    body=json.dumps(body)\n",
    ")\n",
    "\n",
    "response_body = response[\"body\"].read().decode('utf8')\n",
    "print(json.loads(response_body)[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d9b06-040c-4e3f-b93f-ef47c0ce3ee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Our custom pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad9e38e1-59a1-4e71-b713-d8552903deab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The book is a thorough introduction to the most advanced generative AI techniques and platforms available, including Amazon Bedrock, for building and deploying useful generative AI applications. The book is targeted at technical professionals who want to learn and deploy AI to real-world applications, providing in-depth explanations of generative AI concepts, methodologies, and frameworks using Python code examples.\n",
      "Generative AI on AWS is organized into three parts:\n",
      "1. Data and Data Preparation: This section provides an introduction to the importance of high-quality data for generative AI applications, including how to evaluate and prepare datasets for training and inference. It covers text data, image data, audio data, and video data, as well as common data preparation techniques such as data augmentation and tokenization.\n",
      "2. Build, Train, and Evaluate Generative Models: This section covers the core concepts of generative AI, including supervised, semi-supervised, and reinforcement learning models. It also provides an in-depth guide to using Amazon SageMaker to build and train generative models using state-of-the-art infrastructure and leading-edge algorithms. The section covers commonly used deep learning architectures such as Transformers, BERT, GPT-3, and XLNet, as well as generative adversarial networks (GANs) and multimodal models for image and video generation.\n",
      "3. Deploy, Monitor, and Optimize Generative Models: This section covers the core concepts of deploying generative AI models for inference, including serverless infrastructure, batch inference, and real-time inference. It also provides an in-depth guide to using Amazon Bedrock to deploy and monitor generative models in production, including integrating with popular chatbots and voice assistants.\n",
      "Overall, Generative AI on AWS is a comprehensive and detailed guide to building and deploying generative AI applications using Amazon Bedrock and AWS services. It is well-written and easy to follow, with plenty of code examples and reference materials to help readers get started quickly. I highly recommend this book to anyone interested in learning and deploying generative AI applications using AWS.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=provisioned_model_arn, # custom pre-trained model\n",
    "    body=json.dumps(body)\n",
    ")\n",
    "\n",
    "response_body = response[\"body\"].read().decode('utf8')\n",
    "print(json.loads(response_body)[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f62c91-c793-439d-b3b4-66f6eb0b0c1b",
   "metadata": {},
   "source": [
    "# 8. Delete provisioned model to save cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ad633b8-db9c-43a9-b2ab-b39bc7b3ee97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.delete_provisioned_model_throughput(\n",
    "    provisionedModelId = provisioned_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c268ef-0b67-4bd1-bc91-94c283497aa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GitHub repo\n",
    "https://github.com/generative-ai-on-aws/generative-ai-on-aws\n",
    "\n",
    "![](images/github.png)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "forced_instance_type": "ml.t3.medium",
  "forced_lcc_arn": "",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
