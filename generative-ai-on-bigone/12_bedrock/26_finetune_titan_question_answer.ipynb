{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308a0e04-6066-4405-8a13-8b060e552a8a",
   "metadata": {},
   "source": [
    "# Introduction to Bedrock - Fine-Tuning\n",
    "\n",
    "> *If you see errors, you may need to be allow-listed for the Bedrock models used by this notebook*\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9a3e6-4d64-4da4-8a85-d5c12ae70978",
   "metadata": {},
   "source": [
    "In this demo notebook, we demonstrate how to use the Bedrock Python SDK for fine-tuning Bedrock models with your own data. If you have text samples to train and want to adapt the Bedrock models to your domain, you can further fine-tune the Bedrock foundation models by providing your own training datasets. You can upload your datasets to Amazon S3, and provide the S3 bucket path while configuring a Bedrock fine-tuning job. You can also adjust hyper parameters (learning rate, epoch, and batch size) for fine-tuning. After the fine-tuning job of the model with your dataset has completed, you can start using the model for inference in the Bedrock playground application. You can select the fine-tuned model and submit a prompt to the fine-tuned model along with a set of model parameters. The fine-tuned model should generate texts to be more alike your text samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26768f-3775-436d-8b77-dee584420aff",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a0821c-2d18-4698-8efc-df81030bcdc8",
   "metadata": {},
   "source": [
    "1. Setup\n",
    "2. Fine-tuning\n",
    "3. Testing the fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889b27f-7d55-4c07-81fc-3f00d55e5544",
   "metadata": {},
   "source": [
    " Note: This notebook was tested in Amazon SageMaker Studio with Python 3 (Data Science 2.0) kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bb89f-2b60-41e4-8ea7-8cace718bed5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c5e24-b7c8-4932-b8d1-729ff52c6fb1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ddbd728-aa90-4431-9b1c-9dc2f9214140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pandas==2.1.2\n",
      "  Obtaining dependency information for pandas==2.1.2 from https://files.pythonhosted.org/packages/02/52/815f643ed3afb3365354548b3c8b557dbf926a65c40ad5b6d9e455147c7e/pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from pandas==2.1.2)\n",
      "  Obtaining dependency information for numpy<2,>=1.22.4 from https://files.pythonhosted.org/packages/64/41/284783f1014685201e447ea976e85fed0e351f5debbaf3ee6d7645521f1d/numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m243.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas==2.1.2)\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m221.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1 (from pandas==2.1.2)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.1.2)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m243.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.1.2)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m227.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m202.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m349.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2023.3.post1\n",
      "    Uninstalling pytz-2023.3.post1:\n",
      "      Successfully uninstalled pytz-2023.3.post1\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2023.3\n",
      "    Uninstalling tzdata-2023.3:\n",
      "      Successfully uninstalled tzdata-2023.3\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.2\n",
      "    Uninstalling numpy-1.26.2:\n",
      "      Successfully uninstalled numpy-1.26.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.2\n",
      "    Uninstalling pandas-2.1.2:\n",
      "      Successfully uninstalled pandas-2.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "apache-beam 2.50.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\n",
      "apache-beam 2.50.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.2 which is incompatible.\n",
      "apache-beam 2.50.0 requires pyarrow<12.0.0,>=3.0.0, but you have pyarrow 14.0.1 which is incompatible.\n",
      "autovizwidget 0.21.0 requires pandas<2.0.0,>=0.20.1, but you have pandas 2.1.2 which is incompatible.\n",
      "botocore 1.32.6 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.1.0 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.2 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "llama-index 0.8.37 requires urllib3<2, but you have urllib3 2.1.0 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.2 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.2 pandas-2.1.2 python-dateutil-2.8.2 pytz-2023.3.post1 six-1.16.0 tzdata-2023.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U --force-reinstall pandas==2.1.2 datasets==2.14.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d966521-f63a-4c96-8494-68d6d2367938",
   "metadata": {},
   "source": [
    "#### Now let's set up our connection to the Amazon Bedrock SDK using Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785b3b10-2c66-4adc-a4ac-747c214fd9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Un comment the following lines to run from your local environment outside of the AWS account with Bedrock access\n",
    "\n",
    "#import os\n",
    "#os.environ['BEDROCK_ASSUME_ROLE'] = '<YOUR_VALUES>'\n",
    "#os.environ['AWS_PROFILE'] = '<YOUR_VALUES>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ad566f-2a15-46ac-aeeb-346f9db0a10e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json \n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48703d82-bb32-44fa-916e-6cc5040a67cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98cc7d90-d46b-41af-91f8-62da07f7bb41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "modelArn: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k\n",
      "modelId: amazon.titan-text-lite-v1:0:4k\n",
      "modelName: Titan Text G1 - Lite\n",
      "customizationsSupported: FINE_TUNING\n",
      "-----\n",
      "modelArn: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k\n",
      "modelId: amazon.titan-text-express-v1:0:8k\n",
      "modelName: Titan Text G1 - Express\n",
      "customizationsSupported: FINE_TUNING\n"
     ]
    }
   ],
   "source": [
    "for model in bedrock.list_foundation_models(byProvider=\"amazon\", byCustomizationType=\"FINE_TUNING\")[\"modelSummaries\"]:\n",
    "    print(\"-----\\n\" + \"modelArn: \" + model[\"modelArn\"] + \"\\nmodelId: \" + model[\"modelId\"] + \"\\nmodelName: \" + model[\"modelName\"] + \"\\ncustomizationsSupported: \" + ','.join(model[\"customizationsSupported\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c1fa8-657c-4e45-94e8-e907857d145a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Invoke Model before Fine-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1684e7-8b0f-436d-a8a0-2a2b45ffe387",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"amazon.titan-text-express-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa6614-7080-4dbb-af08-cd67ce6a8706",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert the dataset into jsonlines format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f96f947-e885-48a1-8530-b70b8fefc073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"gaia_questions_answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e80dee-a17d-4e46-9b6d-f5e1b7a1a81a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 110\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cef0311-b45f-481b-bdbe-a14d4baa1359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wrap_instruction_fn(example):\n",
    "    prompt = 'Answer the following question:\\n\\n'\n",
    "    end_prompt = '\\n\\nAnswer: '\n",
    "    example[\"instruction\"] = prompt + example[\"question\"] + end_prompt\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e94a8473-2226-4f0e-9890-03635534156b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eb190a0af04a8bbae8195759ec2201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1de6c468ca416eacc71c58d7293cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3517"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']\\\n",
    "  .filter(lambda example: example['question'] and example['answer'])\\\n",
    "  .select(range(10))\\\n",
    "  .select_columns(['question', 'answer'])\\\n",
    "  .map(wrap_instruction_fn)\\\n",
    "  .rename_column('instruction', 'prompt')\\\n",
    "  .rename_column('answer', 'completion')\\\n",
    "  .remove_columns(['question'])\\\n",
    "  .to_json('./train-question-answer.jsonl', index=False)\n",
    "\n",
    "# dataset['validation']\\\n",
    "#   .filter(lambda example: example['question'])\\\n",
    "#   .select_columns(['question', 'answer'])\\\n",
    "#   .map(wrap_instruction_fn)\\\n",
    "#   .rename_column('instruction', 'input')\\\n",
    "#   .rename_column('answer', 'output')\\\n",
    "#   .to_json('./validation-summarization.jsonl', index=False)\n",
    "\n",
    "# dataset['test']\\\n",
    "#   .filter(lambda example: example['question'])\\\n",
    "#   .select_columns(['question', 'answer'])\\\n",
    "#   .map(wrap_instruction_fn)\\\n",
    "#   .rename_column('instruction', 'input')\\\n",
    "#   .rename_column('answer', 'output')\\\n",
    "#   .to_json('./test-summarization.jsonl', index=False)\n",
    "\n",
    "#  .remove_columns(['Unnamed: 0.1', 'Unnamed: 0', 'question_id', 'title', 'answer_id', 'expertreviewed', 'upvotedcount', 'tags'])\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c60adba-f766-47ac-8bac-95f6fed26028",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>completion</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intelligent search, automated customer-support...</td>\n",
       "      <td>Answer the following question:\\n\\nWhat are som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foundation models are large and complex neural...</td>\n",
       "      <td>Answer the following question:\\n\\nHow are foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The generative AI project life cycle, though n...</td>\n",
       "      <td>Answer the following question:\\n\\nCan you desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWS offers a range of frameworks and infrastru...</td>\n",
       "      <td>Answer the following question:\\n\\nWhat makes A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWS offers increased flexibility, choice, ente...</td>\n",
       "      <td>Answer the following question:\\n\\nHow does Gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Building generative AI applications on AWS inv...</td>\n",
       "      <td>Answer the following question:\\n\\nWhat are the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The project life cycle includes stages like de...</td>\n",
       "      <td>Answer the following question:\\n\\nHow do proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AWS's provision of multiple components for bui...</td>\n",
       "      <td>Answer the following question:\\n\\nHow does AWS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Foundation models are significant in AWS for g...</td>\n",
       "      <td>Answer the following question:\\n\\nWhat is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prompts in Generative AI involve text-based in...</td>\n",
       "      <td>Answer the following question:\\n\\nHow do promp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          completion  \\\n",
       "0  Intelligent search, automated customer-support...   \n",
       "1  Foundation models are large and complex neural...   \n",
       "2  The generative AI project life cycle, though n...   \n",
       "3  AWS offers a range of frameworks and infrastru...   \n",
       "4  AWS offers increased flexibility, choice, ente...   \n",
       "5  Building generative AI applications on AWS inv...   \n",
       "6  The project life cycle includes stages like de...   \n",
       "7  AWS's provision of multiple components for bui...   \n",
       "8  Foundation models are significant in AWS for g...   \n",
       "9  Prompts in Generative AI involve text-based in...   \n",
       "\n",
       "                                              prompt  \n",
       "0  Answer the following question:\\n\\nWhat are som...  \n",
       "1  Answer the following question:\\n\\nHow are foun...  \n",
       "2  Answer the following question:\\n\\nCan you desc...  \n",
       "3  Answer the following question:\\n\\nWhat makes A...  \n",
       "4  Answer the following question:\\n\\nHow does Gen...  \n",
       "5  Answer the following question:\\n\\nWhat are the...  \n",
       "6  Answer the following question:\\n\\nHow do proje...  \n",
       "7  Answer the following question:\\n\\nHow does AWS...  \n",
       "8  Answer the following question:\\n\\nWhat is the ...  \n",
       "9  Answer the following question:\\n\\nHow do promp...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"./train-question-answer.jsonl\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "215843b6-9c4e-4c82-b3c1-c8cc99d01488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"./train-question-answer.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de721f4-3f65-4aa4-84ce-19f7a7c47778",
   "metadata": {},
   "source": [
    "Read the JSON line file into an object like any normal file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa423f6-7827-45fc-bd49-39c1b6f9759a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(data) as f:\n",
    "    lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c2ea85-a95b-4cfb-9463-692b9a642897",
   "metadata": {},
   "source": [
    "#### Load the ‘lines’ object into a pandas Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7da61e9b-ac1f-4f69-8cb6-b525a737cba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_inter = pd.DataFrame(lines)\n",
    "df_inter.columns = ['json_element']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf4879-a796-4359-ba80-f7a54dc05cd6",
   "metadata": {},
   "source": [
    "This intermediate data frame will have only one column with each json object in a row. A sample output is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75a8528c-d478-48a9-acef-ac135b3090d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'completion': 'Intelligent search, automated ...\n",
       "1    {'completion': 'Foundation models are large an...\n",
       "2    {'completion': 'The generative AI project life...\n",
       "3    {'completion': 'AWS offers a range of framewor...\n",
       "4    {'completion': 'AWS offers increased flexibili...\n",
       "5    {'completion': 'Building generative AI applica...\n",
       "6    {'completion': 'The project life cycle include...\n",
       "7    {'completion': 'AWS's provision of multiple co...\n",
       "8    {'completion': 'Foundation models are signific...\n",
       "9    {'completion': 'Prompts in Generative AI invol...\n",
       "Name: json_element, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter['json_element'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc711d5-6522-47be-b4b6-fe292d70e6e8",
   "metadata": {},
   "source": [
    "Now we will apply json loads function on each row of the ‘json_element’ column. ‘json.loads’ is a decoder function in python which is used to decode a json object into a dictionary. ‘apply’ is a popular function in pandas that takes any function and applies to each row of the pandas dataframe or series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "600eac79-5830-4422-a39a-19b6770827a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2430c-c36f-43a7-8ce6-e17b0efdbd20",
   "metadata": {},
   "source": [
    "Once decoding is done we will apply the json normalize function to the above result. json normalize will convert any semi-structured json data into a flat table. Here it converts the JSON ‘keys’ to columns and its corresponding values to row elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2061f7a-eb1a-4089-96c1-7bfc8dd3d741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>completion</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intelligent search, automated customer-support...</td>\n",
       "      <td>Answer the following question:\\n\\nWhat are som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foundation models are large and complex neural...</td>\n",
       "      <td>Answer the following question:\\n\\nHow are foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The generative AI project life cycle, though n...</td>\n",
       "      <td>Answer the following question:\\n\\nCan you desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWS offers a range of frameworks and infrastru...</td>\n",
       "      <td>Answer the following question:\\n\\nWhat makes A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWS offers increased flexibility, choice, ente...</td>\n",
       "      <td>Answer the following question:\\n\\nHow does Gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Building generative AI applications on AWS inv...</td>\n",
       "      <td>Answer the following question:\\n\\nWhat are the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The project life cycle includes stages like de...</td>\n",
       "      <td>Answer the following question:\\n\\nHow do proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AWS's provision of multiple components for bui...</td>\n",
       "      <td>Answer the following question:\\n\\nHow does AWS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Foundation models are significant in AWS for g...</td>\n",
       "      <td>Answer the following question:\\n\\nWhat is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prompts in Generative AI involve text-based in...</td>\n",
       "      <td>Answer the following question:\\n\\nHow do promp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          completion  \\\n",
       "0  Intelligent search, automated customer-support...   \n",
       "1  Foundation models are large and complex neural...   \n",
       "2  The generative AI project life cycle, though n...   \n",
       "3  AWS offers a range of frameworks and infrastru...   \n",
       "4  AWS offers increased flexibility, choice, ente...   \n",
       "5  Building generative AI applications on AWS inv...   \n",
       "6  The project life cycle includes stages like de...   \n",
       "7  AWS's provision of multiple components for bui...   \n",
       "8  Foundation models are significant in AWS for g...   \n",
       "9  Prompts in Generative AI involve text-based in...   \n",
       "\n",
       "                                              prompt  \n",
       "0  Answer the following question:\\n\\nWhat are som...  \n",
       "1  Answer the following question:\\n\\nHow are foun...  \n",
       "2  Answer the following question:\\n\\nCan you desc...  \n",
       "3  Answer the following question:\\n\\nWhat makes A...  \n",
       "4  Answer the following question:\\n\\nHow does Gen...  \n",
       "5  Answer the following question:\\n\\nWhat are the...  \n",
       "6  Answer the following question:\\n\\nHow do proje...  \n",
       "7  Answer the following question:\\n\\nHow does AWS...  \n",
       "8  Answer the following question:\\n\\nWhat is the ...  \n",
       "9  Answer the following question:\\n\\nHow do promp...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546f2e9-000b-4c87-807e-2a63554bcc8c",
   "metadata": {},
   "source": [
    "### Uploading data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91c8bc-cb24-4b04-8de8-25c03c3490df",
   "metadata": {},
   "source": [
    "Next, we need to upload our training dataset to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49e9547f-127d-444e-89ed-6403781c83a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_location = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/train-question-answer.jsonl\"\n",
    "s3_output = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fb873b6-c50b-46fb-bd1f-a050bf523221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./train-question-answer.jsonl to s3://sagemaker-us-east-1-079002598131/bedrock/finetuning/train-question-answer.jsonl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./train-question-answer.jsonl $s3_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb85e28-aec1-46bc-aa6c-ba9b04cbc106",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can create the fine-tuning job. \n",
    "\n",
    "### ^^ **Note:** Make sure the IAM role you're using has these [IAM policies](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-iam-role.html) attached that allow Amazon Bedrock access to the specified S3 buckets ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04f82b-a918-4226-bf88-3ce567e50bcc",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "093e54cf-f0f3-403f-8ef5-84e0cbb40d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdc3af82-7cd6-44bd-bf14-e3e455c15e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titan-1701058871'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = \"titan-{}\".format(timestamp)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adfbd806-cb7e-4414-97a6-9239e98e5604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom-titan-1701058871'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model_name = \"custom-{}\".format(job_name)\n",
    "custom_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4f0ead8-31d2-4146-82c8-2d4d5fa07397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a79f03f4-2687-457d-a48a-27f83f46a4b3',\n",
       "  'HTTPStatusCode': 201,\n",
       "  'HTTPHeaders': {'date': 'Mon, 27 Nov 2023 04:22:21 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '122',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'a79f03f4-2687-457d-a48a-27f83f46a4b3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-east-1:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/g7j3engjpdlp'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.create_model_customization_job(\n",
    "    jobName=job_name,\n",
    "    customModelName=custom_model_name,\n",
    "    roleArn=role,\n",
    "    baseModelIdentifier=base_model_id,\n",
    "    hyperParameters = {\n",
    "        \"epochCount\": \"10\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \"0.000001\",\n",
    "        \"learningRateWarmupSteps\": \"0\"\n",
    "    },\n",
    "    trainingDataConfig={\"s3Uri\": s3_location},\n",
    "    outputDataConfig={\"s3Uri\": s3_output},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b1a6b37-6a22-4f63-8729-185642acc1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InProgress'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e0489-c5e3-4cc7-981b-6706497c6527",
   "metadata": {},
   "source": [
    "# Let's periodically check in on the progress.\n",
    "### The next cell might run for ~40min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87f790-8ee0-4485-b090-1be7af0f0554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "\n",
    "while status == \"InProgress\":\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "    status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "    \n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813589e-901f-49d5-9a1b-82609a405da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "completed_job = bedrock.get_model_customization_job(jobIdentifier=job_name)\n",
    "completed_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b47ec7-9933-45d1-9ad6-67be8fb318f9",
   "metadata": {},
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13364c0-17a8-4a30-b354-100c7b43a81b",
   "metadata": {},
   "source": [
    "Now we can test the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5bdf2-29a9-4041-8a62-b1f69ddbf129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.list_custom_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be0a01-1a4a-41e9-8c39-89f4d36942f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for job in bedrock.list_model_customization_jobs()[\"modelCustomizationJobSummaries\"]:\n",
    "    print(\"-----\\n\" + \"jobArn: \" + job[\"jobArn\"] + \"\\njobName: \" + job[\"jobName\"] + \"\\nstatus: \" + job[\"status\"] + \"\\ncustomModelName: \" + job[\"customModelName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf92c4-e2d3-48d4-83ab-592770e6aa61",
   "metadata": {},
   "source": [
    "## GetCustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0456a56-8bc3-47d2-8d69-4205ad0b1cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.get_custom_model(modelIdentifier=custom_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb02cd-0624-43f1-b3bc-2369333640d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model_arn = bedrock.get_custom_model(modelIdentifier=custom_model_name)['modelArn']\n",
    "custom_model_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a7e0b-2ee9-4c58-9db7-9d504b35d67e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_arn = bedrock.get_custom_model(modelIdentifier=custom_model_name)['baseModelArn']\n",
    "base_model_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e23e8-c4ee-4598-95ec-65620abb3631",
   "metadata": {},
   "source": [
    "## **Note:** To invoke custom models, you need to first create a provisioned throughput resource and make requests using that resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd028a6c-f13b-4d58-9b4f-ce8a18aecd66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provisioned_model_name = \"{}-provisioned\".format(custom_model_name)\n",
    "provisioned_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d7cbf-f391-4436-953e-70eaa987e3aa",
   "metadata": {},
   "source": [
    "## !! **Note:** SDK currently only supports 1 month and 6 months commitment terms. Go to Bedrock console to manually purchase no commitment term option for testing !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531afd39-5bde-4ead-a342-bea7c972c39c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bedrock_admin.create_provisioned_model_throughput(\n",
    "#     modelUnits = 1,\n",
    "#     commitmentDuration = \"OneMonth\", ## Note: SDK is currently missing No Commitment option\n",
    "#     provisionedModelName = provisioned_model_name,\n",
    "#     modelId = base_model_arn\n",
    "# ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828ec02-d7ae-43d3-afcb-060c95d4f4fd",
   "metadata": {},
   "source": [
    "## ListProvisionedModelThroughputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b30af-8167-4c70-be70-ec0050fca906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.list_provisioned_model_throughputs()[\"provisionedModelSummaries\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d9e7b-68f8-4162-97d6-fe8f43e3b421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GetProvisionedModelThroughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff67663-3956-44c5-9cbd-8bba90f77e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json \n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1308145-1e5a-474e-ad82-138de065f16e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#provisioned_model_name = \"<YOUR_PROVISIONED_MODEL_NAME>\" # e.g. custom-titan-1698257909-provisioned\n",
    "provisioned_model_name = \"custom-titan-1700585925-provisioned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61669df7-a58d-4f86-bb8c-a9319ca52c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provisioned_model_arn = bedrock.get_provisioned_model_throughput(\n",
    "     provisionedModelId=provisioned_model_name)[\"provisionedModelArn\"]\n",
    "provisioned_model_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15e071-9f84-4a0b-af8c-2f94875fbefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deployment_status = bedrock.get_provisioned_model_throughput(\n",
    "    provisionedModelId=provisioned_model_name)[\"status\"]\n",
    "deployment_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93817fcb-22d3-4c85-9ab5-c78fd67b5a16",
   "metadata": {},
   "source": [
    "## The next cell might run for ~10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22987e2-82fe-4550-9ecd-d13004f0919f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "deployment_status = bedrock.get_provisioned_model_throughput(\n",
    "    provisionedModelId=provisioned_model_name)[\"status\"]\n",
    "\n",
    "while deployment_status == \"Creating\":\n",
    "    \n",
    "    print(deployment_status)\n",
    "    time.sleep(30)\n",
    "    deployment_status = bedrock.get_provisioned_model_throughput(\n",
    "        provisionedModelId=provisioned_model_name)[\"status\"]  \n",
    "    \n",
    "print(deployment_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364ddd6-8ad2-47c8-90b3-e518be36a329",
   "metadata": {},
   "source": [
    "# Qualitative Results with Zero Shot Inference BEFORE and AFTER Fine-Tuning\n",
    "\n",
    "As with many GenAI applications, a qualitative approach where you ask yourself the question \"is my model behaving the way it is supposed to?\" is usually a good starting point. In the example below (the same one we started this notebook with), you can see how the fine-tuned model is able to create a reasonable summary of the dialogue compared to the original inability to understand what is being asked of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8edaaf4-b280-40bf-af81-deb994390212",
   "metadata": {},
   "source": [
    "## Before Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589bd0fc-6c3c-4ea3-bc5f-0a0807266b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_id = \"amazon.titan-text-express-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c2a4c-d40e-458d-a20d-724f8312ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Answer the following question:\\n\\nHow can prompt engineering go wrong?\\n\\nAnswer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26175d4-ff07-44f6-bdcc-17dd1687bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.9,\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=base_model_id, \n",
    "    body=json.dumps(body)\n",
    ")\n",
    "\n",
    "response_body = response[\"body\"].read().decode('utf8')\n",
    "print(json.loads(response_body)[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9da8b-59a2-4852-b011-aa95ce62fdbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = bedrock_runtime.invoke_model(\n",
    "#     # modelId needs to be Provisioned Throughput Model ARN\n",
    "#     modelId=base_model_id,\n",
    "#     body=\"\"\"\n",
    "# {\n",
    "#   \"inputText\": \"Question: How can I create IPv6 mount targets for EFS file systems in an AWS VPC?\\\\n\\\\nAnswer: \",\n",
    "#   \"textGenerationConfig\":{\n",
    "#     \"maxTokenCount\": 1000, \n",
    "#     \"stopSequences\": [],\n",
    "#     \"temperature\": 0.1,\n",
    "#     \"topP\": 0.9\n",
    "#   }\n",
    "# }\n",
    "# \"\"\"\n",
    "# )\n",
    "\n",
    "# response_body = response[\"body\"].read().decode('utf8')\n",
    "# print(response_body)\n",
    "\n",
    "# print(json.loads(response_body)[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ff33a-6047-47f7-9550-06148c66cabb",
   "metadata": {},
   "source": [
    "## After Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c2662-ad0d-40d2-8f8f-4e14e7b5a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.9,\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=provisioned_model_arn, \n",
    "    body=json.dumps(body)\n",
    ")\n",
    "\n",
    "response_body = response[\"body\"].read().decode('utf8')\n",
    "print(json.loads(response_body)[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef4202-e6e8-4f65-bb06-4c2309e1823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = bedrock_runtime.invoke_model(\n",
    "#     # modelId needs to be Provisioned Throughput Model ARN\n",
    "#     modelId=provisioned_model_arn,\n",
    "#     body=\"\"\"\n",
    "# {\n",
    "#   \"inputText\": \"Question: What is the workaround to creating IPv6 mount targets for EFS file systems in an AWS VPC?\\\\n\\\\nAnswer: \",\n",
    "#   \"textGenerationConfig\":{\n",
    "#     \"maxTokenCount\": 500, \n",
    "#     \"stopSequences\": [],\n",
    "#     \"temperature\": 0.1,\n",
    "#     \"topP\": 0.9\n",
    "#   }\n",
    "# }\n",
    "# \"\"\"\n",
    "# )\n",
    "\n",
    "# response_body = response[\"body\"].read().decode('utf8')\n",
    "# print(response_body)\n",
    "\n",
    "# print(json.loads(response_body)[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f62c91-c793-439d-b3b4-66f6eb0b0c1b",
   "metadata": {},
   "source": [
    "## Delete Provisioned Throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdbf87-b454-410a-9f11-fb42c17ed159",
   "metadata": {},
   "source": [
    "When you're done testing, you can delete Provisioned Throughput to stop charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad633b8-db9c-43a9-b2ab-b39bc7b3ee97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bedrock_admin.delete_provisioned_model_throughput(\n",
    "#     provisionedModelId = provisioned_model_name\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "forced_instance_type": "ml.t3.medium",
  "forced_lcc_arn": "",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
