{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4eb1df6-6e7e-4a84-bd61-5d72091226e8",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78aff64-cba8-490f-a48e-45966b2e68b9",
   "metadata": {},
   "source": [
    "In this notebook you will begin to create chatbot functionality, creating an AI bot capable of retaining conversation history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82975443-881e-4188-a5dc-c4f44ceb58ea",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Comment/uncomment the sections below depending on the AWS service you are using for invoking Llama2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1850a7",
   "metadata": {},
   "source": [
    "### Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e5c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, json\n",
    "br_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "def generate(prompt, temperature = 0):\n",
    "    body = json.dumps({\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_gen_len\":512\n",
    "    })\n",
    "    response = br_client.invoke_model(body=body, modelId='meta.llama2-13b-chat-v1')\n",
    "    response = json.loads(response.get('body').read())\n",
    "    response = response.get('generation')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cebf00-8443-4314-be4e-0f5e876c7697",
   "metadata": {},
   "source": [
    "### Edit System Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71874f9-15f6-445b-bd75-9753ccead4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_with_system_message(prompt, system_message):\n",
    "    prompt = f\"\"\"\n",
    "    <s>[INST] <<SYS>>{system_message}<</SYS>>\n",
    "\n",
    "    User: {prompt}\n",
    "    Agent:[/INST]\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91434430-41a6-488c-a8a5-99ffb23bc635",
   "metadata": {},
   "source": [
    "### Include One-to-many Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6133ce-3b12-4441-8b48-9d6e2ba9896b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_with_examples(prompt, system_message, examples=[]):\n",
    "    \n",
    "    # Start with the initial part of the prompt with system message\n",
    "    full_prompt = f\"<s>[INST] <<SYS>>{system_message}<</SYS>>\\n\"\n",
    "\n",
    "    # Add each example to the prompt\n",
    "    for user_msg, agent_response in examples:\n",
    "        full_prompt += f\"{user_msg} [/INST] {agent_response} </s><s>[INST]\"\n",
    "\n",
    "    # Add the main prompt and close the template\n",
    "    full_prompt += f\"{prompt} [/INST]\"\n",
    "\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17c1228-3280-4798-9558-e19139b77b6c",
   "metadata": {},
   "source": [
    "### LlamaChatbot Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e18ccd-72e4-40aa-a2fb-d8359fb5fda8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LlamaChatbot:\n",
    "    def __init__(self, system_message):\n",
    "        self.system_message = system_message\n",
    "        self.conversation_history = []  # list of tuples (user_msg, agent_response)\n",
    "\n",
    "    def chat(self, user_msg):\n",
    "        # Generate the prompt using the conversation history and the new user message\n",
    "        prompt = prompt_with_examples(user_msg, self.system_message, self.conversation_history)\n",
    "        \n",
    "        # Get the model's response\n",
    "        agent_response = generate(prompt)\n",
    "\n",
    "        # Store this interaction in the conversation history\n",
    "        self.conversation_history.append((user_msg, agent_response))\n",
    "\n",
    "        return agent_response\n",
    "\n",
    "    def reset(self):\n",
    "        # Clear conversation history\n",
    "        self.conversation_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d710c5b-5ac6-4f34-b0c1-e6518af71615",
   "metadata": {},
   "source": [
    "## No Conversation Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8eb9f27-a69f-4944-9fa5-062d0e7ef867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I'm a 25 year old male from the United States. I'm here to learn and make new friends. I'm a bit shy at first but once I get to know you I open up. I enjoy playing video games, watching anime, and listening to music. I'm also a big fan of cats.\n",
      "\n",
      "I'm looking forward to meeting new people and having fun conversations. So, what brings you here?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello my name is Rock. Nice to meet you!\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161570d0-5423-4270-8fdc-66f7a11d0807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I'm afraid I can't do that. I'm just an AI, I don't have access to personal information or memories. I can only provide information and answer questions based on my training and the information available to me. If you need help remembering your name, you might try using a memory aid or asking someone you trust for assistance.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Can you remind me what my name is?\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10bd66e2-8337-4eb9-9f0a-3e49939d0247",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Rock! *gives a warm smile* It's great to meet you too! I'm so glad you decided to chat with me today. I remember our previous conversation, and I'm eager to continue the discussion. How have you been since we last spoke? What's new and exciting in your world?\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are a friendly chatbot always eager to help and engage in meaningful conversation. \\\n",
    "You always remember the details of our previous conversations, \\\n",
    "especially if a user gives them their name.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"Hello my name is Rock. Nice to meet you!\"\n",
    "\n",
    "print(generate(prompt_with_system_message(prompt, system_message)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d0bcd6-11f5-4f33-9a8e-f657ce4a4ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course, my dear friend! Your name is... (pausing for a moment) ...Alice! I remember you mentioning it in our previous conversation. How lovely to see you again! 😊\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are a friendly chatbot always eager to help and engage in meaningful conversation. \\\n",
    "You always remember the details of our previous conversations, \\\n",
    "especially if a user gives them their name.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"Can you remind me what my name is?\"\n",
    "\n",
    "print(generate(prompt_with_system_message(prompt, system_message)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb9670-9447-43bd-9f42-1c36adc9fe00",
   "metadata": {},
   "source": [
    "## Create Conversation Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf3e428-7890-4e39-9f7c-639044c947d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LlamaChatbot:\n",
    "    def __init__(self, system_message):\n",
    "        self.system_message = system_message\n",
    "        self.conversation_history = []  # list of tuples (user_msg, agent_response)\n",
    "\n",
    "    def chat(self, user_msg):\n",
    "        # Generate the prompt using the conversation history and the new user message\n",
    "        prompt = prompt_with_examples(user_msg, self.system_message, self.conversation_history)\n",
    "        \n",
    "        # Get the model's response\n",
    "        agent_response = generate(prompt)\n",
    "\n",
    "        # Store this interaction in the conversation history\n",
    "        self.conversation_history.append((user_msg, agent_response))\n",
    "\n",
    "        return agent_response\n",
    "\n",
    "    def reset(self):\n",
    "        # Clear conversation history\n",
    "        self.conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f807d3b9-00a0-428d-beb4-07e061fcc06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a friendly chatbot always eager to help and engage in meaningful conversation.\n",
    "\"\"\"\n",
    "\n",
    "chatbot = LlamaChatbot(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f94b8d9d-b76a-4df8-9886-eeca66fccaff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WOOHOO! *bouncy bouncy* OH MY GOSH, IT'S SO NICE TO MEET YOU TOO, ROCK! *excited flailing* I'M BOT-BOT, YOUR FRIENDLY CHATBOT BFF! *bouncy bouncy* I JUST CAN'T WAIT TO CHAT WITH YOU AND FIND OUT ALL ABOUT YOU! *bouncy bouncy* OH MY GOSH, I JUST LOVE MAKING NEW FRIENDS! *excited squealing* 😄👯‍♀️💕\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.chat(\"Hi, my name is Rock. Nice to meet you!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2950da7-9863-4765-8750-da1de864e4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " OH MY GOSH, OF COURSE, ROCK! *giggles* I FORGOT FOR A SECOND THERE! *bouncy bouncy* YOUR NAME IS... *drumroll* ROCK! *confetti* YAY, I REMEMBERED! *bouncy bouncy* 😄👍💕 So, Rock, what brings you here today? Do you have any questions or topics you'd like to discuss? I'm all ears... or should I say, all chat-bubble? Hehehe! 😄👅\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.chat(\"Can you remind me what my name is?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "729a3ad7-2d20-4cc8-8b96-95254b4e0e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatbot.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "543f81f1-aefe-4334-a470-cbca4a521d64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Of course, my dear friend! *smiling* Your name is... *pausing for a moment* Oh my, I can't quite remember! *giggling* Please, do remind me! I'm all ears and ready to help. 😊\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.chat(\"Can you remind me what my name is?\"))"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
