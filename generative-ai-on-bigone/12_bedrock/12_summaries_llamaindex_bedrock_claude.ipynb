{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade42be5-7813-4aa6-9f4f-aad4318d4175",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Llama Document Summary Index With Amazon Bedrock Claude Model\n",
    "## Tested on an ml.m5.2xlarge\n",
    "\n",
    "> *If you see errors, you may need to be allow-listed for the Bedrock models used by this notebook*\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*\n",
    "\n",
    "\n",
    "This demo showcases the document summary index.\n",
    "\n",
    "The document summary index will extract a summary from each document and store that summary, as well as all nodes corresponding to the document.\n",
    "\n",
    "Retrieval can be performed through the LLM or embeddings. We first select the relevant documents to the query based on their summaries. All retrieved nodes corresponding to the selected documents are retrieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3502a53-6a70-411a-9be7-029454c88281",
   "metadata": {},
   "source": [
    "This notebook demonstrates invoking Bedrock models directly using the AWS SDK, but for later notebooks in the workshop you'll also need to install [LangChain](https://github.com/hwchase17/langchain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be291347-dfcb-41da-93be-e30ad9058e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "apache-beam 2.50.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.2 which is incompatible.\n",
      "botocore 1.32.6 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.1.0 which is incompatible.\n",
      "datasets 2.14.5 requires fsspec[http]<2023.9.0,>=2023.1.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.3 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "llama-index 0.8.37 requires urllib3<2, but you have urllib3 2.1.0 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.2 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "apache-beam 2.50.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.2 which is incompatible.\n",
      "autovizwidget 0.21.0 requires pandas<2.0.0,>=0.20.1, but you have pandas 2.1.3 which is incompatible.\n",
      "datasets 2.14.5 requires fsspec[http]<2023.9.0,>=2023.1.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.3 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.2 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "apache-beam 2.50.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.2 which is incompatible.\n",
      "botocore 1.32.6 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.1.0 which is incompatible.\n",
      "datasets 2.14.5 requires fsspec[http]<2023.9.0,>=2023.1.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.3 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "llama-index 0.8.37 requires urllib3<2, but you have urllib3 2.1.0 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.2 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.0.309 --force-reinstall --quiet\n",
    "%pip install pypdf==3.15.2 --force-reinstall --quiet\n",
    "%pip install llama-index==0.8.37 --force-reinstall --quiet\n",
    "%pip install sentence_transformers==2.2.2 --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ca1d87-da57-4776-a9f1-75645ad5f1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "apache-beam 2.50.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.2 which is incompatible.\n",
      "llama-index 0.8.37 requires urllib3<2, but you have urllib3 2.1.0 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydantic==1.10.13 --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a21c7a-b9f8-4a0c-87e4-e821c5b7f22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "apache-beam 2.50.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.2 which is incompatible.\n",
      "llama-index 0.8.37 requires urllib3<2, but you have urllib3 2.1.0 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlalchemy==2.0.21 --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1104a948-7459-47a8-93ed-e2893fd25f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "apache-beam 2.50.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.2 which is incompatible.\n",
      "botocore 1.32.6 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.1.0 which is incompatible.\n",
      "datasets 2.14.5 requires fsspec[http]<2023.9.0,>=2023.1.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "llama-index 0.8.37 requires urllib3<2, but you have urllib3 2.1.0 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# needed for llamaindex\n",
    "%pip install openai==0.28 --force-reinstall --quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b6d4d55-2a2f-41d5-aa32-159d6bc406fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb7288e-22f8-4753-a6ea-197cf2f8aba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    get_response_synthesizer,\n",
    "    set_global_service_context\n",
    ")\n",
    "from llama_index.indices.document_summary import DocumentSummaryIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c391a70-7690-4bbd-a2dc-f95b845991a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3491600b-32fa-4559-8d25-c7d07a57b84b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./data\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    dict(year=2022, source=filenames[0]),\n",
    "    dict(year=2021, source=filenames[1]),\n",
    "    dict(year=2020, source=filenames[2]),\n",
    "    dict(year=2019, source=filenames[3])]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa6b01a-b8fc-4b0a-8308-6b245acd5710",
   "metadata": {},
   "source": [
    "As part of Amazon's culture, the CEO always includes a copy of the 1997 Letter to Shareholders with every new release. This will cause repetition, take longer to generate embeddings, and may skew your results. In the next section you will take the downloaded data, trim the 1997 letter (last 3 pages) and overwrite them as processed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a0b300-0c6c-43be-a2ea-ae16fa0912f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "local_pdfs = glob.glob(data_root + '*.pdf')\n",
    "\n",
    "for local_pdf in local_pdfs:\n",
    "    pdf_reader = PdfReader(local_pdf)\n",
    "    pdf_writer = PdfWriter()\n",
    "    for pagenum in range(len(pdf_reader.pages)-3):\n",
    "        page = pdf_reader.pages[pagenum]\n",
    "        pdf_writer.add_page(page)\n",
    "\n",
    "    with open(local_pdf, 'wb') as new_file:\n",
    "        new_file.seek(0)\n",
    "        pdf_writer.write(new_file)\n",
    "        new_file.truncate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d917f4-c076-4287-98f4-229f761c3763",
   "metadata": {},
   "source": [
    "Now that you have clean PDFs to work with, you will enrich your documents with metadata, then use a process called \"chunking\" to break up a larger document into small pieces. These small pieces will allow you to generate embeddings without surpassing the input limit of the embedding model.\n",
    "\n",
    "In this example you will break the document into 1000 character chunks, with a 100 character overlap. This will allow your embeddings to maintain some of its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4429b839-e244-42b8-9b24-5368c1bb0a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "for filename in filenames:\n",
    "    doc = SimpleDirectoryReader(input_files=[f\"data/{filename}\"]).load_data()\n",
    "    doc[0].doc_id = filename.replace(\".pdf\", \"\")\n",
    "    docs.extend(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3de855-a3ee-4994-b3c0-0099fa7b5704",
   "metadata": {},
   "source": [
    "### Build Document Summary Index\n",
    "\n",
    "We show two ways of building the index:\n",
    "- default mode of building the document summary index\n",
    "- customizing the summary query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a3004bc-c525-4b57-aebd-b0d38b3a8cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Un comment the following lines to run from your local environment outside of the AWS account with Bedrock access\n",
    "\n",
    "#import os\n",
    "#os.environ['BEDROCK_ASSUME_ROLE'] = '<YOUR_VALUES>'\n",
    "#os.environ['AWS_PROFILE'] = 'bedrock-user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56ea0a6-7563-4005-a573-10ce0ebbc0de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json \n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30fa1e1a-0fcb-4dba-b4f1-cbdf5c2bf01e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import LangchainEmbedding\n",
    "from langchain.llms.bedrock import Bedrock # required until llama_index offers direct Bedrock integration\n",
    "from langchain.embeddings.bedrock import BedrockEmbeddings\n",
    "\n",
    "model_kwargs_claude = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_k\": 10,\n",
    "    \"max_tokens_to_sample\": 512\n",
    "}\n",
    "\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2\",\n",
    "              model_kwargs=model_kwargs_claude)\n",
    "\n",
    "embed_model = LangchainEmbedding(\n",
    "  BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\")\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, \n",
    "                                               embed_model=embed_model, \n",
    "                                               chunk_size=512)\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0a449-1a78-4809-83a3-c5264c28fe8f",
   "metadata": {},
   "source": [
    "### This will take a few minutes. Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93c531c9-4aee-47ae-a4d2-81af3a6af908",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: AMZN-2022-Shareholder-Letter\n",
      "current doc id: abe6382c-5343-437f-a788-847569559cfd\n",
      "current doc id: abd8a458-1532-4b70-a5d6-6822ad6e00d6\n",
      "current doc id: f1dca7cc-ed67-4b94-a7a9-f143bdbeb740\n",
      "current doc id: 1517b09b-d0b1-4689-a8ae-2faaa3c04dfe\n",
      "current doc id: ced85ff6-1372-4533-80e2-d39078fb3ee2\n",
      "current doc id: e26f95f5-a850-4509-8c6b-13f5613421d4\n",
      "current doc id: AMZN-2021-Shareholder-Letter\n",
      "current doc id: b8ca6627-7364-4265-b67d-23b85a9e382f\n",
      "current doc id: 90d7f040-c11b-4020-afb1-e7aaab8d0c7c\n",
      "current doc id: df6d3df8-003d-42c3-82f5-35580cb1d327\n",
      "current doc id: 7b17f840-16ea-4f87-84b6-31048fbb834f\n",
      "current doc id: f8a7b442-678b-440a-adc5-5066a5684f92\n",
      "current doc id: AMZN-2020-Shareholder-Letter\n",
      "current doc id: 860875c9-46ff-4ba2-a3a9-d3e490953c3c\n",
      "current doc id: 7965b5bc-94d8-44b2-bbb0-a33af5fe0a8d\n",
      "current doc id: df0fd59e-0fdc-4279-8cc2-6c0309bd15af\n",
      "current doc id: cfff31cf-a33a-45b6-94a7-a88d43d3ba98\n",
      "current doc id: 5294742e-b635-4865-a335-216586772ffa\n",
      "current doc id: fc0461c3-80a5-4551-b16b-e42241941519\n",
      "current doc id: AMZN-2019-Shareholder-Letter\n",
      "current doc id: 56dfcac4-2b3a-4bb5-b34b-92c396249a5c\n",
      "current doc id: 8467ea0e-8d92-4a20-a86b-3e10a648d12f\n",
      "current doc id: 7c424ad8-4bc0-43fb-a33e-65109785f4fc\n",
      "current doc id: fad7f699-291b-4d2c-962c-715dbcc6d2c3\n"
     ]
    }
   ],
   "source": [
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")\n",
    "doc_summary_index = DocumentSummaryIndex.from_documents(\n",
    "    docs,\n",
    "    service_context=service_context,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "317d5201-a7e6-4ab1-bdf7-1fd2de6f4bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf5d19a2-5fa3-4f1b-aadd-25c209cfeb75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Based on the context, this text is the opening letter from Amazon's 2022 annual shareholder letter written by CEO Andy Jassy. It provides an overview of Amazon's performance and outlook.\\n\\nSome key points and potential questions this text can answer:\\n\\n- It discusses Amazon's performance and challenges in 2022, a difficult macroeconomic year. It talks about how Amazon still found ways to grow demand and innovate despite the challenges. Questions it can answer - How did Amazon perform financially in 2022? What were some of the challenges it faced? How did it continue to grow and innovate?\\n\\n- It provides a historical overview of how Amazon has evolved over 25 years since its early days as just an online book retailer. Questions - How has Amazon's business evolved over time? What new products and services has it introduced over the years? \\n\\n- It mentions some previous challenging economic times like the 2001 dot-com crash and the 2008-09 recession, and how Amazon balanced short-term actions with long-term investments. Questions - How did Amazon respond during difficult prior economic downturns? What long-term investments did it make?\\n\\n- It talks about the growth and success of Amazon Web Services (AWS), which started small but now generates significant revenue. Questions - How did AWS emerge and evolve as a key business for Amazon? What role has AWS played in Amazon's success?\\n\\nIn summary, this opening shareholder letter provides an overview of Amazon's 2022 performance, a historical perspective on its evolution as a company, discussion of how it has responded to prior challenges, and the success of strategic long-term investments like AWS. The text can answer questions about Amazon's financials, challenges, responses to economic conditions, long-term investments, and evolution of its businesses over time.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_summary_index.get_document_summary(\"AMZN-2022-Shareholder-Letter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349c2872-2b53-4812-9392-b89e5879e32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_summary_index.storage_context.persist(\"llama_claude_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f96e6524-f8ab-4227-ad5a-3dcb3b640532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.loading import load_index_from_storage\n",
    "from llama_index import StorageContext\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"llama_claude_index\")\n",
    "doc_summary_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b3344-8e24-4e72-893b-7accd2a3fa57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Perform Retrieval from Document Summary Index\n",
    "\n",
    "We show how to execute queries at a high-level. We also show how to perform retrieval at a lower-level so that you can view the parameters that are in place. We show both LLM-based retrieval and embedding-based retrieval using the document summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43413937-2e28-42ca-bf50-44b920614fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.prompts.base import Prompt\n",
    "from llama_index.prompts.prompt_type import PromptType\n",
    "\n",
    "CLAUDE_CHOICE_SELECT_PROMPT_TMPL = (\n",
    "    \"\"\"\n",
    "    \n",
    "    Human: A list of documents is shown below. Each document has a number next to it along  with a summary of the document. A question is also provided. \n",
    "    Respond with the respective document number. You should consult to answer the question, in order of relevance, as well as the relevance score. \n",
    "    The relevance score is a number from 1-10 based on how relevant you think the document is to the question.\\n\"\n",
    "    Do not include any documents that are not relevant to the question. \n",
    "    \n",
    "    Example format: \n",
    "    Document 1:\\n<summary of document 1>\n",
    "    Document 2:\\n<summary of document 2>\n",
    "    ...\\n\\n\n",
    "    Document 10:\\n<summary of document 10>\n",
    "    \n",
    "    Question: <question>\n",
    "    Answer:\n",
    "    Doc: 9, Relevance: 7\n",
    "    Doc: 3, Relevance: 4\n",
    "    Doc: 7, Relevance: 3\n",
    "\n",
    "    Let's try this now: \n",
    "    {context_str}\n",
    "\n",
    "    Question: {query_str}\n",
    "    \n",
    "    Assistant: Answer:\"\"\"\n",
    ")\n",
    "claude_choice_select_prompt = Prompt(\n",
    "    CLAUDE_CHOICE_SELECT_PROMPT_TMPL, prompt_type=PromptType.CHOICE_SELECT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f65a3-482f-4481-9933-19ac55e91719",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### High-level Querying\n",
    "\n",
    "Note: this uses the default, LLM-based form of retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e925b75-0a99-49cc-8e9a-daaf715ee490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.llama_custom_parse_choice_select_answer_fn import custom_parse_choice_select_answer_fn\n",
    "query_engine = doc_summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", use_async=True, similarity_top_k=10,  verbose=False,\n",
    "    parse_choice_select_answer_fn=custom_parse_choice_select_answer_fn,\n",
    "    choice_select_prompt=claude_choice_select_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c190a1e7-b85c-41cd-af42-e2521d2406a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unfortunately there is no information provided in the given context about AWS or how it has evolved over time. The context discusses Amazon's response to the COVID-19 pandemic, including efforts to protect warehouse and delivery workers, adjust operations to meet changing demands, and consider implementing testing. But it does not mention anything specifically about AWS, Amazon's cloud computing platform. Without any relevant information about AWS in the provided sources, I do not have enough context to provide a substantive answer to the question \"How has AWS evolved?\". I apologize that I cannot provide a useful response without being given background information related to the evolution and history of AWS.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How has AWS evolved?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b99c2-06de-4071-9314-eec75c50c5f5",
   "metadata": {},
   "source": [
    "#### LLM-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd99ce8-8347-4e6e-88e4-23dd8fcb9084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.document_summary import DocumentSummaryIndexRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67e397dd-fbb0-4465-994a-7527b3a6dd57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.llama_custom_parse_choice_select_answer_fn import custom_parse_choice_select_answer_fn\n",
    "retriever = DocumentSummaryIndexRetriever(\n",
    "    doc_summary_index,\n",
    "    choice_select_prompt=claude_choice_select_prompt,\n",
    "    # choice_batch_size=choice_batch_size,\n",
    "    # format_node_batch_fn=format_node_batch_fn,\n",
    "    parse_choice_select_answer_fn=custom_parse_choice_select_answer_fn,\n",
    "    # service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eef31654-27ea-4fb0-b29e-b18e5bf867f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "retrieved_nodes = retriever.retrieve(\"According to the documents, How has AWS evolved?\")\n",
    "print(len(retrieved_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96f76e79-1595-43b3-81e7-9ca7547fa2d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "work came from optimizing the connections between this large amount of infrastructure. We also continue\n",
      "to improve our advanced machine learning algorithms to better predict what customers in various parts of thecountry will need so that we have the right inventory in the right regions at the right time. We’ve recentlycompleted this regional roll out and like the early results. Shorter travel distances mean lower cost to serve,less impact on the environment, and customers getting their orders faster. On the latter, we’re excited aboutseeing more next day and same-day deliveries, and we’re on track to have our fastest Prime delivery speedsever in 2023. Overall, we remain confident about our plans to lower costs, reduce delivery times, and build a\n",
      "meaningfully larger retail business with healthy operating margins.\n",
      "AWS has an $85B annualized revenue run rate, is still early in its adoption curve, but at a juncture where it’s\n",
      "critical to stay focused on what matters most to customers over the long-haul . Despite growing 29% year-over-\n",
      "year (“Y oY”) in 2022 on a $62B revenue base, AWS faces short-term headwinds right now as companiesare being more cautious in spending given the challenging, current macroeconomic conditions. While somecompanies might obsess over how they could extract as much money from customers as possible in these tighttimes, it’s neither what customers want nor best for customers in the long term, so we’re taking a differenttack. One of the many advantages of AWS and cloud computing is that when your business grows, you canseamlessly scale up; and conversely, if your business contracts, you can choose to give us back that capacityand cease paying for it. This elasticity is unique to the cloud, and doesn’t exist when you’ve already madeexpensive capital investments in your own on-premises datacenters, servers, and networking gear. In AWS,like all our businesses, we’re not trying to optimize for any one quarter or year.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "10.0\n",
      "We’re trying to build customerrelationships (and a business) that outlast all of us; and as a result, our AWS sales and support teams arespending much of their time helping customers optimize their AWS spend so they can better weather thisuncertain economy. Many of these AWS customers tell us that they’re not cost-cutting as much as cost-optimizing so they can take their resources and apply them to emerging and inventive new customerexperiences they’re planning. Customers have appreciated this customer-focused, long-term approach, andwe think it’ll bode well for both customers and AWS.\n",
      "While these short-term headwinds soften our growth rate, we like a lot of the fundamentals that we’re seeing\n",
      "in AWS. Our new customer pipeline is robust, as are our active migrations. Many companies usediscontinuous periods like this to step back and determine what they strategically want to change, and wefind an increasing number of enterprises opting out of managing their own infrastructure, and preferring tomove to AWS to enjoy the agility, innovation, cost-efficiency, and security benefits. And most importantlyfor customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.\n",
      "Chip development is a good example. In last year’s letter, I mentioned the investment we were making in our\n",
      "general-purpose CPU processors named Graviton. Graviton2-based compute instances deliver up to 40%better price-performance than the comparable latest generation x86-based instances; and in 2022, we deliveredour Graviton3 chips, providing 25% better performance than the Graviton2 processors. Further, as machinelearning adoption has continued to accelerate, customers have yearned for lower-cost GPUs (the chipsmost commonly used for machine learning). AWS started investing years ago in these specialized chips formachine learning training and inference (inferences are the predictions or answers that a machine learningmodel provides). We delivered our first training chip in 2022 (“Trainium”); and for the most commonmachine learning models, Trainium-based instances are up to 140% faster than GPU-based instances at upto 70% lower cost.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "10.0\n",
      "Most companies are still in the training stage, but as they develop models that graduate tolarge-scale production, they’ll find that most of the cost is in inference because models are trainedperiodically whereas inferences are happening all the time as their associated application is being exercised.We launched our first inference chips (“Inferentia”) in 2019, and they have saved companies like Amazon overa hundred million dollars in capital expense already. Our Inferentia2 chip, which just launched, offers upto four times higher throughput and ten times lower latency than our first Inferentia processor. With theenormous upcoming growth in machine learning, customers will be able to get a lot more done with AWS’straining and inference chips at a significantly lower cost. We’re not close to being done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
      "Similarly high potential, Amazon’s Advertising business is uniquely effective for brands, which is part of why it\n",
      "continues to grow at a brisk clip . Akin to physical retailers’ advertising businesses selling shelf space, end-\n",
      "caps, and placement in their circulars, our sponsored products and brands offerings have been an integral part\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "8.0\n",
      "Everybody agreed that having a persistent block store was important to a complete compute service;\n",
      "however, to have one ready would take an extra year. The question became could we offer customers auseful service where they could get meaningful value before we had all the features we thought they wanted?We decided that the initial launch of EC2 could be feature-poor if we also organized ourselves to listen tocustomers and iterate quickly. This approach works well if you indeed iterate quickly; but, is disastrous if youcan’t. We launched EC2 in 2006 with one instance size, in one data center, in one region of the world, withLinux operating system instances only (no Windows), without monitoring, load balancing, auto-scaling, oryes, persistent storage. EC2 was an initial success, but nowhere near the multi-billion-dollar service it’sbecome until we added the missing capabilities listed above, and then some.\n",
      "In the early days of AWS, people sometimes asked us why compute wouldn’t just be an undifferentiated\n",
      "commodity. But, there’s a lot more to compute than just a server. Customers want various flavors of compute(e.g. server configurations optimized for storage, memory, high-performance compute, graphics rendering,machine learning), multiple form factors (e.g. fixed instance sizes, portable containers, serverless functions),various sizes and optimizations of persistent storage, and a slew of networking capabilities. Then, there’sthe CPU chip that runs in your compute. For many years, the industry had used Intel or AMD x86 processors.We have important partnerships with these companies, but realized that if we wanted to push price andperformance further (as customers requested), we’d have to develop our own chips, too. Our first generalizedchip was Graviton, which we announced in 2018. This helped a subset of customer workloads run morecost-effectively than prior options. But, it wasn’t until 2020, after taking the learnings from Graviton and\n",
      "innovating on a new chip, that we had something remarkable with our Graviton2 chip, which provides up to40% better price-performance than the comparable latest generation x86 processors.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "8.0\n",
      "Think about howmuch of an impact 40% improvement on compute is. Compute is used for every bit of technology. That’s ahuge deal for customers. And, while Graviton2 has been a significant success thus far (48 of the top 50 AWSEC2 customers have already adopted it), the AWS Chips team was already learning from what customerssaid could be better, and announced Graviton3 this past December (offering a 25% improvement on top ofGraviton2’s relative gains). The list of what we’ve invented and delivered for customers in EC2 (and AWS ingeneral) is pretty mind-boggling, and this iterative approach to innovation has not only given customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.\n",
      "Devices : Our first foray into devices was the Kindle, released in 2007. It was not the most sophisticated\n",
      "industrial design (it was creamy white in color and the corners were uncomfortable for some people to hold),but revolutionary because it offered customers the ability to download any of over 90,000 books (nowmillions) in 60 seconds—and we got better and faster at building attractive designs. Shortly thereafter, welaunched a tablet, and then a phone (with the distinguishing feature of having front-facing cameras and agyroscope to give customers a dynamic perspective along with varied 3D experiences). The phone wasunsuccessful, and though we determined we were probably too late to this party and directed these resourceselsewhere, we hired some fantastic long-term builders and learned valuable lessons from this failure thathave served us well in devices like Echo and FireTV .\n",
      "When I think of the first Echo device—and what Alexa could do for customers at that point—it was\n",
      "noteworthy, yet so much less capable than what’s possible today.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "8.0\n",
      "Today, there are hundreds of millions ofAlexa-enabled devices out there (in homes, offices, cars, hotel rooms, Amazon Echo devices, and third-partymanufacturer devices); you can listen to music—or watch videos now; you can control your lights andhome automation; you can create routines like “Start My Day” where Alexa tells you the weather, yourestimated commute time based on current traffic, then plays the news; you can easily order retail items onAmazon; you can get general or customized news, updates on sporting events and related stats—and we’re stillquite early with respect to what Alexa and Alexa-related devices will do for customers. Our goal is forAlexa to be the world’s most helpful and resourceful personal assistant, who makes people’s lives meaningfullyeasier and better. We have a lot more inventing and iterating to go, but customers continue to indicate thatwe’re on the right path. We have several other devices at varying stages of evolution (e.g. Ring and Blinkprovide the leading digital home security solutions, Astro is a brand new home robot that we just launchedin late 2021), but it’s safe to say that every one of our devices, whether you’re talking about Kindle, FireTV,Alexa/Echo, Ring, Blink, or Astro is an invention-in-process with a lot more coming that will keepimproving customers’ lives.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "7.0\n",
      "month flat fee, enables Prime members to get as many of the eligible prescription medications as they need\n",
      "for dozens of common conditions, like high blood pressure, acid reflux, and anxiety. However, our customershave continued to express a strong desire for Amazon to provide a better alternative to the inefficient andunsatisfying broader healthcare experience. We decided to start with primary care as it’s a prevalent first stopin the patient journey. We evaluated and studied the existing landscape extensively, including some early\n",
      "Amazon experiments like Amazon Care. During this process, we identified One Medical’s patient-focusedexperience as an excellent foundation upon which to build our future business; and in July 2022, we announcedour acquisition of One Medical. There are several elements that customers love about One Medical. It hasa fantastic digital app that makes it easy for patients to discuss issues with a medical practitioner via chat orvideo conference. If a physical visit is required, One Medical has offices in cities across the US wherepatients can book same or next day appointments. One Medical has relationships with specialty physiciansin each of its cities and works closely with local hospital systems to make seeing specialists easy, so OneMedical members can quickly access these resources when needed. Going forward, we strongly believethat One Medical and Amazon will continue to innovate together to change what primary care will look likefor customers.\n",
      "Kuiper is another example of Amazon innovating for customers over the long term in an area where there’s\n",
      "high customer need. Our vision for Kuiper is to create a low-Earth orbit satellite system to deliver high-qualitybroadband internet service to places around the world that don’t currently have it. There are hundreds ofmillions of households and businesses who don’t have reliable access to the internet. Imagine what they’ll beable to do with reliable connectivity, from people taking online education courses, using financial services,starting their own businesses, doing their shopping, enjoying entertainment, to businesses and governmentsimproving their coverage, efficiency, and operations. Kuiper will deliver not only accessibility, butaffordability. Our teams have developed low-cost antennas (i.e. customer terminals) that will lower thebarriers to access.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "7.0\n",
      "customer terminals) that will lower thebarriers to access. We recently unveiled the new terminals that will communicate with the satellites passingoverhead, and we expect to be able to produce our standard residential version for less than $400 each. They’resmall: 11 inches square, 1 inch thick, and weigh less than 5 pounds without their mounting bracket, butthey deliver speeds up to 400 megabits per second. And they’re powered by Amazon-designed baseband chips.We’re preparing to launch two prototype satellites to test the entire end-to-end communications networkthis year, and plan to be in beta with commercial customers in 2024. The customer reaction to what we’veshared thus far about Kuiper has been very positive, and we believe Kuiper represents a very large potentialopportunity for Amazon. It also shares several similarities to AWS in that it’s capital intensive at the start,but has a large prospective consumer, enterprise, and government customer base, significant revenue andoperating profit potential, and relatively few companies with the technical and inventive aptitude, as well asthe investment hypothesis to go after it.\n",
      "One final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our\n",
      "business for many decades to come, and where we’re investing heavily is Large Language Models (“LLMs”)\n",
      "and Generative AI . Machine learning has been a technology with high promise for several decades, but it’s\n",
      "only been the last five to ten years that it’s started to be used more pervasively by companies. This shift wasdriven by several factors, including access to higher volumes of compute capacity at lower prices than was everavailable. Amazon has been using machine learning extensively for 25 years, employing it in everythingfrom personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air,to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learningfunctionality and customer base of any cloud provider). More recently, a newer form of machine learning,called Generative AI, has burst onto the scene and promises to significantly accelerate machine learningadoption.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "7.0\n",
      "Generative AI is based on very Large Language Models (trained on up to hundreds of billionsof parameters, and growing), across expansive datasets, and has radically general and broad recall andlearning capabilities. We have been working on our own LLMs for a while now, believe it will transform andimprove virtually every customer experience, and will continue to invest substantially in these modelsacross all of our consumer, seller, brand, and creator experiences. Additionally, as we’ve done for years inAWS, we’re democratizing this technology so companies of all sizes can leverage Generative AI. AWS isoffering the most price-performant machine learning chips in Trainium and Inferentia so small and largecompanies can afford to train and run their LLMs in production. We enable companies to choose fromvarious LLMs and build applications with all of the AWS security, privacy and other features that customersare accustomed to using. And, we’re delivering applications like AWS’s CodeWhisperer, which revolutionizes\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "8.0\n",
      "development process of working backwards from the customer where having to write a Press Release (to\n",
      "flesh out the customer benefits) and a Frequently Asked Questions document (to detail how we’d build it)helps us have blind faith without false hope (at least usually).\n",
      "5/Define a Minimum Loveable Product (MLP), and Be Willing to Iterate Fast : Figuring out where to draw\n",
      "the line for launch is one of the most difficult decisions teams must make. Often, teams wait too long, andinsist on too many bells and whistles, before launching. And, they miss the first mover advantage oropportunity to build mindshare in fast-moving market segments before well-executing peers get too farahead. The launch product must be good enough that you believe it’ll be loved from the get-go (why we callit a “Minimum Loveable Product” vs. a “Minimum Viable Product”), but in newer market segments,teams are often better off getting this MLP to customers and iterating quickly thereafter.\n",
      "6/Adopt a Long-term Orientation : We’re sometimes criticized at Amazon for not shutting much down. It’s\n",
      "true that we have a longer tolerance for our investments than most companies. But, we know thattransformational invention takes multiple years, and if you’re making big bets that you believe couldsubstantially change customer experience (and your company), you have to be in it for the long-haul oryou’ll give up too quickly.\n",
      "7/Brace Yourself for Failure : If you invent a lot, you will fail more often than you wish. Nobody likes this\n",
      "part, but it comes with the territory. When it’s clear that we’ve launched something that won’t work, we makesure we’ve learned from what didn’t go well, and secure great landing places for team members whodelivered well—or your best people will hesitate to work on new initiatives.\n",
      "Albert Einstein is sometimes credited with describing compound interest as the eighth wonder of the world\n",
      "(“He who understands it, earns it. He who doesn’t, pays it”).\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "8.0\n",
      "He who doesn’t, pays it”). We think of iterative innovation in much thesame way. Iterative innovation creates magic for customers. Constantly inventing and improving products forcustomers has a compounding effect on the customer experience, and in turn on a business’s prospects.\n",
      "Time is your friend when you are compounding gains. Amazon is a big company with some large businesses,\n",
      "but it’s still early days for us. We will continue to be insurgent—inventing in businesses that we’re in, in newbusinesses that we’ve yet to launch, and in new ideas that we haven’t even imagined yet. It remains Day 1.\n",
      "Sincerely,\n",
      "Andy Jassy\n",
      "President and Chief Executive OfficerAmazon.com, Inc.\n",
      "P .S. As we have always done, our original 1997 Shareholder Letter follows. What’s written there is as true\n",
      "today as it was in 1997.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "6.0\n",
      "To our shareowners:\n",
      "In Amazon’s 1997 letter to shareholders, our first, I talked about our hope to create an “enduring franchise,”\n",
      "one that would reinvent what it means to serve customers by unlocking the internet’s power. I noted that\n",
      "Amazon had grown from having 158 employees to 614, and that we had surpassed 1.5 million customer\n",
      "accounts. We had just gone public at a split-adjusted stock price of $1.50 per share. I wrote that it was Day 1.\n",
      "We’ve come a long way since then, and we are working harder than ever to serve and delight customers.\n",
      "Last year, we hired 500,000 employees and now directly employ 1.3 million people around the world. We have\n",
      "more than 200 million Prime members worldwide. More than 1.9 million small and medium-sized businesses\n",
      "sell in our store, and they make up close to 60% of our retail sales. Customers have connected more than\n",
      "100 million smart home devices to Alexa. Amazon Web Services serves millions of customers and ended 2020\n",
      "with a $50 billion annualized run rate. In 1997, we hadn’t invented Prime, Marketplace, Alexa, or AWS.\n",
      "They weren’t even ideas then, and none was preordained. We took great risk with each one and put sweat\n",
      "and ingenuity into each one.\n",
      "Along the way, we’ve created $1.6 trillion of wealth for shareowners. Who are they? Y our Chair is one, and\n",
      "my Amazon shares have made me wealthy. But more than 7/8ths of the shares, representing $1.4 trillion of\n",
      "wealth creation, are owned by others. Who are they? They’re pension funds, universities, and 401(k)s, and\n",
      "they’re Mary and Larry, who sent me this note out of the blue just as I was sitting down to write this\n",
      "shareholder letter:\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "8.0\n",
      "Customers around the world have leveraged the cloud to scale up services and stand up responses to COVID-19.\n",
      "We joined the New York City COVID-19 Rapid Response Coalition to develop a conversational agent to enableat-risk and elderly New Yorkers to receive accurate, timely information about medical and other important needs.In response to a request from the Los Angeles Unified School District to transition 700,000 students to remotelearning, AWS helped establish a call center to field IT questions, provide remote support, and enable staff toanswer calls. We are providing cloud services to the CDC to help thousands of public health practitioners andclinicians gather data related to COVID-19 and inform response efforts. In the UK, AWS provides the cloudcomputing infrastructure for a project that analyzes hospital occupancy levels, emergency room capacity, andpatient wait times to help the country’s National Health Service decide where best to allocate resources. InCanada, OTN—one of the world’s largest virtual care networks—is scaling its AWS-powered video service toaccommodate a 4,000% spike in demand to support citizens as the pandemic continues. In Brazil, AWS willprovide the São Paulo State Government with cloud computing infrastructure to guarantee online classes to1 million students in public schools across the state.\n",
      "Following CDC guidance, our Alexa health team built an experience that lets U.S. customers check their risk\n",
      "level for COVID-19 at home. Customers can ask, “Alexa, what do I do if I think I have COVID-19?” or “Alexa,what do I do if I think I have coronavirus?” Alexa then asks a series of questions about the person’s symptomsand possible exposure. Based on those responses, Alexa then provides CDC-sourced guidance. We created asimilar service in Japan, based on guidance from the Japanese Ministry of Health, Labor, and Welfare.\n",
      "We’re making it easy for customers to use Amazon.com or Alexa to donate directly to charities on the front lines\n",
      "of the COVID-19 crisis, including Feeding America, the American Red Cross, and Save the Children.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "8.0\n",
      "Echo usershave the option to say, “Alexa, make a donation to Feeding America COVID-19 Response Fund.” In Seattle,we’ve partnered with a catering business to distribute 73,000 meals to 2,700 elderly and medically vulnerableresidents in Seattle and King County during the outbreak, and we donated 8,200 laptops to help Seattle PublicSchools students gain access to a device while classes are conducted virtually.\n",
      "Beyond COVID\n",
      "Although these are incredibly difficult times, they are an important reminder that what we do as a company can\n",
      "make a big difference in people’s lives. Customers count on us to be there, and we are fortunate to be able tohelp. With our scale and ability to innovate quickly, Amazon can make a positive impact and be an organizingforce for progress.\n",
      "Last year, we co-founded The Climate Pledge with Christiana Figueres, the UN’s former climate change chief\n",
      "and founder of Global Optimism, and became the first signatory to the pledge. The pledge commits Amazon tomeet the goals of the Paris Agreement 10 years early—and be net zero carbon by 2040. Amazon faces significantchallenges in achieving this goal because we don’t just move information around—we have extensive physicalinfrastructure and deliver more than 10 billion items worldwide a year. And we believe if Amazon can get to netzero carbon ten years early, any company can—and we want to work together with all companies to make it areality.\n",
      "To that end, we are recruiting other companies to sign The Climate Pledge. Signatories agree to measure and\n",
      "report greenhouse gas emissions regularly, implement decarbonization strategies in line with the ParisAgreement, and achieve net zero annual carbon emissions by 2040. (We’ll be announcing new signatories soon.)\n",
      "We plan to meet the pledge, in part, by purchasing 100,000 electric delivery vans from Rivian—a Michigan-\n",
      "based producer of electric vehicles. Amazon aims to have 10,000 of Rivian’s new electric vans on the road asearly as 2022, and all 100,000 vehicles on the road by 2030. That’s good for the environment, but the promise iseven greater.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "8.0\n",
      "That’s good for the environment, but the promise iseven greater. This type of investment sends a signal to the marketplace to start inventing and developing newtechnologies that large, global companies need to transition to a low-carbon economy.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "6.0\n",
      "To our shareowners:\n",
      "One thing we’ve learned from the COVID-19 crisis is how important Amazon has become to our customers. We\n",
      "want you to know we take this responsibility seriously, and we’re proud of the work our teams are doing to helpcustomers through this difficult time.\n",
      "Amazonians are working around the clock to get necessary supplies delivered directly to the doorsteps of people\n",
      "who need them. The demand we are seeing for essential products has been and remains high. But unlike apredictable holiday surge, this spike occurred with little warning, creating major challenges for our suppliers anddelivery network. We quickly prioritized the stocking and delivery of essential household staples, medicalsupplies, and other critical products.\n",
      "Our Whole Foods Market stores have remained open, providing fresh food and other vital goods for customers.\n",
      "We are taking steps to help those most vulnerable to the virus, setting aside the first hour of shopping at WholeFoods each day for seniors. We have temporarily closed Amazon Books, Amazon 4-star, and Amazon Pop Upstores because they don’t sell essential products, and we offered associates from those closed stores theopportunity to continue working in other parts of Amazon.\n",
      "Crucially, while providing these essential services, we are focused on the safety of our employees and contractors\n",
      "around the world—we are deeply grateful for their heroic work and are committed to their health and well-being.Consulting closely with medical experts and health authorities, we’ve made over 150 significant process changesin our operations network and Whole Foods Market stores to help teams stay healthy, and we conduct dailyaudits of the measures we’ve put into place. We’ve distributed face masks and implemented temperature checksat sites around the world to help protect employees and support staff. We regularly sanitize door handles,stairway handrails, lockers, elevator buttons, and touch screens, and disinfectant wipes and hand sanitizer arestandard across our network.\n",
      "We’ve also introduced extensive social distancing measures to help protect our associates. We have eliminated\n",
      "stand-up meetings during shifts, moved information sharing to bulletin boards, staggered break times, and spreadout chairs in breakrooms.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "6.0\n",
      "While training new hires is challenging with new distancing requirements, we continueto ensure that every new employee gets six hours of safety training. We’ve shifted training protocols so we don’thave employees gathering in one spot, and we’ve adjusted our hiring processes to allow for social distancing.\n",
      "A next step in protecting our employees might be regular testing of all Amazonians, including those showing no\n",
      "symptoms. Regular testing on a global scale, across all industries, would both help keep people safe and help getthe economy back up and running. For this to work, we as a society would need vastly more testing capacity thanis currently available. If every person could be tested regularly, it would make a huge difference in how we fightthis virus. Those who test positive could be quarantined and cared for, and everyone who tests negative couldre-enter the economy with confidence.\n",
      "We’ve begun the work of building incremental testing capacity. A team of Amazonians—from research scientists\n",
      "and program managers to procurement specialists and software engineers—moved from their normal day jobsonto a dedicated team to work on this initiative. We have begun assembling the equipment we need to build ourfirst lab and hope to start testing small numbers of our frontline employees soon. We are not sure how far we willget in the relevant timeframe, but we think it’s worth trying, and we stand ready to share anything we learn.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(retrieved_nodes):\n",
    "    print(node.score)\n",
    "    print(node.node.get_text())\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a215ef33-5d05-42ad-83c5-409ccc288d26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The new context from the 2019 Amazon shareholder letter does not contain significant information related to the evolution of AWS over time. The letter focuses on Amazon's response to the COVID-19 pandemic in 2020, specifically efforts to protect employee safety and build testing capacity. While important, this does not provide substantive new information about the historical development of AWS since its launch in 2006.\n",
      "\n",
      "As such, I do not believe the original answer needs to be refined. It already provides a comprehensive overview of how AWS has evolved, covering:\n",
      "\n",
      "- Starting as a minimal IaaS offering and expanding into a vast service catalog \n",
      "\n",
      "- Leveraging Amazon's infrastructure to bootstrap growth\n",
      "\n",
      "- Relentless innovation and focus on customer needs\n",
      "\n",
      "- Maturing from basic IaaS to higher-level PaaS, SaaS, and industry offerings \n",
      "\n",
      "- Global expansion for lower latency and localized support\n",
      "\n",
      "- Continued downward pressure on pricing while increasing performance\n",
      "\n",
      "In summary, the new context focuses on different subject matter (Amazon's COVID-19 response) that does not significantly enhance or alter the historical summary of AWS evolution already provided. The original answer remains a complete, accurate overview of how AWS has evolved over time.\n",
      "\n",
      "Original Answer:\n",
      "\n",
      "AWS has evolved tremendously since its initial launch in 2006. Here are some key ways AWS has evolved:\n",
      "\n",
      "- Started as a minimal viable product with only S3 cloud storage and EC2 compute capabilities. Has expanded into a highly extensive suite of services including databases, analytics, machine learning, IoT, security, enterprise applications, etc.\n",
      "\n",
      "- Leveraged Amazon's own internal technology and infrastructure like data centers, servers, and networks to rapidly scale up AWS. This helped bootstrap AWS's growth. \n",
      "\n",
      "- Relentlessly focused on expanding capabilities through innovation, releasing thousands of new features per year.\n",
      "\n",
      "- Worked to understand customer needs and provide customized solutions, migrating many enterprise workloads to the cloud. \n",
      "\n",
      "- Iteratively grew in maturity, expanding from a basic IaaS provider to higher-level PaaS, SaaS, and industry-specific services. \n",
      "\n",
      "- Expanded globally to provide lower latency and localized support, now available in over 200 countries.\n",
      "\n",
      "- Continued downward pressure on prices while increasing efficiency and performance of services.\n",
      "\n",
      "So in summary, AWS has evolved tremendously since its initial launch to become a highly robust and mature cloud computing platform through continuous innovation, understanding of customer needs, and rapid global\n",
      "CPU times: user 172 ms, sys: 7.96 ms, total: 180 ms\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use retriever as part of a query engine\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"refine\", use_async=True)\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "# query\n",
    "response = query_engine.query(\"How has AWS evolved?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb24cb8-b839-4754-b653-ac40cebfe0bc",
   "metadata": {},
   "source": [
    "#### Embedding-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc47dc54-197f-43bb-9298-b2af24c6b095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.document_summary import DocumentSummaryIndexEmbeddingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dcb81cb-0d36-4af8-a0c5-9061a2dce986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = DocumentSummaryIndexEmbeddingRetriever(\n",
    "    doc_summary_index,\n",
    "    choice_select_prompt=claude_choice_select_prompt,\n",
    "    # choice_batch_size=choice_batch_size,\n",
    "    # format_node_batch_fn=format_node_batch_fn,\n",
    "    parse_choice_select_answer_fn=custom_parse_choice_select_answer_fn,\n",
    "    #service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48934544-3dde-4231-b41c-540139378751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrieved_nodes = retriever.retrieve(\"Human: How has AWS evolved?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f06e5f6-d62e-4348-8ef5-d4cb6219b54e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb93c084-411b-40c2-b5d4-6fc2a90b8ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everybody agreed that having a persistent block store was important to a complete compute service;\n",
      "however, to have one ready would take an extra year. The question became could we offer customers auseful service where they could get meaningful value before we had all the features we thought they wanted?We decided that the initial launch of EC2 could be feature-poor if we also organized ourselves to listen tocustomers and iterate quickly. This approach works well if you indeed iterate quickly; but, is disastrous if youcan’t. We launched EC2 in 2006 with one instance size, in one data center, in one region of the world, withLinux operating system instances only (no Windows), without monitoring, load balancing, auto-scaling, oryes, persistent storage. EC2 was an initial success, but nowhere near the multi-billion-dollar service it’sbecome until we added the missing capabilities listed above, and then some.\n",
      "In the early days of AWS, people sometimes asked us why compute wouldn’t just be an undifferentiated\n",
      "commodity. But, there’s a lot more to compute than just a server. Customers want various flavors of compute(e.g. server configurations optimized for storage, memory, high-performance compute, graphics rendering,machine learning), multiple form factors (e.g. fixed instance sizes, portable containers, serverless functions),various sizes and optimizations of persistent storage, and a slew of networking capabilities. Then, there’sthe CPU chip that runs in your compute. For many years, the industry had used Intel or AMD x86 processors.We have important partnerships with these companies, but realized that if we wanted to push price andperformance further (as customers requested), we’d have to develop our own chips, too. Our first generalizedchip was Graviton, which we announced in 2018. This helped a subset of customer workloads run morecost-effectively than prior options. But, it wasn’t until 2020, after taking the learnings from Graviton and\n",
      "innovating on a new chip, that we had something remarkable with our Graviton2 chip, which provides up to40% better price-performance than the comparable latest generation x86 processors.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "Think about howmuch of an impact 40% improvement on compute is. Compute is used for every bit of technology. That’s ahuge deal for customers. And, while Graviton2 has been a significant success thus far (48 of the top 50 AWSEC2 customers have already adopted it), the AWS Chips team was already learning from what customerssaid could be better, and announced Graviton3 this past December (offering a 25% improvement on top ofGraviton2’s relative gains). The list of what we’ve invented and delivered for customers in EC2 (and AWS ingeneral) is pretty mind-boggling, and this iterative approach to innovation has not only given customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.\n",
      "Devices : Our first foray into devices was the Kindle, released in 2007. It was not the most sophisticated\n",
      "industrial design (it was creamy white in color and the corners were uncomfortable for some people to hold),but revolutionary because it offered customers the ability to download any of over 90,000 books (nowmillions) in 60 seconds—and we got better and faster at building attractive designs. Shortly thereafter, welaunched a tablet, and then a phone (with the distinguishing feature of having front-facing cameras and agyroscope to give customers a dynamic perspective along with varied 3D experiences). The phone wasunsuccessful, and though we determined we were probably too late to this party and directed these resourceselsewhere, we hired some fantastic long-term builders and learned valuable lessons from this failure thathave served us well in devices like Echo and FireTV .\n",
      "When I think of the first Echo device—and what Alexa could do for customers at that point—it was\n",
      "noteworthy, yet so much less capable than what’s possible today.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "Today, there are hundreds of millions ofAlexa-enabled devices out there (in homes, offices, cars, hotel rooms, Amazon Echo devices, and third-partymanufacturer devices); you can listen to music—or watch videos now; you can control your lights andhome automation; you can create routines like “Start My Day” where Alexa tells you the weather, yourestimated commute time based on current traffic, then plays the news; you can easily order retail items onAmazon; you can get general or customized news, updates on sporting events and related stats—and we’re stillquite early with respect to what Alexa and Alexa-related devices will do for customers. Our goal is forAlexa to be the world’s most helpful and resourceful personal assistant, who makes people’s lives meaningfullyeasier and better. We have a lot more inventing and iterating to go, but customers continue to indicate thatwe’re on the right path. We have several other devices at varying stages of evolution (e.g. Ring and Blinkprovide the leading digital home security solutions, Astro is a brand new home robot that we just launchedin late 2021), but it’s safe to say that every one of our devices, whether you’re talking about Kindle, FireTV,Alexa/Echo, Ring, Blink, or Astro is an invention-in-process with a lot more coming that will keepimproving customers’ lives.\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(retrieved_nodes):\n",
    "    \n",
    "    print(node.node.get_text())\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c626c-1eab-49c6-bbf5-e3b466832ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
