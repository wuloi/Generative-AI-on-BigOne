# 第九章：使用 RAG 和代理的上下文感知推理应用程序
[![](../img/gaia_book_cover_sm.png)](https://www.amazon.com/Generative-AI-AWS-Multimodal-Applications/dp/1098159225/)

# 问题与解答

_问：大型语言模型在上下文感知推理方面面临哪些限制？_

答：大型语言模型 (LLM) 在拥有准确和最新的知识方面面临挑战，从而导致幻觉和知识截止等问题。

_问：幻觉和知识截止如何影响模型的准确性？_

答：幻觉会导致生成不正确或不相关的信息，而知识截止会将模型的理解限制在截至某个日期的可用信息范围内，从而影响响应的准确性。

_问：什么是检索增强生成 (RAG)，它是如何工作的？_

答：RAG 是一个框架，它允许 LLM 访问在训练期间未见过的数据。它通过允许 LLM 驱动的应用程序使用外部数据源来克服知识限制。

_问：外部知识来源如何促进 RAG？_

答：RAG 中的外部知识来源提供了 LLM 参数内存中未包含的额外数据，有助于缓解幻觉和知识截止等问题。

_问：文档加载和分块在 RAG 中的意义是什么？_

答：文档加载和分块在 RAG 中对于组织和处理外部数据非常重要，使其可供模型访问以增强其知识库和推理能力。

_问：你能解释一下 RAG 工作流程及其实现吗？_

答：RAG 工作流程涉及将外部数据源与 LLM 集成，使用文档加载、分块和检索增强等方法，利用额外的相关信息增强模型的响应。

_问：开发上下文感知推理应用程序的关键考虑因素是什么？_

答：关键考虑因素包括管理知识的准确性、定期更新信息以及有效集成外部数据源，以解决幻觉和知识截止问题。

_问：嵌入向量存储和检索如何影响 RAG 的性能？_

答：嵌入向量存储和检索对于 RAG 有效管理和访问相关的外部数据至关重要，通过提供额外的上下文和信息，可以显著提高模型的性能。

_问：使用最大边际相关性进行重新排序有哪些有效策略？_

答：有效的策略包括使用算法在检索结果中优先考虑相关性和多样性，确保针对查询呈现最相关和最多样的信息。

# 章节
* [第一章](/01_intro) - 生成式人工智能用例、基础知识、项目生命周期
* [第二章](/02_prompt) - 提示工程和上下文学习
* [第三章](/03_foundation) - 大型语言基础模型
* [第四章](/04_optimize) - 量化和分布式计算
* [第五章](/05_finetune) - 微调和评估
* [第六章](/06_peft) - 参数高效微调 (PEFT)
* [第七章](/07_rlhf) - 使用带有 RLHF 的强化学习进行微调
* [第八章](/08_deploy) - 优化和部署生成式人工智能应用程序
* [第九章](/09_rag) - 检索增强生成 (RAG) 和代理
* [第十章](/10_multimodal) - 多模态基础模型
* [第十一章](/11_diffusers) - 使用 Stable Diffusion 进行受控生成和微调
* [第十二章](/12_bedrock) - 用于生成式人工智能的 Amazon Bedrock 托管服务

# 相关资源
* YouTube 频道：https://youtube.generativeaionaws.com
* 生成式人工智能 AWS Meetup（全球，虚拟）：https://meetup.generativeaionaws.com
* AWS 上的生成式人工智能 O'Reilly 图书：https://www.amazon.com/Generative-AI-AWS-Multimodal-Applications/dp/1098159225/
* AWS 上的数据科学 O'Reilly 图书：https://www.amazon.com/Data-Science-AWS-End-End/dp/1492079391/
