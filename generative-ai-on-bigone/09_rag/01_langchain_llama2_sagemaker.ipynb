{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e85f55-9a35-4d97-9917-bef3f6e8a627",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG) with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89353535-16f4-438a-8613-be3d698f0a96",
   "metadata": {},
   "source": [
    "In this example notebook, you will see how to perform basic Retrieval Augmented Generation (RAG) using a collection of Amazon's Letters to Shareholders to run basic Q&A.\n",
    "\n",
    "This notebook does not have any specific CPU/GPU requirements, and was built using the `Data Science 3.0 Python 3` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335cbce-a8a6-443d-804b-c6bc4d0d8c54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174bd3f-7ea6-4e40-9617-a7d263cc0f11",
   "metadata": {},
   "source": [
    "Install the dependencies for this example:\n",
    "- LangChain: Framework for Orchestrating the RAG workflow\n",
    "- FAISS: In-Memory Vector Database for storing document embeddings\n",
    "- PyPDF: Python library for processing PDF documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e49456-bad8-40b3-b266-87a3935f7aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.0.309 --quiet --root-user-action=ignore\n",
    "%pip install faiss-cpu==1.7.4 --quiet --root-user-action=ignore\n",
    "%pip install pypdf==3.15.1 --quiet --root-user-action=ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582419ab-471e-4bdf-8b6a-a49c57f2a882",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fetching and Processing the Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8063d9f-0c5d-4e33-9e01-dce73b45c2ab",
   "metadata": {},
   "source": [
    "Next, fetch the sample data for this example. This section will download the publicly available Amazon Letters to Shareholders, that are provided yearly as a \"Year in Review\" of Amazon's business.\n",
    "\n",
    "This will download the pdfs locally and store them in a `data` directory local to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb4b3c4-4eea-4a4e-87cc-2401830ef953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./data\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    dict(year=2022, source=filenames[0]),\n",
    "    dict(year=2021, source=filenames[1]),\n",
    "    dict(year=2020, source=filenames[2]),\n",
    "    dict(year=2019, source=filenames[3])]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1137c-ecfa-4d54-ba0e-843de52c1c5b",
   "metadata": {},
   "source": [
    "As a part of Amazon's peculiar culture, the CEO always attaches the original 1997 Letter to Shareholders to the current letter. To reduce the amount of processing necessary, reduce bias towards that year, and improve output, you will use PyPDF to remove those pages from each file and re-save it over the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d1ff002-8c3e-4c19-92b4-d333b9919fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pypdf import PdfReader, PdfWriter\n",
    "import glob\n",
    "\n",
    "local_pdfs = glob.glob(data_root + '*.pdf')\n",
    "\n",
    "for local_pdf in local_pdfs:\n",
    "    pdf_reader = PdfReader(local_pdf)\n",
    "    pdf_writer = PdfWriter()\n",
    "    for pagenum in range(len(pdf_reader.pages)-3):\n",
    "        page = pdf_reader.pages[pagenum]\n",
    "        pdf_writer.add_page(page)\n",
    "\n",
    "    with open(local_pdf, 'wb') as new_file:\n",
    "        new_file.seek(0)\n",
    "        pdf_writer.write(new_file)\n",
    "        new_file.truncate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7c20b-45c3-4de5-8352-bb8991074a4d",
   "metadata": {},
   "source": [
    "Now that you have clean PDFs to work with, they need to be broken down into manageable pieces so you can provide the most relevant sections to the LLM as part of your RAG workflow. Here, you will iterate over all the documents and break them down into 512 character chunks with an overlap of 100 characters.\n",
    "\n",
    "The `chunk_size` dictates the size of the documents that will be embedded and stored in the vector database.\n",
    "\n",
    "The `chunk_overlap` dictates the amount of text that is used from a previous chunk when building the next one. This allows you to maintain some of the context between chunks.\n",
    "\n",
    "The `RecursiveCharacterTextSplitter` attempts to split up text recursively using delimeters of `[\"\\n\\n\", \"\\n\", \" \", \"\"]` until achieving the desired chunk size. This attempts to keep paragraphs/sentences/words together to allow for better semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd66b0d4-dc7e-4283-a7f7-e1b793f0dc4a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Document Pages 25\n",
      "# of Document Chunks: 299\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "documents = []\n",
    "\n",
    "for idx, file in enumerate(filenames):\n",
    "    loader = PyPDFLoader(data_root + file)\n",
    "    document = loader.load()\n",
    "    for document_fragment in document:\n",
    "        document_fragment.metadata = metadata[idx]\n",
    "        \n",
    "    documents += document\n",
    "\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'# of Document Pages {len(documents)}')\n",
    "print(f'# of Document Chunks: {len(docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e640ff1f-b6c5-48ae-86ab-a69b629f7c1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy Model for Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f48b4-0155-46e4-9165-b8faf5d70096",
   "metadata": {},
   "source": [
    "In the following sections you will need to deploy a set of ML Models, one for Embeddings and a LLM for Language Generation. This example assumes you are working inside of SageMaker studio, so you can deploy them yourself or through SageMaker Jumpstart.\n",
    "\n",
    "For these examples, you will use `All MiniLM L6 v2` as the embedding model, and `LLaMa-2-7B-chat` as the LLM for language generation. \n",
    "\n",
    "__Note:__ If you choose other options, you may have to adjust the `transform_input` and `transform_output` functions in future sections for embedding and llm to match the models you've selected.\n",
    "\n",
    "Refer to the [SageMaker Jumpstart Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html) for details on how to deploy models via Jumpstart.\n",
    "\n",
    "If you already have an embedding endpoint deployed, you can skip the following cell, and modify the `embedding_model_endpoint_name` value to match your endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59583752-0a04-4fda-a3fa-3d30be3c4df5",
   "metadata": {},
   "source": [
    "__Note: running the following cell will deploy a SageMaker endpoint. You will need to delete the endpoint to stop charges from accumulating. See the clean up step at the end of this notebook.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c44af9-fb91-4773-bc5f-c8d7459db772",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'huggingface-textembedding-all-MiniLM-L6-v2' with wildcard version identifier '*'. You can pin to version '1.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "embedding_model_id, embedding_model_version = \"huggingface-textembedding-all-MiniLM-L6-v2\", \"*\"\n",
    "model = JumpStartModel(model_id=embedding_model_id, model_version=embedding_model_version)\n",
    "embedding_predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e75dcdf-141a-4e2a-8e1b-1b1e039bb907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hf-textembedding-all-minilm-l6-v2-2023-12-26-20-58-21-407'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the model endpoint NAME, not the ARN\n",
    "embedding_model_endpoint_name = embedding_predictor.endpoint_name\n",
    "embedding_model_endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84cacf-fffe-4500-ace2-bef19b7694e3",
   "metadata": {},
   "source": [
    "To use your SageMaker model endpoints, you need to have a set of credentials. This section will assume them from your SageMaker Studio session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd7c3fa-0c39-4876-925f-ee3918e9bdb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7696e9d-1d95-45fb-b575-76018d08e2ac",
   "metadata": {},
   "source": [
    "## Creating and Populating the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bd413-4a32-4ab9-92d4-1bcfd6854933",
   "metadata": {},
   "source": [
    "Next you need to set up how to process the embeddings for the input documents.\n",
    "\n",
    "The provided CustomEmbeddingsContentHandler class has a set of functions, transform_input and transform_output, for porcessing data going into and out of the embedding model.\n",
    "\n",
    "With the content handler defined, you will then use the SageMakerEndpointEmbeddings class from LangChain to create an embeddings object that corresponds to your hosted embeddings model along with the appropriate content handler for processing its inputs/outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5aa464-6e62-4e4f-83aa-ea08545a93d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "import json\n",
    "\n",
    "\n",
    "class CustomEmbeddingsContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"embedding\"]\n",
    "\n",
    "\n",
    "embeddings_content_handler = CustomEmbeddingsContentHandler()\n",
    "\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddings(\n",
    "    endpoint_name=embedding_model_endpoint_name,\n",
    "    region_name=aws_region,\n",
    "    content_handler=embeddings_content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c536f-4a3d-423a-8711-d3aed5f7a08c",
   "metadata": {},
   "source": [
    "With our embeddings references ready, the next step is to actually process those document chunks into vectors and store them somewhere. This example uses a FAISS in-memory vector database, but there are many other options available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6feb6fba-9e9e-4880-860a-2c0c8f61c9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a2b4c55-056e-4922-a7fa-4786b0d1dbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a7597-abc0-4a14-8d6e-810893ff4a78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running Vector Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae5fdb-6881-4b9d-ba42-ed07f980183e",
   "metadata": {},
   "source": [
    "Now that you have a populated vector database, you can run queries against it to return relevant document chunks.\n",
    "\n",
    "Start with a simple query that corresponds to the source material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b119c2c4-3dbe-41a0-87d2-1b85fcb0abb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"How has AWS evolved?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8897cbb-7ce8-4b37-bb30-41d1c8ea887b",
   "metadata": {
    "tags": []
   },
   "source": [
    "The results that come back from the `similarity_search_with_score` API are sorted by score from lowest to highest. The score value is represented by the [L-squared (or L2)](https://en.wikipedia.org/wiki/Lp_space) distance of each result. Lower scores are better, repesenting a shorter distance between vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2a0069d-d864-49d4-90eb-c588fba0f9b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.5685306191444397\n",
      "\n",
      "\n",
      "Content: customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.7789842486381531\n",
      "\n",
      "\n",
      "Content: We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.7893760204315186\n",
      "\n",
      "\n",
      "Content: back and determining what they wanted to change coming out of the pandemic. Many concludedthat they didn’t want to continue managing their technology infrastructure themselves, and made thedecision to accelerate their move to the cloud. This shift by so many companies (along with the economyrecovering) helped re-accelerate AWS’s revenue growth to 37% Y oY in 2021.\n",
      "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "Score: 0.7898486852645874\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_with_scores = db.similarity_search_with_score(query)\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff8e58e5-baff-4d2f-b3d7-614016b13f74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.5685306191444397\n",
      "\n",
      "\n",
      "Content: customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.7789842486381531\n",
      "\n",
      "\n",
      "Content: We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.7893760204315186\n",
      "\n",
      "\n",
      "Content: much as cost-optimizing so they can take their resources and apply them to emerging and inventive new customerexperiences they’re planning. Customers have appreciated this customer-focused, long-term approach, andwe think it’ll bode well for both customers and AWS.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.8272767066955566\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter={\"year\": 2022}\n",
    "\n",
    "results_with_scores = db.similarity_search_with_score(query,\n",
    "  filter=filter)\n",
    "\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9bd43-f485-4acd-bf4a-aa2661f3ad2b",
   "metadata": {},
   "source": [
    "## Creating Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad27408-6e86-4469-88d9-410c8784c6f9",
   "metadata": {},
   "source": [
    "You've gotten results from your vector database, but currently they are just chunks of the original documents and some of them might not even contain the information you want to provide as an answer to your original query.\n",
    "\n",
    "To generate the appropriate response, you will leverage a prompt template that takes the original question asked along with relevant context chunks from your vector database to generate a new response from your language generator model.\n",
    "\n",
    "LangChain provides functionality to allow for easier creation and population of prompt templates. The template below has specific markup for LLaMa-2-chat, but also has placeholder values for `{context}` and `{question}`, which you will provide to fill out the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80de40d9-4525-4e6a-8af0-f4a567a8fc5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "Use the context provided to answer the question at the end. If you dont know the answer just say that you don't know, don't try to make up an answer.\n",
    "<</SYS>>\n",
    "\n",
    "Context:\n",
    "----------------\n",
    "{context}\n",
    "----------------\n",
    "\n",
    "Question: {question} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7a714-e1bc-4c75-8316-c56a47a21353",
   "metadata": {},
   "source": [
    "## Preparing the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e7a61-132a-4b1f-ba39-5b9e2d577141",
   "metadata": {},
   "source": [
    "The next step is a process similar to the one you did earlier for the embedding model, but now for your LLM.\n",
    "\n",
    "In the QAContentHandler class, you will see `transform_input` and `transform_output` functions to manipulate the inputs and outputs of your LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "949f5a8a-581d-43a6-8c1d-2a7eb998dbf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "import json\n",
    "\n",
    "\n",
    "class QAContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps(\n",
    "            {\"inputs\" : [\n",
    "                [\n",
    "                    {\n",
    "                        \"role\" : \"system\",\n",
    "                        \"content\" : \"\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\" : \"user\",\n",
    "                        \"content\" : prompt\n",
    "                    }\n",
    "                ]],\n",
    "                \"parameters\" : {**model_kwargs}\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generation\"][\"content\"]\n",
    "\n",
    "qa_content_handler = QAContentHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065bc98-ddd4-4c2d-bb92-8572f7483c63",
   "metadata": {},
   "source": [
    "Now you will deploy a SageMaker endpoint for language generation LLM. Afterward you will create an object pointed to that endpoint and provide inference parameters to the endpoint and model.\n",
    "\n",
    "If you already have a LLM endpoint deployed, you can skip the following cell, and modify the `llm_model_endpoint_name` value to match your endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386fdd6-7aee-4cde-a601-521007b31c3c",
   "metadata": {},
   "source": [
    "__Note: running the following cell will deploy a SageMaker endpoint which takes a few minutes. You will need to delete the endpoint to stop charges from accumulating. See the clean up step at the end of this notebook.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f21bd6-2616-4c54-8e61-7f587861e94e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_model_id, llm_model_version = \"meta-textgeneration-llama-2-7b-f\", \"2.*\"\n",
    "llm_model = JumpStartModel(model_id=llm_model_id, model_version=llm_model_version)\n",
    "llm_predictor = llm_model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b369788d-da6f-4f55-8b5f-10a82fe7e7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-textgeneration-llama-2-7b-f-2023-12-26-21-03-42-236'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the model endpoint NAME, not the ARN\n",
    "llm_model_endpoint_name = llm_predictor.endpoint_name\n",
    "llm_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fe31a83-9892-4751-b6d9-30c69a3ef0f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = SagemakerEndpoint(\n",
    "        endpoint_name=llm_model_endpoint_name,\n",
    "        region_name=aws_region,\n",
    "        model_kwargs={\"max_new_tokens\": 1000, \"top_p\": 0.9, \"temperature\": 1e-11},\n",
    "        endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "        content_handler=qa_content_handler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0594e6-0c4d-4564-9da6-74e5b8b44b91",
   "metadata": {},
   "source": [
    "You can invoke this LLM object directly to get a baseline response without any contextual information provided. You'll notice the answer to the question `How has AWS evolved?` is more about __what__ AWS has done rather than a more internal take on how AWS has evolved. This is likely due to the corpus of data that the LLM was trained on which contained a large amount of articles from the internet.\n",
    "\n",
    "Note that this is not a bad response by any stretch, but it might not be the response you're looking for.\n",
    "\n",
    "You'll see how context can evolve the reponse in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab06b378-162d-41c7-bac3-80fae801d1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" AWS (Amazon Web Services) has evolved significantly since its launch in 2006. Here are some key milestones and developments in AWS's evolution:\\n\\n1. 2006: Amazon Web Services (AWS) is launched as a separate business unit within Amazon, offering a limited set of cloud computing services, including Elastic Compute Cloud (EC2), Simple Storage Service (S3), and Simple Queue Service (SQS).\\n2. 2008: AWS introduces its first virtual private cloud (VPC), allowing customers to launch AWS resources in a dedicated virtual network.\\n3. 2010: AWS launches its first data center outside of the United States, in Ireland.\\n4. 2011: AWS introduces the Elastic Block Store (EBS), providing block-level storage volumes for EC2 instances.\\n5. 2012: AWS launches its CloudFormation service, allowing customers to define and manage AWS infrastructure using templates.\\n6. 2013: AWS introduces the Amazon Elastic Container Service (ECS), providing a highly scalable, high-performance container orchestration service.\\n7. 2014: AWS launches its first data center in Asia, in Singapore.\\n8. 2015: AWS introduces the Amazon Elastic Container Service for Kubernetes (EKS), providing a managed service for deploying and managing containerized applications using Kubernetes.\\n9. 2016: AWS launches its first data center in Australia, in Sydney.\\n10. 2017: AWS introduces the Amazon Neptune database service, providing a highly scalable, fully managed graph database service.\\n11. 2018: AWS launches its first data center in India, in Mumbai.\\n12. 2019: AWS introduces the Amazon SageMaker machine learning platform, providing a fully managed service for building, training, and deploying machine learning models.\\n13. 2020: AWS launches its first data center in South Africa, in Johannesburg.\\n\\nIn addition to these major milestones, AWS has continued to expand its service offerings and capabilities, including the introduction of new services such as AWS Lambda, AWS Glue, and AWS Transfer for FSx. AWS has also continued to invest in its infrastructure, expanding its global footprint and adding new regions and availability zones to its network.\\n\\nOverall, AWS has evolved from a small set of cloud computing services to a comprehensive cloud platform offering a wide range of services and capabilities, including computing, storage, database, analytics, machine learning, and more. AWS has established itself as a leader in the cloud computing market and continues to innovate and expand its offerings to meet the growing demands of its customers.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How has AWS evolved?\"\n",
    "llm.predict(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ea03c-83fb-4ef4-a4cb-cc6d3b26c2c3",
   "metadata": {},
   "source": [
    "With the LLM endpoint object created, you are ready to create your first chain!\n",
    "\n",
    "This chain is a simple example using LangChain's RetrievalQA chain, which will:\n",
    "- take a query as input\n",
    "- generate query embeddings\n",
    "- query the vector database for relevant document chunks based on the query embedding\n",
    "- inject the context and original query into the prompt template\n",
    "- invoke the LLM with the completed prompt\n",
    "- return the LLM result\n",
    "\n",
    "The [`stuff` chain type](https://python.langchain.com/docs/modules/chains/document/stuff) simply takes the context documents and inserts them into the prompt.\n",
    "\n",
    "By setting `return_source_documents` to `True`, the LLM responses will also contain the document chunks from the vector database, to illustrate where the context came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6565df76-1c3f-4d5a-a78d-928766d6586b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78919b-9019-4a06-95b2-c209fbdce562",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now that your chain is set up, you can supply queries to it and generate responses based on your source documents.\n",
    "\n",
    "A few examples have been provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "473c77f3-a42f-407f-9231-07b2bb71fc76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How has AWS evolved?\n",
      "\n",
      "Result:  Based on the provided context, AWS has evolved in the following ways:\n",
      "\n",
      "1. Rapid innovation: AWS continues to deliver new capabilities rapidly, launching over 3,300 new features and services in 2022 alone.\n",
      "2. Long-term investment: AWS has made a long-term decision to continue investing in its infrastructure, even during challenging times such as the 2008-2009 recession.\n",
      "3. Expansion of services: AWS has expanded its offerings beyond just computing and storage, now providing a wide range of services including analytics, machine learning, and security.\n",
      "4. Increased profitability: Despite continued investment in innovation, AWS has achieved strong profitability, with an $85B annual revenue run rate business.\n",
      "5. Shift to cloud adoption: The pandemic has accelerated the shift to cloud adoption, with many companies deciding to move their technology infrastructure to the cloud. This has helped re-accelerate AWS's revenue growth to 37% YoY in 2021.\n",
      "\n",
      "Overall, AWS has evolved from a niche player in the cloud computing market to a dominant force, with a strong track record of innovation and investment in its infrastructure.\n",
      "\n",
      "Context Documents: \n",
      "page_content='done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='back and determining what they wanted to change coming out of the pandemic. Many concludedthat they didn’t want to continue managing their technology infrastructure themselves, and made thedecision to accelerate their move to the cloud. This shift by so many companies (along with the economyrecovering) helped re-accelerate AWS’s revenue growth to 37% Y oY in 2021.' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How has AWS evolved?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "      print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8ba6252-103e-4d12-936f-4ce91f139aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(\n",
    "        search_type=\"mmr\", # Maximum Marginal Relevance (MMR)\n",
    "        search_kwargs={\"k\": 3, \"lambda_mult\": 0.1}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d2e45-eb62-4790-81c1-ece18f4b7151",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now that your chain is set up, you can supply queries to it and generate responses based on your source documents.\n",
    "\n",
    "A few examples have been provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4816efb-1d74-433b-adaa-61ed50caff04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How has AWS evolved?\n",
      "\n",
      "Result:  Based on the context provided, AWS has evolved in the following ways:\n",
      "\n",
      "1. Innovation: AWS has continued to innovate and invest in new technologies and services to meet the changing needs of its customers.\n",
      "2. Growth: AWS is expected to experience unusual growth in the next decade, particularly in the areas of virtual classrooms and government efforts to combat the pandemic.\n",
      "3. Efficiency: AWS is more efficient than traditional in-house data centers due to its institutional advantages and the transition to virtual classrooms and government use.\n",
      "\n",
      "I don't know the answer to the question \"What are the specific areas of innovation for AWS?\" as the context does not provide that information.\n",
      "\n",
      "Context Documents: \n",
      "page_content='done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='AWS is also inherently more efficient than the traditional in-house data center. That’s primarily due to two' metadata={'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='institutionsaround the world are transitioning from in-person to virtual classrooms and are running on AWS to help ensurecontinuity of learning. And governments are leveraging AWS as a secure platform to build out new capabilitiesin their efforts to end this pandemic.' metadata={'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How has AWS evolved?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "      print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a826123-5998-45dd-9dda-c71386c89491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Why is Amazon successful?\n",
      "\n",
      "Result:  Based on the provided context, Amazon's success can be attributed to several factors:\n",
      "\n",
      "1. Early Mover Advantage: Amazon has been iterating and remaking its fulfillment capabilities for nearly two decades, giving it a significant head start over its competitors. This early mover advantage has allowed Amazon to develop a robust and efficient logistics network, which has been critical in its success.\n",
      "2. Customer Obsession: Amazon is divinely discontented with customer experiences, whether they are its own or not. The company is constantly experimenting and inventing to make customers' experiences better. This customer-centric approach has helped Amazon build a loyal customer base and differentiate itself from its competitors.\n",
      "3. Innovation: Amazon is known for its innovative approach to business. The company is always looking for new ways to improve its operations and customer experiences. This innovative spirit has allowed Amazon to stay ahead of the competition and adapt to changing market conditions.\n",
      "4. Scale: Amazon's large scale has been a significant factor in its success. With over a million Amazonians working in its fulfillment network, the company has the resources and capacity to handle a large volume of orders and meet customer demand.\n",
      "5. Strategic Acquisitions: Amazon has made several strategic acquisitions over the years, including the purchase of Whole Foods Market and the acquisition of Twitch. These acquisitions have helped Amazon expand its reach and offer a wider range of products and services to its customers.\n",
      "\n",
      "Overall, Amazon's success can be attributed to a combination of its early mover advantage, customer obsession, innovation, scale, and strategic acquisitions.\n",
      "\n",
      "Context Documents: \n",
      "page_content='position us well to pursue this large market segment. Amazon Business allows businesses, municipalities,and organizations to procure products like office supplies and other bulk items easily and at great savings.While some areas of the economy have struggled over the past few years, Amazon Business has thrived. Why?Because the team has translated what it means to deliver selection, value, and convenience into a businessprocurement setting, constantly listening to and learning from customers, and innovating' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='unpredictable as this pandemic turned out to be. What is it about Amazon that made it possible for us to doso? It’s because we weren’t starting from a standing start. We had been iterating on and remaking ourfulfillment capabilities for nearly two decades. In every business we pursue, we’re constantly experimentingand inventing. We’re divinely discontented with customer experiences, whether they’re our own or not. Webelieve these customer experiences can always be better, and we strive to make customers’' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='For example, more than a million Amazonians work in our fulfillment network. In 2018, we championed' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Why is Amazon successful?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "      print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2418da7b-0bfc-4ef6-a64a-17b4ccb12174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What business challenges has Amazon experienced?\n",
      "\n",
      "Result:  Based on the provided context, Amazon has experienced the following business challenges:\n",
      "\n",
      "1. Rising cost to serve in their Stores fulfillment network (i.e. the cost to get a product from Amazon to a customer).\n",
      "2. Unusual number of simultaneous challenges this past year.\n",
      "3. Operating in large, dynamic, global market segments with many capable and well-funded competitors.\n",
      "\n",
      "It is important to note that the context only provides information about the challenges Amazon has experienced, and does not provide information about the company's overall performance or success.\n",
      "\n",
      "Context Documents: \n",
      "page_content='shareholders, and employees.\\nWhile there were an unusual number of simultaneous challenges this past year, the reality is that if you\\noperate in large, dynamic, global market segments with many capable and well-funded competitors (theconditions in which Amazon operates all of its businesses), conditions rarely stay stagnant for long.\\nIn the 25 years I’ve been at Amazon, there has been constant change, much of which we’ve initiated ourselves.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='This type of iterative innovation is pervasive across every team at Amazon. I could have given comparable\\nexamples in Advertising, Grocery, Gaming, Amazon Music, Amazon Care (our telemedicine offering), orPharmacy, to name a few. All of these stories are still being written as we rapidly experiment, learn, andcontinue to try to make our customer experience better every day.\\nIf this approach sounds appealing, a natural question is what’s required to get good at it? It’s easier said' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='A critical challenge we’ve continued to tackle is the rising cost to serve in our Stores fulfillment network (i.e.\\nthe cost to get a product from Amazon to a customer)—and we’ve made several changes that we believe will\\nmeaningfully improve our fulfillment costs and speed of delivery .\\nDuring the early part of the pandemic, with many physical stores shut down, our consumer business grew' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What business challenges has Amazon experienced?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "      print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8bd21-c18f-43c8-bc1a-02380b4c928b",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee483c-e1d8-499f-a707-82dafd3bd0cb",
   "metadata": {},
   "source": [
    "Uncomment the `delete_endpoint` calls to remove the resources you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276e6b3-788a-49f4-960e-8856dbf22a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "# #Delete embedding endpoint\n",
    "# sagemaker_client.delete_endpoint(EndpointName=embedding_model_endpoint_name)\n",
    "\n",
    "# #Delete llm endpoint\n",
    "# sagemaker_client.delete_endpoint(EndpointName=llm_model_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e6b028-4b2b-4f76-9d52-56d7e56dc4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
