{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d47280b2-33e4-4e7e-bb3a-fffd6624a586",
   "metadata": {},
   "source": [
    "## Textual Inversion fine-tuning Stable Diffusion\n",
    "\n",
    "[Textual inversion](https://arxiv.org/abs/2208.01618) is a method to personalize text2image models like stable diffusion on your own images using just 3-5 examples.\n",
    "The `textual_inversion.py` script shows how to implement the training procedure and adapt it for stable diffusion.\n",
    "\n",
    "Here, we'll customize Stable Diffusion by fine-tuning with Molly pictures using an example adapted from Hugging Face.  To do this, we'll utilize some Hugging Face libraries including the [Diffuser's Library](https://huggingface.co/docs/diffusers/index) and [PEFT Libraries](https://huggingface.co/docs/peft/index).  \n",
    "\n",
    "To start, we'll install some prerequisites and perform some initial setup. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba9403-6022-4765-8754-9a6b9c0b3d25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d900a9c6-aefc-435f-9589-b890b98088c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.1 \\\n",
    "  accelerate==0.24.1 \\\n",
    "  transformers==4.35.2 \\\n",
    "  torchvision \\\n",
    "  ftfy \\\n",
    "  tensorboard \\\n",
    "  Jinja2 \\\n",
    "  ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb0814-2e7c-45ef-9a72-22c049535c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40beadcd-3604-4452-98ac-bf5122af42ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping xformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall xformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b43502d2-cec7-41d3-a108-b28e4db8f533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.10.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - xformers\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.08.22 |       h06a4308_0         123 KB\n",
      "    certifi-2023.7.22          |  py310h06a4308_0         153 KB\n",
      "    cudatoolkit-11.3.1         |       h2bc3f7f_2       549.3 MB\n",
      "    ninja-1.10.2               |       h06a4308_5           8 KB\n",
      "    ninja-base-1.10.2          |       hd09550d_5         109 KB\n",
      "    pytorch-1.12.1             |cpu_py310he8d8e81_0        60.9 MB\n",
      "    xformers-0.0.22            |py310_cu11.6.2_pyt1.12.1       133.3 MB  xformers\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       743.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-11.3.1-h2bc3f7f_2 \n",
      "  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5 \n",
      "  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5 \n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.12.1-cpu_py310he8d8e81_0 \n",
      "  xformers           xformers/linux-64::xformers-0.0.22-py310_cu11.6.2_pyt1.12.1 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2023.7.2~ --> pkgs/main::ca-certificates-2023.08.22-h06a4308_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2023.7.22~ --> pkgs/main/linux-64::certifi-2023.7.22-py310h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ca-certificates-2023 | 123 KB    |                                       |   0% \n",
      "pytorch-1.12.1       | 60.9 MB   |                                       |   0% \u001b[A\n",
      "\n",
      "ninja-1.10.2         | 8 KB      |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "xformers-0.0.22      | 133.3 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ninja-base-1.10.2    | 109 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.7.22    | 153 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "ninja-1.10.2         | 8 KB      | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 123 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-1.12.1       | 60.9 MB   | 4                                     |   1% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.7.22    | 153 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.7.22    | 153 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-1.12.1       | 60.9 MB   | #######3                              |  20% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | 9                                     |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###2                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-1.12.1       | 60.9 MB   | ###########6                          |  31% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ####2                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-1.12.1       | 60.9 MB   | #################8                    |  48% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #####2                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-1.12.1       | 60.9 MB   | #########################5            |  69% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-1.12.1       | 60.9 MB   | #################################8    |  92% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #######1                              |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ########                              |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ########8                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #########5                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##########2                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##########8                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###########4                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ############                          |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ############6                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #############3                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #############8                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##############5                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###############2                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###############8                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ################5                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #################1                    |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #################7                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##################4                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###################                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###################6                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ####################1                 |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ####################6                 |  56% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #####################2                |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #####################7                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ######################3               |  60% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ######################8               |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #######################3              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #######################8              |  65% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ########################3             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ########################8             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #########################3            |  69% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #########################8            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##########################4           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##########################9           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###########################4          |  74% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###########################8          |  75% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ############################5         |  77% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #############################1        |  79% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #############################8        |  81% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##############################5       |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###############################2      |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###############################8      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ################################4     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #################################1    |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | #################################8    |  92% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##################################6   |  94% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ###################################7  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ####################################7 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-1.12.1       | 60.9 MB   | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "xformers-0.0.22      | 133.3 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: | By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y xformers -c xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62306ab-9fd7-48ac-8562-9ab2836146ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "write_basic_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db64ddbd-3f17-46da-ab79-2fb5f26d6ee4",
   "metadata": {},
   "source": [
    "Training Script Parameters:\n",
    "\n",
    "It is often a good idea to regularly save checkpoints of your model during training. This way, you can resume training from a saved checkpoint if your training is interrupted for any reason. To save a checkpoint, pass the following argument to the training script to save the full training state in a subfolder in output_dir every 500 steps:\n",
    "\n",
    "--checkpointing_steps=500\n",
    "\n",
    "\n",
    "To resume training from a saved checkpoint, pass the following argument to the training script and the specific checkpoint you’d like to resume from:\n",
    "\n",
    "--resume_from_checkpoint=\"checkpoint-1500\"\n",
    "\n",
    "\n",
    "This guide will show you two ways to create a dataset to finetune on:\n",
    "\n",
    "provide a folder of images to the --train_data_dir argument\n",
    "upload a dataset to the Hub and pass the dataset repository id to the --dataset_name argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af486564-2458-4ee9-b307-c5c639043329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = \"./images-ti-molly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e65974f-8c1d-415c-8e2b-3e3935a5c138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 1.12.1 with CUDA 1106 (you have 2.0.1+cu117)\n",
      "    Python  3.10.13 (you have 3.10.6)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 1.12.1 with CUDA 1106 (you have 2.0.1+cu117)\n",
      "    Python  3.10.13 (you have 3.10.6)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 1.12.1 with CUDA 1106 (you have 2.0.1+cu117)\n",
      "    Python  3.10.13 (you have 3.10.6)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 1.12.1 with CUDA 1106 (you have 2.0.1+cu117)\n",
      "    Python  3.10.13 (you have 3.10.6)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 1.12.1 with CUDA 1106 (you have 2.0.1+cu117)\n",
      "    Python  3.10.13 (you have 3.10.6)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 1.12.1 with CUDA 1106 (you have 2.0.1+cu117)\n",
      "    Python  3.10.13 (you have 3.10.6)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 1.12.1 with CUDA 1106 (you have 2.0.1+cu117)\n",
      "    Python  3.10.13 (you have 3.10.6)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 1.12.1 with CUDA 1106 (you have 2.0.1+cu117)\n",
      "    Python  3.10.13 (you have 3.10.6)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "11/17/2023 16:53:49 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 3\n",
      "Local process index: 3\n",
      "Device: cuda:3\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "11/17/2023 16:53:49 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 6\n",
      "Local process index: 6\n",
      "Device: cuda:6\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "11/17/2023 16:53:49 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "11/17/2023 16:53:49 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 7\n",
      "Local process index: 7\n",
      "Device: cuda:7\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "11/17/2023 16:53:49 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 4\n",
      "Local process index: 4\n",
      "Device: cuda:4\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "Detected kernel version 4.14.327, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "11/17/2023 16:53:49 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 2\n",
      "Local process index: 2\n",
      "Device: cuda:2\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "11/17/2023 16:53:49 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "11/17/2023 16:53:49 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 5\n",
      "Local process index: 5\n",
      "Device: cuda:5\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "{'timestep_spacing', 'prediction_type', 'variance_type', 'thresholding', 'dynamic_thresholding_ratio', 'sample_max_value', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'timestep_post_act', 'reverse_transformer_layers_per_block', 'addition_time_embed_dim', 'cross_attention_norm', 'num_attention_heads', 'projection_class_embeddings_input_dim', 'dual_cross_attention', 'time_cond_proj_dim', 'class_embeddings_concat', 'conv_out_kernel', 'transformer_layers_per_block', 'addition_embed_type_num_heads', 'dropout', 'mid_block_only_cross_attention', 'mid_block_type', 'resnet_out_scale_factor', 'num_class_embeds', 'encoder_hid_dim_type', 'time_embedding_act_fn', 'addition_embed_type', 'resnet_time_scale_shift', 'attention_type', 'time_embedding_dim', 'conv_in_kernel', 'use_linear_projection', 'class_embed_type', 'encoder_hid_dim', 'upcast_attention', 'resnet_skip_time_act', 'time_embedding_type', 'only_cross_attention'} was not found in config. Values will be initialized to default values.\n",
      "11/17/2023 16:54:19 - INFO - __main__ - ***** Running training *****\n",
      "11/17/2023 16:54:19 - INFO - __main__ -   Num examples = 400\n",
      "11/17/2023 16:54:19 - INFO - __main__ -   Num Epochs = 231\n",
      "11/17/2023 16:54:19 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "11/17/2023 16:54:19 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "11/17/2023 16:54:19 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "11/17/2023 16:54:19 - INFO - __main__ -   Total optimization steps = 3000\n",
      "Steps:   0%|           | 1/3000 [00:04<4:00:25,  4.81s/it, loss=0.207, lr=0.016]11/17/2023 16:54:24 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "11/17/2023 16:54:24 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "11/17/2023 16:54:24 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "11/17/2023 16:54:24 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "11/17/2023 16:54:24 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "11/17/2023 16:54:24 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "11/17/2023 16:54:24 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "11/17/2023 16:54:24 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "Steps:  17%|█▎      | 500/3000 [15:07<1:17:26,  1.86s/it, loss=0.0842, lr=0.016]11/17/2023 17:09:26 - INFO - __main__ - Saving embeddings\n",
      "11/17/2023 17:09:27 - INFO - accelerate.accelerator - Saving current state to textual_inversion_molly/checkpoint-500\n",
      "11/17/2023 17:09:29 - INFO - accelerate.checkpointing - Model weights saved in textual_inversion_molly/checkpoint-500/pytorch_model.bin\n",
      "11/17/2023 17:09:30 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_molly/checkpoint-500/optimizer.bin\n",
      "11/17/2023 17:09:30 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_molly/checkpoint-500/scheduler.bin\n",
      "11/17/2023 17:09:30 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_molly/checkpoint-500/sampler.bin\n",
      "11/17/2023 17:09:30 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_molly/checkpoint-500/random_states_0.pkl\n",
      "11/17/2023 17:09:30 - INFO - __main__ - Saved state to textual_inversion_molly/checkpoint-500\n",
      "Steps:  33%|██▎    | 1000/3000 [30:22<1:03:05,  1.89s/it, loss=0.0432, lr=0.016]11/17/2023 17:24:42 - INFO - __main__ - Saving embeddings\n",
      "11/17/2023 17:24:42 - INFO - accelerate.accelerator - Saving current state to textual_inversion_molly/checkpoint-1000\n",
      "11/17/2023 17:24:45 - INFO - accelerate.checkpointing - Model weights saved in textual_inversion_molly/checkpoint-1000/pytorch_model.bin\n",
      "11/17/2023 17:24:46 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_molly/checkpoint-1000/optimizer.bin\n",
      "11/17/2023 17:24:46 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_molly/checkpoint-1000/scheduler.bin\n",
      "11/17/2023 17:24:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_molly/checkpoint-1000/sampler.bin\n",
      "11/17/2023 17:24:46 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_molly/checkpoint-1000/random_states_0.pkl\n",
      "11/17/2023 17:24:46 - INFO - __main__ - Saved state to textual_inversion_molly/checkpoint-1000\n",
      "Steps:  50%|████▌    | 1500/3000 [45:40<46:21,  1.85s/it, loss=0.0324, lr=0.016]11/17/2023 17:40:00 - INFO - __main__ - Saving embeddings\n",
      "11/17/2023 17:40:00 - INFO - accelerate.accelerator - Saving current state to textual_inversion_molly/checkpoint-1500\n",
      "11/17/2023 17:40:02 - INFO - accelerate.checkpointing - Model weights saved in textual_inversion_molly/checkpoint-1500/pytorch_model.bin\n",
      "11/17/2023 17:40:04 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_molly/checkpoint-1500/optimizer.bin\n",
      "11/17/2023 17:40:04 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_molly/checkpoint-1500/scheduler.bin\n",
      "11/17/2023 17:40:04 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_molly/checkpoint-1500/sampler.bin\n",
      "11/17/2023 17:40:04 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_molly/checkpoint-1500/random_states_0.pkl\n",
      "11/17/2023 17:40:04 - INFO - __main__ - Saved state to textual_inversion_molly/checkpoint-1500\n",
      "Steps:  67%|████  | 2000/3000 [1:00:58<31:36,  1.90s/it, loss=0.00282, lr=0.016]11/17/2023 17:55:18 - INFO - __main__ - Saving embeddings\n",
      "11/17/2023 17:55:18 - INFO - accelerate.accelerator - Saving current state to textual_inversion_molly/checkpoint-2000\n",
      "11/17/2023 17:55:20 - INFO - accelerate.checkpointing - Model weights saved in textual_inversion_molly/checkpoint-2000/pytorch_model.bin\n",
      "11/17/2023 17:55:22 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_molly/checkpoint-2000/optimizer.bin\n",
      "11/17/2023 17:55:22 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_molly/checkpoint-2000/scheduler.bin\n",
      "11/17/2023 17:55:22 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_molly/checkpoint-2000/sampler.bin\n",
      "11/17/2023 17:55:22 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_molly/checkpoint-2000/random_states_0.pkl\n",
      "11/17/2023 17:55:22 - INFO - __main__ - Saved state to textual_inversion_molly/checkpoint-2000\n",
      "Steps:  83%|█████ | 2500/3000 [1:16:16<15:13,  1.83s/it, loss=0.00387, lr=0.016]11/17/2023 18:10:36 - INFO - __main__ - Saving embeddings\n",
      "11/17/2023 18:10:36 - INFO - accelerate.accelerator - Saving current state to textual_inversion_molly/checkpoint-2500\n",
      "11/17/2023 18:10:38 - INFO - accelerate.checkpointing - Model weights saved in textual_inversion_molly/checkpoint-2500/pytorch_model.bin\n",
      "11/17/2023 18:10:39 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_molly/checkpoint-2500/optimizer.bin\n",
      "11/17/2023 18:10:39 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_molly/checkpoint-2500/scheduler.bin\n",
      "11/17/2023 18:10:39 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_molly/checkpoint-2500/sampler.bin\n",
      "11/17/2023 18:10:39 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_molly/checkpoint-2500/random_states_0.pkl\n",
      "11/17/2023 18:10:39 - INFO - __main__ - Saved state to textual_inversion_molly/checkpoint-2500\n",
      "Steps: 100%|███████| 3000/3000 [1:31:33<00:00,  1.89s/it, loss=0.0436, lr=0.016]11/17/2023 18:25:53 - INFO - __main__ - Saving embeddings\n",
      "11/17/2023 18:25:53 - INFO - accelerate.accelerator - Saving current state to textual_inversion_molly/checkpoint-3000\n",
      "11/17/2023 18:25:55 - INFO - accelerate.checkpointing - Model weights saved in textual_inversion_molly/checkpoint-3000/pytorch_model.bin\n",
      "11/17/2023 18:25:56 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_molly/checkpoint-3000/optimizer.bin\n",
      "11/17/2023 18:25:56 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_molly/checkpoint-3000/scheduler.bin\n",
      "11/17/2023 18:25:56 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_molly/checkpoint-3000/sampler.bin\n",
      "11/17/2023 18:25:56 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_molly/checkpoint-3000/random_states_0.pkl\n",
      "11/17/2023 18:25:56 - INFO - __main__ - Saved state to textual_inversion_molly/checkpoint-3000\n",
      "Steps: 100%|████████| 3000/3000 [1:31:36<00:00,  1.89s/it, loss=0.708, lr=0.016]11/17/2023 18:25:56 - INFO - __main__ - Saving embeddings\n",
      "Steps: 100%|████████| 3000/3000 [1:31:36<00:00,  1.83s/it, loss=0.708, lr=0.016]\n"
     ]
    }
   ],
   "source": [
    "# learnable_property - valid options are 'object' or style\n",
    "\n",
    "!accelerate launch textual_inversion.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"./images-ti-molly\" \\\n",
    "  --learnable_property=\"object\" \\\n",
    "  --placeholder_token=\"M*\" \\\n",
    "  --initializer_token=\"dog\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=3000 \\\n",
    "  --learning_rate=5.0e-04 --scale_lr \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --output_dir=\"textual_inversion_molly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166292a-4d3e-4fba-a798-87de5dbf9ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
