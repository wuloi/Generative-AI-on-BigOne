{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6011cb7-fd15-4379-be46-02b4ffdb3fe5",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b48c0687-ade4-4e7e-812a-99f0cfeca9c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_checkpoint = \"NousResearch/Meta-Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eeaafdb-8482-4491-bba2-5b3b389813c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 引入必要的类型提示\n",
    "from typing import List, Literal, TypedDict\n",
    "\n",
    "# 从transformers库中导入PreTrainedTokenizer类\n",
    "# PreTrainedTokenizer是一个通用的分词器类，用于处理文本和模型的输入\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "# 定义角色的类型\n",
    "# 角色可以是 \"system\"、\"user\" 或 \"assistant\"\n",
    "Role = Literal[\"system\", \"user\", \"assistant\"]\n",
    "\n",
    "# 定义消息的结构\n",
    "# 消息包括角色和内容\n",
    "class Message(TypedDict):\n",
    "    role: Role\n",
    "    content: str\n",
    "\n",
    "# 定义消息列表类型\n",
    "# 一个消息列表是一个Message对象的列表\n",
    "MessageList = List[Message]\n",
    "\n",
    "# 定义用于标记不同部分的字符串\n",
    "BEGIN_INST, END_INST = \"[INST] \", \" [/INST] \"\n",
    "BEGIN_SYS, END_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "def convert_list_of_message_lists_to_input_prompt(\n",
    "    list_of_message_lists: List[MessageList], \n",
    "    tokenizer: PreTrainedTokenizer\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    将多个消息列表转换为模型输入的提示字符串\n",
    "    :param list_of_message_lists: 包含消息列表的列表，每个消息列表代表一个对话\n",
    "    :param tokenizer: 用于处理文本的分词器\n",
    "    :return: 转换后的输入提示字符串列表\n",
    "    \"\"\"\n",
    "    input_prompts: List[str] = []  # 初始化用于存储输入提示的列表\n",
    "\n",
    "    # 打印类型信息，用于调试\n",
    "    print(type(list_of_message_lists))\n",
    "    print(type(list_of_message_lists[0]))    \n",
    "\n",
    "    # 遍历每个消息列表\n",
    "    for message_list in list_of_message_lists:\n",
    "        # 处理系统消息，将其与下一条消息合并\n",
    "        if message_list[0][\"role\"] == \"system\":\n",
    "            content = \"\".join([BEGIN_SYS, message_list[0][\"content\"], END_SYS, message_list[1][\"content\"]])\n",
    "            message_list = [{\"role\": message_list[1][\"role\"], \"content\": content}] + message_list[2:]\n",
    "\n",
    "        # 检查消息列表的角色顺序是否正确\n",
    "        if not (\n",
    "            all([msg[\"role\"] == \"user\" for msg in message_list[::2]])  # 用户消息必须在偶数索引\n",
    "            and all([msg[\"role\"] == \"assistant\" for msg in message_list[1::2]])  # 助理消息必须在奇数索引\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Format must be in this order: 'system', 'user', 'assistant' roles.\\nAfter that, you can alternate between user and assistant multiple times\"\n",
    "            )\n",
    "\n",
    "        # 获取分词器的eos_token和bos_token\n",
    "        eos = tokenizer.eos_token\n",
    "        bos = tokenizer.bos_token\n",
    "\n",
    "        # 构建输入提示字符串\n",
    "        input_prompt = \"\".join(\n",
    "            [\n",
    "                \"\".join([bos, BEGIN_INST, (prompt[\"content\"]).strip(), END_INST, (answer[\"content\"]).strip(), eos])\n",
    "                for prompt, answer in zip(message_list[::2], message_list[1::2])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 确保最后一条消息来自用户\n",
    "        if message_list[-1][\"role\"] != \"user\":\n",
    "            raise ValueError(f\"Last message must be from user role. Instead, you sent from {message_list[-1]['role']} role\")\n",
    "\n",
    "        # 添加最后一条用户消息到输入提示\n",
    "        input_prompt += \"\".join([bos, BEGIN_INST, (message_list[-1][\"content\"]).strip(), END_INST])\n",
    "\n",
    "        # 将构建好的输入提示添加到列表中\n",
    "        input_prompts.append(input_prompt)\n",
    "\n",
    "    return input_prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "117730a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'Answer only with emojis'}\n",
      "{'role': 'user', 'content': 'Who won the 2016 baseball World Series?'}\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "['<|begin_of_text|>[INST] <<SYS>>\\nAnswer only with emojis\\n<</SYS>>\\n\\nWho won the 2016 baseball World Series? [/INST] ']\n"
     ]
    }
   ],
   "source": [
    "# 创建一个系统消息对象\n",
    "# Message是一个TypedDict类型，定义了角色和内容\n",
    "system_message = Message()\n",
    "system_message[\"role\"] = \"system\"  # 设置消息角色为 \"system\"\n",
    "system_message[\"content\"] = \"Answer only with emojis\"  # 设置消息内容\n",
    "print(system_message)  # 打印系统消息\n",
    "\n",
    "# 创建一个用户消息对象\n",
    "user_message = Message()\n",
    "user_message[\"role\"] = \"user\"  # 设置消息角色为 \"user\"\n",
    "user_message[\"content\"] = \"Who won the 2016 baseball World Series?\"  # 设置消息内容\n",
    "print(user_message)  # 打印用户消息\n",
    "\n",
    "# 创建一个助理消息对象\n",
    "# 这部分代码被注释掉了，如果需要使用，可以取消注释\n",
    "# assistant_message = Message()\n",
    "# assistant_message.role = \"assistant\"  # 设置消息角色为 \"assistant\"\n",
    "# assistant_message.content = \"\"  # 设置消息内容（目前为空）\n",
    "\n",
    "# 创建消息列表并添加消息\n",
    "list_of_messages = list()  # 初始化消息列表\n",
    "list_of_messages.append(system_message)  # 将系统消息添加到消息列表\n",
    "list_of_messages.append(user_message)  # 将用户消息添加到消息列表\n",
    "\n",
    "# 创建消息列表的列表\n",
    "# 这是为了与convert_list_of_message_lists_to_input_prompt函数的参数类型匹配\n",
    "list_of_message_lists = list()  # 初始化消息列表的列表\n",
    "list_of_message_lists.append(list_of_messages)  # 将消息列表添加到消息列表的列表中\n",
    "\n",
    "# 使用convert_list_of_message_lists_to_input_prompt函数生成输入提示\n",
    "# 需要提供一个tokenizer对象，这里假设tokenizer已经定义\n",
    "prompt = convert_list_of_message_lists_to_input_prompt(list_of_message_lists, tokenizer)\n",
    "print(prompt)  # 打印生成的输入提示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc027fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:  25%|██▌       | 1/4 [08:14<24:43, 494.61s/it]"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 如果需要加载模型，可以使用以下代码\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"NousResearch/Meta-Llama-3.1-8B-Instruct\")\n",
    "# # 这行代码将加载与分词器配套的自回归语言模型\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22483f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt is 31 tokens\n"
     ]
    }
   ],
   "source": [
    "# 从transformers库中导入pipeline函数\n",
    "# pipeline用于简化使用预训练模型的过程\n",
    "from transformers import pipeline\n",
    "\n",
    "# 使用tokenizer将输入提示转换为模型可以处理的格式\n",
    "# tokenized_prompt是一个字典，其中包含了输入提示的token IDs等信息\n",
    "tokenized_prompt = tokenizer(prompt)\n",
    "\n",
    "# 打印输入提示的token数量\n",
    "# \"input_ids\"是tokenizer输出的一部分，包含token IDs\n",
    "# [0]表示我们取第一个示例（如果有多个示例的话）\n",
    "# len(tokenized_prompt[\"input_ids\"][0])计算token的数量\n",
    "print(f'prompt is {len(tokenized_prompt[\"input_ids\"][0])} tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce89dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(prompt)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.4xlarge",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
